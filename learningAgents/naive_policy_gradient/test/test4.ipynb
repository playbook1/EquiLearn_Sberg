{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from learningAgents import ReinforceAlgorithm\n",
    "from environmentModel import Model, AdversaryModes\n",
    "from NeuralNetwork import NeuralNetwork\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions import Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adversaryProbs=torch.zeros(len(AdversaryModes))\n",
    "adversaryProbs[0]=1\n",
    "adversaryProbs[1]=0\n",
    "adversaryProbs[8]=0\n",
    "game = Model(totalDemand = 400, \n",
    "               tupleCosts = (57, 71),\n",
    "              totalStages = 3, adversaryProbs=adversaryProbs, advHistoryNum=0)\n",
    "adversaryProbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuralNet=NeuralNetwork(num_input=3+game.advHistoryNum, lr=0.0009,num_actions=4)\n",
    "algorithm = ReinforceAlgorithm(game, neuralNet, numberIterations=1, numberEpisodes=500_000, discountFactor =0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([0.2586, 0.2267, 0.2415, 0.2732], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.2533, 0.2339, 0.2419, 0.2709], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.2527, 0.2385, 0.2395, 0.2692], grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "0   actions:  tensor([2, 0, 1])\n",
      "loss=  tensor(8.5116, grad_fn=<DivBackward0>)   , return=  16077.953125\n",
      "discReturns/1000= tensor([6.4173, 6.5452, 5.5306])\n",
      "actionProbs tensor([[0.3393, 0.3253, 0.3351, 0.3369],\n",
      "        [0.3313, 0.3346, 0.3347, 0.3331],\n",
      "        [0.3294, 0.3401, 0.3302, 0.3299]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.1817, 0.2163, 0.2985, 0.3034], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.2524, 0.2462, 0.2377, 0.2637], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.3150, 0.2631, 0.1929, 0.2290], grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "1000   actions:  tensor([3, 0, 1])\n",
      "loss=  tensor(8.1034, grad_fn=<DivBackward0>)   , return=  16128.5\n",
      "discReturns/1000= tensor([6.4204, 6.5859, 5.5493])\n",
      "actionProbs tensor([[0.2481, 0.3045, 0.4168, 0.3884],\n",
      "        [0.3336, 0.3355, 0.3213, 0.3267],\n",
      "        [0.4182, 0.3600, 0.2619, 0.2849]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.1334, 0.2362, 0.3270, 0.3034], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.2938, 0.2644, 0.2113, 0.2305], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.3979, 0.2562, 0.1596, 0.1863], grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "2000   actions:  tensor([1, 2, 0])\n",
      "loss=  tensor(8.1663, grad_fn=<DivBackward0>)   , return=  16097.0625\n",
      "discReturns/1000= tensor([6.4144, 6.5158, 5.5876])\n",
      "actionProbs tensor([[0.2371, 0.4195, 0.5818, 0.5352],\n",
      "        [0.3511, 0.3156, 0.2528, 0.2734],\n",
      "        [0.4118, 0.2649, 0.1654, 0.1913]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.1264, 0.3190, 0.3194, 0.2352], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.2714, 0.2118, 0.2268, 0.2900], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.3312, 0.1451, 0.1824, 0.3413], grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "3000   actions:  tensor([1, 2, 3])\n",
      "loss=  tensor(7.7956, grad_fn=<DivBackward0>)   , return=  16088.0625\n",
      "discReturns/1000= tensor([6.4140, 6.5140, 5.5786])\n",
      "actionProbs tensor([[0.2283, 0.5553, 0.5223, 0.3443],\n",
      "        [0.3600, 0.2707, 0.2723, 0.3118],\n",
      "        [0.4118, 0.1740, 0.2054, 0.3440]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.2482, 0.2621, 0.2458, 0.2438], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.0078, 0.5132, 0.1748, 0.3042], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.2996e-04, 6.7104e-01, 1.0558e-01, 2.2274e-01],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "4000   actions:  tensor([2, 3, 1])\n",
      "loss=  tensor(6.2015, grad_fn=<DivBackward0>)   , return=  16181.078125\n",
      "discReturns/1000= tensor([6.4200, 6.5586, 5.6428])\n",
      "actionProbs tensor([[9.9646e-01, 7.5082e-01, 9.1119e-01, 8.4861e-01],\n",
      "        [3.4226e-03, 1.6053e-01, 7.0757e-02, 1.1563e-01],\n",
      "        [1.1663e-04, 8.8657e-02, 1.8050e-02, 3.5764e-02]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.6987, 0.0778, 0.1138, 0.1097], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.2867, 0.1874, 0.2457, 0.2802], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.0299, 0.3304, 0.2827, 0.3570], grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "5000   actions:  tensor([0, 3, 2])\n",
      "loss=  tensor(7.0283, grad_fn=<DivBackward0>)   , return=  16071.078125\n",
      "discReturns/1000= tensor([6.4077, 6.4770, 5.6023])\n",
      "actionProbs tensor([[0.9024, 0.4797, 0.5484, 0.4976],\n",
      "        [0.0932, 0.2908, 0.2981, 0.3200],\n",
      "        [0.0043, 0.2295, 0.1535, 0.1824]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.4281, 0.1196, 0.1586, 0.2937], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.2674, 0.1681, 0.2319, 0.3326], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.1276, 0.2072, 0.3222, 0.3430], grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "6000   actions:  tensor([2, 3, 3])\n",
      "loss=  tensor(9.3096, grad_fn=<DivBackward0>)   , return=  16173.078125\n",
      "discReturns/1000= tensor([6.4197, 6.5570, 5.6348])\n",
      "actionProbs tensor([[0.5192, 0.2342, 0.2148, 0.2960],\n",
      "        [0.3081, 0.3128, 0.2983, 0.3183],\n",
      "        [0.1727, 0.4529, 0.4869, 0.3857]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.3398, 0.1476, 0.1862, 0.3263], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.2662, 0.1662, 0.2260, 0.3416], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.1597, 0.1825, 0.2953, 0.3625], grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "7000   actions:  tensor([3, 1, 2])\n",
      "loss=  tensor(8.3283, grad_fn=<DivBackward0>)   , return=  16161.8125\n",
      "discReturns/1000= tensor([6.4216, 6.5917, 5.5836])\n",
      "actionProbs tensor([[0.4162, 0.2694, 0.2361, 0.2880],\n",
      "        [0.3417, 0.3180, 0.3004, 0.3160],\n",
      "        [0.2421, 0.4126, 0.4635, 0.3960]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.0036, 0.0059, 0.0867, 0.9037], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.0407, 0.0646, 0.2431, 0.6516], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.1662, 0.3718, 0.2997, 0.1622], grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "8000   actions:  tensor([3, 3, 0])\n",
      "loss=  tensor(3.7994, grad_fn=<DivBackward0>)   , return=  16232.8125\n",
      "discReturns/1000= tensor([6.4232, 6.5995, 5.6626])\n",
      "actionProbs tensor([[0.0040, 0.0030, 0.0450, 0.3491],\n",
      "        [0.0600, 0.0434, 0.1674, 0.3337],\n",
      "        [0.9360, 0.9536, 0.7876, 0.3171]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.4876e-05, 9.3187e-04, 8.7202e-03, 9.9030e-01],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.0129, 0.0520, 0.1422, 0.7930], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.3535, 0.3230, 0.2566, 0.0670], grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "9000   actions:  tensor([3, 3, 0])\n",
      "loss=  tensor(2.6147, grad_fn=<DivBackward0>)   , return=  16232.8125\n",
      "discReturns/1000= tensor([6.4232, 6.5995, 5.6626])\n",
      "actionProbs tensor([[6.3213e-06, 1.4238e-04, 1.6296e-03, 2.8665e-01],\n",
      "        [2.5665e-03, 1.1246e-02, 3.7628e-02, 3.2510e-01],\n",
      "        [9.9743e-01, 9.8861e-01, 9.6074e-01, 3.8824e-01]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5217e-05, 3.0186e-04, 5.6817e-03, 9.9400e-01],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.0118, 0.0418, 0.1364, 0.8100], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.3650, 0.3637, 0.2124, 0.0588], grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "10000   actions:  tensor([3, 3, 2])\n",
      "loss=  tensor(2.9327, grad_fn=<DivBackward0>)   , return=  16228.8125\n",
      "discReturns/1000= tensor([6.4230, 6.5987, 5.6586])\n",
      "actionProbs tensor([[8.9273e-06, 1.7587e-04, 5.2892e-03, 5.6887e-01],\n",
      "        [4.1136e-03, 1.4426e-02, 7.5196e-02, 2.7456e-01],\n",
      "        [9.9588e-01, 9.8540e-01, 9.1952e-01, 1.5657e-01]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.2717e-05, 9.0861e-04, 2.7069e-03, 9.9635e-01],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.0107, 0.0507, 0.0994, 0.8392], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.2628, 0.2863, 0.3678, 0.0831], grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "11000   actions:  tensor([3, 3, 1])\n",
      "loss=  tensor(2.6499, grad_fn=<DivBackward0>)   , return=  16231.8125\n",
      "discReturns/1000= tensor([6.4231, 6.5993, 5.6616])\n",
      "actionProbs tensor([[2.2516e-05, 5.6284e-04, 1.2880e-03, 4.7417e-01],\n",
      "        [5.6598e-03, 2.4260e-02, 3.6513e-02, 3.0839e-01],\n",
      "        [9.9432e-01, 9.7518e-01, 9.6220e-01, 2.1744e-01]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([1.8378e-05, 6.0701e-04, 2.0308e-03, 9.9734e-01],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.0076, 0.0434, 0.0840, 0.8649], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.2351, 0.3016, 0.3613, 0.1021], grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "12000   actions:  tensor([3, 3, 2])\n",
      "loss=  tensor(2.6850, grad_fn=<DivBackward0>)   , return=  16228.8125\n",
      "discReturns/1000= tensor([6.4230, 6.5987, 5.6586])\n",
      "actionProbs tensor([[1.8482e-05, 4.6682e-04, 1.2835e-03, 4.8667e-01],\n",
      "        [5.5341e-03, 2.4013e-02, 3.8230e-02, 3.0380e-01],\n",
      "        [9.9445e-01, 9.7552e-01, 9.6049e-01, 2.0953e-01]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.3697, 0.4972, 0.1120, 0.0211], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2470e-01, 8.7203e-01, 3.2162e-03, 4.9112e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.0515e-02, 9.4913e-01, 3.5373e-04, 1.1714e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "13000   actions:  tensor([1, 0, 1])\n",
      "loss=  tensor(7.0830, grad_fn=<DivBackward0>)   , return=  16025.5625\n",
      "discReturns/1000= tensor([6.4122, 6.5047, 5.5121])\n",
      "actionProbs tensor([[9.9718e-01, 9.8445e-01, 9.9977e-01, 9.9998e-01],\n",
      "        [2.7010e-03, 1.3865e-02, 2.3050e-04, 1.8725e-05],\n",
      "        [1.2197e-04, 1.6822e-03, 2.8261e-06, 4.9786e-08]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.3182, 0.5391, 0.1194, 0.0233], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5509e-03, 9.9830e-01, 1.4989e-04, 1.8189e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.1629e-05, 9.9995e-01, 2.5145e-06, 5.5513e-09],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "14000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9848, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[9.9998e-01, 9.9152e-01, 9.9999e-01, 1.0000e+00],\n",
      "        [2.0585e-05, 7.7546e-03, 5.2999e-06, 3.3008e-07],\n",
      "        [6.3944e-08, 7.2479e-04, 8.2962e-09, 9.3999e-11]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.3036, 0.5525, 0.1215, 0.0224], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.2539e-04, 9.9963e-01, 4.1779e-05, 4.9783e-07],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.8154e-06, 9.9999e-01, 4.2360e-07, 9.7779e-10],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "15000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9711, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 9.9643e-01, 1.0000e+00, 1.0000e+00],\n",
      "        [1.9819e-06, 3.3333e-03, 6.3567e-07, 4.1076e-08],\n",
      "        [2.5657e-09, 2.4154e-04, 4.6686e-10, 5.8440e-12]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.2998, 0.5370, 0.1414, 0.0217], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3903e-04, 9.9984e-01, 2.3061e-05, 2.4225e-07],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.8420e-06, 1.0000e+00, 1.7909e-07, 3.8110e-10],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "16000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9668, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 9.9851e-01, 1.0000e+00, 1.0000e+00],\n",
      "        [3.5205e-07, 1.4113e-03, 1.2378e-07, 8.4585e-09],\n",
      "        [2.5367e-10, 7.6768e-05, 5.2276e-11, 7.2368e-13]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.3207, 0.5181, 0.1460, 0.0152], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.3543e-05, 9.9991e-01, 1.2442e-05, 9.3556e-08],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.5673e-07, 1.0000e+00, 7.5506e-08, 1.1750e-10],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "17000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9652, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 9.9928e-01, 1.0000e+00, 1.0000e+00],\n",
      "        [8.2480e-08, 6.9354e-04, 3.0638e-08, 2.2169e-09],\n",
      "        [3.6713e-11, 3.0005e-05, 8.0429e-12, 1.2045e-13]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.3383, 0.4909, 0.1582, 0.0127], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.8787e-05, 9.9995e-01, 6.9842e-06, 4.2598e-08],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.0504e-07, 1.0000e+00, 3.2688e-08, 4.1895e-11],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "18000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9645, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 9.9955e-01, 1.0000e+00, 1.0000e+00],\n",
      "        [2.4289e-08, 4.3134e-04, 9.3548e-09, 7.1231e-10],\n",
      "        [7.2215e-12, 1.6308e-05, 1.6553e-12, 2.6486e-14]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.1905, 0.7251, 0.0794, 0.0051], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.9574e-05, 9.9997e-01, 1.4276e-06, 1.8202e-08],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.1287e-07, 1.0000e+00, 3.5025e-09, 1.5485e-11],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "19000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9647, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 9.9951e-01, 1.0000e+00, 1.0000e+00],\n",
      "        [5.3153e-08, 4.7185e-04, 6.1542e-09, 1.2312e-09],\n",
      "        [1.3510e-11, 1.6663e-05, 5.3320e-13, 3.6991e-14]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.1986, 0.7299, 0.0673, 0.0042], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.8482e-06, 1.0000e+00, 2.6069e-07, 4.6258e-09],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.5360e-09, 1.0000e+00, 2.6356e-10, 1.9015e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "20000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9638, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 9.9995e-01, 1.0000e+00, 1.0000e+00],\n",
      "        [3.3424e-10, 4.9210e-05, 1.3919e-10, 3.9621e-11],\n",
      "        [7.4174e-15, 5.7078e-07, 1.6322e-15, 1.8890e-16]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.1972, 0.7426, 0.0568, 0.0035], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.9374e-07, 1.0000e+00, 7.9414e-08, 1.4723e-09],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.0885e-10, 1.0000e+00, 4.1539e-11, 3.1162e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "21000   actions:  tensor([0, 1, 1])\n",
      "loss=  tensor(2.9604, grad_fn=<DivBackward0>)   , return=  16007.453125\n",
      "discReturns/1000= tensor([6.4064, 6.4707, 5.5306])\n",
      "actionProbs tensor([[1.0000e+00, 9.9999e-01, 1.0000e+00, 1.0000e+00],\n",
      "        [2.3388e-11, 1.2577e-05, 1.3068e-11, 3.9356e-12],\n",
      "        [1.4395e-16, 7.5111e-08, 4.0825e-17, 4.9747e-18]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.2287, 0.7100, 0.0577, 0.0036], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.1899e-07, 1.0000e+00, 3.2236e-08, 6.1867e-10],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4805e-10, 1.0000e+00, 1.0156e-11, 7.8457e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "22000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.3540e-12, 4.9339e-06, 1.9585e-12, 5.9801e-13],\n",
      "        [9.0227e-18, 1.9633e-08, 2.4552e-18, 3.0177e-19]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([0.2510, 0.6890, 0.0567, 0.0033], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0986e-07, 1.0000e+00, 1.4619e-08, 2.6538e-10],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.1433e-11, 1.0000e+00, 2.8927e-12, 2.0861e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "23000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [7.5219e-13, 2.4944e-06, 4.4320e-13, 1.3669e-13],\n",
      "        [1.0287e-18, 7.2863e-09, 2.5616e-19, 3.1387e-20]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.2543, 0.6870, 0.0556, 0.0031], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.7060e-08, 1.0000e+00, 7.5801e-09, 1.3230e-10],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.9835e-11, 1.0000e+00, 1.0288e-12, 7.0488e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "24000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8796e-13, 1.2191e-06, 1.1417e-13, 3.5628e-14],\n",
      "        [1.3766e-19, 2.5685e-09, 3.2646e-20, 3.9993e-21]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.2706, 0.6732, 0.0517, 0.0045], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.2764e-08, 1.0000e+00, 3.8387e-09, 1.0760e-10],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.1982e-12, 1.0000e+00, 3.3819e-13, 3.6984e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "25000   actions:  tensor([0, 1, 1])\n",
      "loss=  tensor(2.9604, grad_fn=<DivBackward0>)   , return=  16007.453125\n",
      "discReturns/1000= tensor([6.4064, 6.4707, 5.5306])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [5.5756e-14, 6.8400e-07, 3.4187e-14, 1.1091e-14],\n",
      "        [2.1841e-20, 1.0708e-09, 4.7151e-21, 5.9682e-22]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.2393, 0.7125, 0.0448, 0.0034], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.0036e-08, 1.0000e+00, 2.4947e-09, 6.1273e-11],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.6171e-12, 1.0000e+00, 2.0062e-13, 1.9072e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "26000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.9218e-14, 3.2208e-07, 1.2767e-14, 4.1169e-15],\n",
      "        [5.0811e-21, 3.6954e-10, 1.1780e-21, 1.4703e-22]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.2369, 0.7325, 0.0286, 0.0020], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.7278e-08, 1.0000e+00, 1.5155e-09, 3.3104e-11],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.8506e-12, 1.0000e+00, 1.1481e-13, 9.5265e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "27000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [8.5239e-15, 1.5954e-07, 6.1895e-15, 1.9765e-15],\n",
      "        [1.5847e-21, 1.3308e-10, 3.9114e-22, 4.7447e-23]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.1775, 0.8058, 0.0157, 0.0010], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0847e-08, 1.0000e+00, 7.4647e-10, 1.4703e-11],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.2394e-12, 1.0000e+00, 4.9859e-14, 3.6364e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "28000   actions:  tensor([0, 1, 1])\n",
      "loss=  tensor(2.9604, grad_fn=<DivBackward0>)   , return=  16007.453125\n",
      "discReturns/1000= tensor([6.4064, 6.4707, 5.5306])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.2649e-15, 8.6615e-08, 3.3111e-15, 1.0544e-15],\n",
      "        [5.3176e-22, 5.2308e-11, 1.3356e-22, 1.5748e-23]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1566e-01, 8.7251e-01, 1.1127e-02, 6.9700e-04],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.5685e-09, 1.0000e+00, 4.9123e-10, 9.7605e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3417e-12, 1.0000e+00, 3.2383e-14, 2.3767e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "29000   actions:  tensor([0, 1, 1])\n",
      "loss=  tensor(2.9604, grad_fn=<DivBackward0>)   , return=  16007.453125\n",
      "discReturns/1000= tensor([6.4064, 6.4707, 5.5306])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [2.1695e-15, 4.3784e-08, 1.6866e-15, 5.3497e-16],\n",
      "        [1.9010e-22, 1.8783e-11, 4.7697e-23, 5.5883e-24]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.5606e-02, 9.0454e-01, 9.1949e-03, 6.5668e-04],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.6807e-09, 1.0000e+00, 3.5039e-10, 7.6765e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.8114e-13, 1.0000e+00, 2.3749e-14, 1.9406e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "30000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.1057e-15, 2.2356e-08, 7.7059e-16, 2.3639e-16],\n",
      "        [7.3431e-23, 7.0831e-12, 1.6548e-23, 1.8933e-24]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.6920e-02, 9.3530e-01, 7.1973e-03, 5.8179e-04],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.0711e-09, 1.0000e+00, 2.4896e-10, 6.0438e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.2358e-13, 1.0000e+00, 1.6418e-14, 1.4798e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "31000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [6.1040e-16, 1.2096e-08, 3.9133e-16, 1.1752e-16],\n",
      "        [2.7940e-23, 2.7268e-12, 5.8176e-24, 6.4870e-25]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.6236e-02, 9.5781e-01, 5.4622e-03, 4.9332e-04],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.9294e-09, 1.0000e+00, 1.7680e-10, 4.7449e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.7823e-13, 1.0000e+00, 1.1446e-14, 1.1367e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "32000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.2512e-16, 6.3751e-09, 1.9764e-16, 5.8731e-17],\n",
      "        [1.0084e-23, 1.0087e-12, 2.0245e-24, 2.2260e-25]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.2445e-02, 9.7299e-01, 4.1493e-03, 4.1741e-04],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1523e-09, 1.0000e+00, 1.2314e-10, 3.6802e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.1408e-13, 1.0000e+00, 7.7025e-15, 8.5867e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "33000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8553e-16, 3.7141e-09, 1.0725e-16, 3.1862e-17],\n",
      "        [3.9733e-24, 4.2814e-13, 7.7330e-25, 8.5693e-26]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([1.3699e-02, 9.8299e-01, 2.9732e-03, 3.3332e-04],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.8968e-10, 1.0000e+00, 8.4996e-11, 2.9097e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2317e-13, 1.0000e+00, 5.2250e-15, 6.8599e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "34000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.0025e-16, 2.0257e-09, 5.6925e-17, 1.7383e-17],\n",
      "        [1.4567e-24, 1.6482e-13, 2.8472e-25, 3.3344e-26]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.5300e-03, 9.9018e-01, 2.0273e-03, 2.5946e-04],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.6582e-10, 1.0000e+00, 5.3643e-11, 2.1657e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.1696e-14, 1.0000e+00, 3.1936e-15, 5.1250e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "35000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [6.1553e-17, 1.2796e-09, 3.3525e-17, 1.0576e-17],\n",
      "        [6.3323e-25, 7.8050e-14, 1.2175e-25, 1.5265e-26]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.1973e-03, 9.9279e-01, 1.7551e-03, 2.5455e-04],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.1528e-10, 1.0000e+00, 5.9251e-11, 2.8249e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.7870e-14, 1.0000e+00, 4.0557e-15, 7.9765e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "36000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.0994e-17, 6.8067e-10, 2.2813e-17, 7.4994e-18],\n",
      "        [3.1642e-25, 2.8624e-14, 6.5669e-26, 8.9050e-27]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.9267e-03, 9.9566e-01, 1.2145e-03, 1.9928e-04],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.6421e-10, 1.0000e+00, 3.7780e-11, 2.1187e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.8044e-14, 1.0000e+00, 2.4962e-15, 5.9901e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "37000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [2.3986e-17, 4.2937e-10, 1.3299e-17, 4.5452e-18],\n",
      "        [1.2932e-25, 1.3555e-14, 2.7740e-26, 4.0568e-27]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4849e-03, 9.9765e-01, 7.2241e-04, 1.3922e-04],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.4091e-11, 1.0000e+00, 1.3612e-11, 9.8666e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.1952e-15, 1.0000e+00, 6.9753e-16, 2.3141e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "38000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.2673e-17, 3.4871e-10, 6.5552e-18, 2.4656e-18],\n",
      "        [4.6326e-26, 9.5829e-15, 9.2312e-27, 1.5892e-27]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3101e-03, 9.9767e-01, 8.4527e-04, 1.7901e-04],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.7293e-11, 1.0000e+00, 2.7787e-11, 2.2622e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3089e-14, 1.0000e+00, 1.9747e-15, 7.5382e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "39000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.0597e-17, 1.8003e-10, 5.9046e-18, 2.2697e-18],\n",
      "        [3.3695e-26, 3.3805e-15, 7.8789e-27, 1.4202e-27]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.8588e-04, 9.9900e-01, 4.1200e-04, 1.0480e-04],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.7074e-11, 1.0000e+00, 7.5580e-12, 7.8085e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.1387e-15, 1.0000e+00, 4.0687e-16, 2.0817e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "40000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [6.1889e-18, 1.7629e-10, 3.2308e-18, 1.3122e-18],\n",
      "        [1.3898e-26, 3.1605e-15, 3.1180e-27, 6.2713e-28]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.0990e-04, 9.9903e-01, 4.3681e-04, 1.1960e-04],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.1737e-11, 1.0000e+00, 1.2825e-11, 1.4480e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.4031e-15, 1.0000e+00, 9.3137e-16, 5.3288e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "41000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [5.3406e-18, 1.0081e-10, 2.9569e-18, 1.2193e-18],\n",
      "        [1.0987e-26, 1.3246e-15, 2.8216e-27, 5.8963e-28]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.4064e-04, 9.9934e-01, 3.0372e-04, 1.1202e-04],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.6588e-12, 1.0000e+00, 3.6420e-12, 6.8190e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.0277e-16, 1.0000e+00, 1.5348e-16, 1.6749e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "42000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.9000e-18, 8.0850e-11, 9.6885e-19, 4.9184e-19],\n",
      "        [1.6343e-27, 7.8275e-16, 3.9528e-28, 1.1696e-28]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.8178e-04, 9.9945e-01, 2.6597e-04, 1.0324e-04],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.8803e-12, 1.0000e+00, 4.5437e-12, 8.9914e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.8361e-16, 1.0000e+00, 2.6232e-16, 3.0829e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "43000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.7176e-18, 5.3125e-11, 9.0706e-19, 4.6242e-19],\n",
      "        [1.7358e-27, 4.6183e-16, 4.5523e-28, 1.3783e-28]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([1.5037e-04, 9.9951e-01, 2.4435e-04, 9.8391e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.7690e-12, 1.0000e+00, 5.9524e-12, 1.2235e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0255e-15, 1.0000e+00, 4.6344e-16, 5.7392e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "44000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.5880e-18, 3.5295e-11, 8.5936e-19, 4.3866e-19],\n",
      "        [1.8794e-27, 2.7572e-16, 5.2266e-28, 1.6075e-28]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3897e-04, 9.9952e-01, 2.4183e-04, 9.9783e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.6783e-12, 1.0000e+00, 8.3102e-12, 1.7513e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.6344e-15, 1.0000e+00, 8.3137e-16, 1.0685e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "45000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.4949e-18, 2.3949e-11, 8.2259e-19, 4.2013e-19],\n",
      "        [1.8783e-27, 1.5978e-16, 5.4903e-28, 1.7102e-28]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.7100e-04, 9.9931e-01, 3.6235e-04, 1.5864e-04],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.0651e-12, 1.0000e+00, 3.5875e-12, 7.5840e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.8209e-16, 1.0000e+00, 1.6320e-16, 2.0493e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "46000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [5.2062e-19, 2.1916e-11, 2.1683e-19, 1.0470e-19],\n",
      "        [2.2877e-28, 1.0246e-16, 4.6113e-29, 1.3226e-29]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3093e-04, 9.9945e-01, 2.9096e-04, 1.2960e-04],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.5180e-12, 1.0000e+00, 3.2933e-12, 7.0645e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.8415e-16, 1.0000e+00, 1.7893e-16, 2.3057e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "47000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.8947e-19, 1.8226e-11, 2.0618e-19, 9.9295e-20],\n",
      "        [2.5283e-28, 8.6218e-17, 5.2990e-29, 1.5331e-29]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0591e-04, 9.9954e-01, 2.4488e-04, 1.1067e-04],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.3339e-12, 1.0000e+00, 3.2774e-12, 7.1098e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.3171e-16, 1.0000e+00, 2.1635e-16, 2.8482e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "48000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.6056e-19, 1.4638e-11, 1.9582e-19, 9.3996e-20],\n",
      "        [2.8178e-28, 6.9162e-17, 6.1076e-29, 1.7792e-29]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.1836e-05, 9.9959e-01, 2.1929e-04, 1.0029e-04],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.4910e-12, 1.0000e+00, 3.5707e-12, 7.8113e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.4168e-16, 1.0000e+00, 2.8820e-16, 3.8595e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "49000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.3474e-19, 1.1441e-11, 1.8621e-19, 8.9079e-20],\n",
      "        [3.1279e-28, 5.3053e-17, 6.9696e-29, 2.0409e-29]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.5961e-05, 9.9961e-01, 2.1013e-04, 9.6930e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.0257e-12, 1.0000e+00, 4.2387e-12, 9.3257e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.4091e-16, 1.0000e+00, 4.1346e-16, 5.6113e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "50000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.1360e-19, 8.8351e-12, 1.7815e-19, 8.4970e-20],\n",
      "        [3.3531e-28, 3.8918e-17, 7.6544e-29, 2.2521e-29]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.6876e-05, 9.9960e-01, 2.1569e-04, 1.0005e-04],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.0597e-12, 1.0000e+00, 5.4333e-12, 1.2000e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0691e-15, 1.0000e+00, 6.1952e-16, 8.4960e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "51000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.9729e-19, 6.8243e-12, 1.7183e-19, 8.1818e-20],\n",
      "        [3.3263e-28, 2.7039e-17, 7.7632e-29, 2.2953e-29]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.0607e-05, 9.9958e-01, 2.2777e-04, 1.0611e-04],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.5486e-12, 1.0000e+00, 7.1428e-12, 1.5822e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5769e-15, 1.0000e+00, 9.4119e-16, 1.3012e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "52000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.8407e-19, 5.3162e-12, 1.6665e-19, 7.9236e-20],\n",
      "        [3.2933e-28, 1.8931e-17, 7.8196e-29, 2.3205e-29]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.1508e-05, 9.9975e-01, 1.1844e-04, 9.3568e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1663e-13, 1.0000e+00, 1.6288e-13, 1.0591e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.1825e-18, 1.0000e+00, 4.3018e-18, 2.3474e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "53000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [2.9527e-20, 1.0511e-11, 1.4452e-20, 1.1895e-20],\n",
      "        [4.8520e-30, 3.8872e-17, 1.4115e-30, 9.7495e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([3.3723e-05, 9.9979e-01, 9.8618e-05, 7.8933e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1077e-13, 1.0000e+00, 1.5952e-13, 1.0467e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.2282e-18, 1.0000e+00, 5.4193e-18, 3.0158e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "54000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [2.7200e-20, 8.2827e-12, 1.3394e-20, 1.0981e-20],\n",
      "        [6.0963e-30, 3.3016e-17, 1.8139e-30, 1.2612e-30]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.0493e-05, 9.9981e-01, 9.0659e-05, 7.3363e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2102e-13, 1.0000e+00, 1.7794e-13, 1.1774e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.2069e-18, 1.0000e+00, 7.4194e-18, 4.1953e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "55000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [2.5698e-20, 6.4765e-12, 1.2709e-20, 1.0392e-20],\n",
      "        [6.8995e-30, 2.5640e-17, 2.0979e-30, 1.4660e-30]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.9635e-05, 9.9981e-01, 8.9362e-05, 7.3031e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4451e-13, 1.0000e+00, 2.1626e-13, 1.4426e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1495e-17, 1.0000e+00, 1.0715e-17, 6.1373e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "56000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [2.4626e-20, 5.0510e-12, 1.2221e-20, 9.9752e-21],\n",
      "        [7.3764e-30, 1.9020e-17, 2.2802e-30, 1.5981e-30]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.0075e-05, 9.9980e-01, 9.1933e-05, 7.5801e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.8058e-13, 1.0000e+00, 2.7474e-13, 1.8468e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.6533e-17, 1.0000e+00, 1.5789e-17, 9.1363e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "57000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [2.3837e-20, 3.9708e-12, 1.1865e-20, 9.6724e-21],\n",
      "        [7.6707e-30, 1.3956e-17, 2.3965e-30, 1.6818e-30]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.1326e-05, 9.9979e-01, 9.6814e-05, 8.0391e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.2950e-13, 1.0000e+00, 3.5386e-13, 2.3934e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.3738e-17, 1.0000e+00, 2.3117e-17, 1.3486e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "58000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [2.3243e-20, 3.1733e-12, 1.1596e-20, 9.4458e-21],\n",
      "        [7.8112e-30, 1.0310e-17, 2.4613e-30, 1.7293e-30]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.3119e-05, 9.9978e-01, 1.0313e-04, 8.6070e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.9159e-13, 1.0000e+00, 4.5381e-13, 3.0836e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.3418e-17, 1.0000e+00, 3.3068e-17, 1.9421e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "59000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [2.2794e-20, 2.5895e-12, 1.1392e-20, 9.2751e-21],\n",
      "        [7.8004e-30, 7.7323e-18, 2.4788e-30, 1.7444e-30]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.5152e-05, 9.9976e-01, 1.1008e-04, 9.2242e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.6534e-13, 1.0000e+00, 5.7263e-13, 3.9050e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.5727e-17, 1.0000e+00, 4.5846e-17, 2.7076e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "60000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [2.2439e-20, 2.1595e-12, 1.1230e-20, 9.1397e-21],\n",
      "        [7.7311e-30, 5.9445e-18, 2.4751e-30, 1.7445e-30]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.7201e-05, 9.9975e-01, 1.1706e-04, 9.8419e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.4838e-13, 1.0000e+00, 7.0698e-13, 4.8360e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.0693e-17, 1.0000e+00, 6.1530e-17, 3.6509e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "61000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [2.2140e-20, 1.8373e-12, 1.1093e-20, 9.0256e-21],\n",
      "        [7.6722e-30, 4.7038e-18, 2.4718e-30, 1.7445e-30]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.9207e-05, 9.9973e-01, 1.2387e-04, 1.0445e-04],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.3938e-13, 1.0000e+00, 8.5476e-13, 5.8624e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.8274e-17, 1.0000e+00, 8.0113e-17, 4.7731e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "62000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [2.1882e-20, 1.5910e-12, 1.0975e-20, 8.9273e-21],\n",
      "        [7.6199e-30, 3.8178e-18, 2.4684e-30, 1.7441e-30]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.1149e-05, 9.9972e-01, 1.3048e-04, 1.1030e-04],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.3723e-13, 1.0000e+00, 1.0144e-12, 6.9729e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.8411e-17, 1.0000e+00, 1.0157e-16, 6.0729e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "63000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [2.1661e-20, 1.3992e-12, 1.0874e-20, 8.8429e-21],\n",
      "        [7.5768e-30, 3.1690e-18, 2.4663e-30, 1.7444e-30]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([4.3010e-05, 9.9970e-01, 1.3682e-04, 1.1592e-04],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.4081e-13, 1.0000e+00, 1.1840e-12, 8.1555e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2097e-16, 1.0000e+00, 1.2580e-16, 7.5451e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "64000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [2.1463e-20, 1.2465e-12, 1.0783e-20, 8.7668e-21],\n",
      "        [7.5362e-30, 2.6801e-18, 2.4635e-30, 1.7439e-30]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.4782e-05, 9.9969e-01, 1.4285e-04, 1.2127e-04],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.4920e-13, 1.0000e+00, 1.3618e-12, 9.3972e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4584e-16, 1.0000e+00, 1.5266e-16, 9.1813e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "65000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [2.1286e-20, 1.1228e-12, 1.0701e-20, 8.6985e-21],\n",
      "        [7.5003e-30, 2.3037e-18, 2.4613e-30, 1.7437e-30]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.6480e-05, 9.9968e-01, 1.4863e-04, 1.2641e-04],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.6227e-13, 1.0000e+00, 1.5478e-12, 1.0698e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.7305e-16, 1.0000e+00, 1.8220e-16, 1.0985e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "66000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [2.1133e-20, 1.0211e-12, 1.0630e-20, 8.6391e-21],\n",
      "        [7.4732e-30, 2.0079e-18, 2.4606e-30, 1.7443e-30]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.8127e-05, 9.9967e-01, 1.5423e-04, 1.3138e-04],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0798e-12, 1.0000e+00, 1.7415e-12, 1.2054e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.0245e-16, 1.0000e+00, 2.1427e-16, 1.2947e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "67000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [2.0996e-20, 9.3613e-13, 1.0567e-20, 8.5859e-21],\n",
      "        [7.4418e-30, 1.7697e-18, 2.4577e-30, 1.7433e-30]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.9731e-05, 9.9965e-01, 1.5972e-04, 1.3626e-04],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2018e-12, 1.0000e+00, 1.9436e-12, 1.3471e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.3405e-16, 1.0000e+00, 2.4898e-16, 1.5075e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "68000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [2.0870e-20, 8.6389e-13, 1.0509e-20, 8.5380e-21],\n",
      "        [7.4018e-30, 1.5732e-18, 2.4516e-30, 1.7400e-30]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.1271e-05, 9.9964e-01, 1.6501e-04, 1.4098e-04],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3273e-12, 1.0000e+00, 2.1522e-12, 1.4938e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.6772e-16, 1.0000e+00, 2.8620e-16, 1.7364e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "69000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [2.0750e-20, 8.0180e-13, 1.0454e-20, 8.4924e-21],\n",
      "        [7.3621e-30, 1.4104e-18, 2.4453e-30, 1.7365e-30]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.2752e-05, 9.9963e-01, 1.7013e-04, 1.4554e-04],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4558e-12, 1.0000e+00, 2.3667e-12, 1.6447e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.0336e-16, 1.0000e+00, 3.2581e-16, 1.9805e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "70000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [2.0634e-20, 7.4794e-13, 1.0401e-20, 8.4487e-21],\n",
      "        [7.3218e-30, 1.2737e-18, 2.4383e-30, 1.7326e-30]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.4191e-05, 9.9962e-01, 1.7511e-04, 1.5000e-04],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5877e-12, 1.0000e+00, 2.5876e-12, 1.8003e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.4106e-16, 1.0000e+00, 3.6798e-16, 2.2409e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "71000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [2.0525e-20, 7.0083e-13, 1.0352e-20, 8.4083e-21],\n",
      "        [7.2840e-30, 1.1578e-18, 2.4320e-30, 1.7290e-30]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.5587e-05, 9.9961e-01, 1.7994e-04, 1.5432e-04],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.7230e-12, 1.0000e+00, 2.8144e-12, 1.9603e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.8088e-16, 1.0000e+00, 4.1267e-16, 2.5173e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "72000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [2.0426e-20, 6.5926e-13, 1.0307e-20, 8.3715e-21],\n",
      "        [7.2504e-30, 1.0586e-18, 2.4268e-30, 1.7261e-30]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.6941e-05, 9.9960e-01, 1.8464e-04, 1.5852e-04],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.8616e-12, 1.0000e+00, 3.0475e-12, 2.1249e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.2289e-16, 1.0000e+00, 4.6003e-16, 2.8106e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "73000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [2.0338e-20, 6.2232e-13, 1.0268e-20, 8.3386e-21],\n",
      "        [7.2228e-30, 9.7290e-19, 2.4230e-30, 1.7242e-30]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([5.8235e-05, 9.9959e-01, 1.8916e-04, 1.6258e-04],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.0022e-12, 1.0000e+00, 3.2847e-12, 2.2927e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.6664e-16, 1.0000e+00, 5.0962e-16, 3.1184e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "74000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [2.0255e-20, 5.8940e-13, 1.0231e-20, 8.3079e-21],\n",
      "        [7.1973e-30, 8.9857e-19, 2.4199e-30, 1.7228e-30]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.9513e-05, 9.9958e-01, 1.9362e-04, 1.6659e-04],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.1464e-12, 1.0000e+00, 3.5287e-12, 2.4654e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.1266e-16, 1.0000e+00, 5.6197e-16, 3.4439e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "75000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [2.0179e-20, 5.5973e-13, 1.0197e-20, 8.2802e-21],\n",
      "        [7.1748e-30, 8.3324e-19, 2.4175e-30, 1.7218e-30]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.0760e-05, 9.9957e-01, 1.9797e-04, 1.7051e-04],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.2937e-12, 1.0000e+00, 3.7781e-12, 2.6422e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.6072e-16, 1.0000e+00, 6.1683e-16, 3.7856e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "76000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [2.0109e-20, 5.3291e-13, 1.0166e-20, 8.2544e-21],\n",
      "        [7.1539e-30, 7.7554e-19, 2.4153e-30, 1.7210e-30]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.1969e-05, 9.9956e-01, 2.0221e-04, 1.7433e-04],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.4431e-12, 1.0000e+00, 4.0321e-12, 2.8225e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.1068e-16, 1.0000e+00, 6.7415e-16, 4.1432e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "77000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [2.0040e-20, 5.0854e-13, 1.0136e-20, 8.2301e-21],\n",
      "        [7.1345e-30, 7.2430e-19, 2.4137e-30, 1.7207e-30]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.3138e-05, 9.9955e-01, 2.0634e-04, 1.7805e-04],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.5944e-12, 1.0000e+00, 4.2905e-12, 3.0060e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.6238e-16, 1.0000e+00, 7.3385e-16, 4.5160e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "78000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.9974e-20, 4.8629e-13, 1.0107e-20, 8.2064e-21],\n",
      "        [7.1153e-30, 6.7852e-19, 2.4121e-30, 1.7202e-30]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.4299e-05, 9.9954e-01, 2.1043e-04, 1.8174e-04],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.7500e-12, 1.0000e+00, 4.5559e-12, 3.1946e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.1663e-16, 1.0000e+00, 7.9653e-16, 4.9080e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "79000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.9909e-20, 4.6571e-13, 1.0078e-20, 8.1828e-21],\n",
      "        [7.0966e-30, 6.3703e-19, 2.4102e-30, 1.7196e-30]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.5427e-05, 9.9953e-01, 2.1440e-04, 1.8532e-04],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.9065e-12, 1.0000e+00, 4.8230e-12, 3.3846e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.7227e-16, 1.0000e+00, 8.6097e-16, 5.3113e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "80000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.9847e-20, 4.4699e-13, 1.0051e-20, 8.1599e-21],\n",
      "        [7.0790e-30, 6.0002e-19, 2.4084e-30, 1.7189e-30]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.6548e-05, 9.9953e-01, 2.1836e-04, 1.8890e-04],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.0667e-12, 1.0000e+00, 5.0973e-12, 3.5798e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.3028e-16, 1.0000e+00, 9.2836e-16, 5.7337e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "81000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.9787e-20, 4.2957e-13, 1.0023e-20, 8.1369e-21],\n",
      "        [7.0611e-30, 5.6623e-19, 2.4062e-30, 1.7179e-30]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.7644e-05, 9.9952e-01, 2.2222e-04, 1.9239e-04],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.2291e-12, 1.0000e+00, 5.3753e-12, 3.7779e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.9012e-16, 1.0000e+00, 9.9801e-16, 6.1707e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "82000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.9727e-20, 4.1344e-13, 9.9960e-21, 8.1147e-21],\n",
      "        [7.0423e-30, 5.3543e-19, 2.4035e-30, 1.7165e-30]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.8694e-05, 9.9951e-01, 2.2590e-04, 1.9572e-04],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.3914e-12, 1.0000e+00, 5.6529e-12, 3.9757e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.5106e-16, 1.0000e+00, 1.0690e-15, 6.6166e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "83000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.9669e-20, 3.9859e-13, 9.9696e-21, 8.0929e-21],\n",
      "        [7.0243e-30, 5.0760e-19, 2.4009e-30, 1.7152e-30]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([6.9756e-05, 9.9950e-01, 2.2961e-04, 1.9907e-04],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.5586e-12, 1.0000e+00, 5.9386e-12, 4.1793e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0148e-15, 1.0000e+00, 1.1433e-15, 7.0831e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "84000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.9613e-20, 3.8465e-13, 9.9438e-21, 8.0714e-21],\n",
      "        [7.0071e-30, 4.8190e-19, 2.3983e-30, 1.7138e-30]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.0822e-05, 9.9949e-01, 2.3333e-04, 2.0243e-04],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.7300e-12, 1.0000e+00, 6.2320e-12, 4.3885e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0811e-15, 1.0000e+00, 1.2208e-15, 7.5705e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "85000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.9558e-20, 3.7153e-13, 9.9181e-21, 8.0501e-21],\n",
      "        [6.9893e-30, 4.5808e-19, 2.3955e-30, 1.7123e-30]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.1818e-05, 9.9949e-01, 2.3681e-04, 2.0558e-04],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.8988e-12, 1.0000e+00, 6.5209e-12, 4.5946e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1477e-15, 1.0000e+00, 1.2986e-15, 8.0604e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "86000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.9505e-20, 3.5947e-13, 9.8934e-21, 8.0297e-21],\n",
      "        [6.9727e-30, 4.3655e-19, 2.3928e-30, 1.7107e-30]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.2805e-05, 9.9948e-01, 2.4027e-04, 2.0872e-04],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.0704e-12, 1.0000e+00, 6.8148e-12, 4.8044e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2161e-15, 1.0000e+00, 1.3785e-15, 8.5637e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "87000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.9456e-20, 3.4818e-13, 9.8702e-21, 8.0103e-21],\n",
      "        [6.9539e-30, 4.1655e-19, 2.3887e-30, 1.7082e-30]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.3813e-05, 9.9947e-01, 2.4375e-04, 2.1187e-04],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.2473e-12, 1.0000e+00, 7.1167e-12, 5.0199e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2874e-15, 1.0000e+00, 1.4617e-15, 9.0868e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "88000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.9409e-20, 3.3748e-13, 9.8478e-21, 7.9916e-21],\n",
      "        [6.9353e-30, 3.9785e-19, 2.3845e-30, 1.7054e-30]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.4810e-05, 9.9946e-01, 2.4721e-04, 2.1499e-04],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.4267e-12, 1.0000e+00, 7.4232e-12, 5.2387e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3607e-15, 1.0000e+00, 1.5473e-15, 9.6263e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "89000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.9362e-20, 3.2739e-13, 9.8257e-21, 7.9733e-21],\n",
      "        [6.9167e-30, 3.8047e-19, 2.3802e-30, 1.7027e-30]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.5816e-05, 9.9946e-01, 2.5067e-04, 2.1811e-04],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.6106e-12, 1.0000e+00, 7.7368e-12, 5.4625e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4369e-15, 1.0000e+00, 1.6362e-15, 1.0186e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "90000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.9317e-20, 3.1781e-13, 9.8039e-21, 7.9551e-21],\n",
      "        [6.8990e-30, 3.6421e-19, 2.3760e-30, 1.7000e-30]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.8372e-06, 9.9995e-01, 2.4608e-05, 1.7789e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.5244e-14, 1.0000e+00, 5.9721e-14, 3.2052e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1065e-18, 1.0000e+00, 2.1090e-18, 9.1354e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "91000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.6780e-21, 1.2671e-12, 3.0749e-21, 2.2830e-21],\n",
      "        [1.6216e-31, 1.0021e-18, 8.5878e-32, 5.1462e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.8165e-06, 9.9995e-01, 2.4625e-05, 1.7816e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.5961e-14, 1.0000e+00, 6.1723e-14, 3.3141e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1732e-18, 1.0000e+00, 2.2529e-18, 9.7769e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "92000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.6212e-21, 1.2134e-12, 3.0413e-21, 2.2571e-21],\n",
      "        [1.6455e-31, 9.5612e-19, 8.7467e-32, 5.2466e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.8445e-06, 9.9995e-01, 2.4813e-05, 1.7971e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.7274e-14, 1.0000e+00, 6.5127e-14, 3.4993e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2831e-18, 1.0000e+00, 2.4807e-18, 1.0792e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "93000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.5731e-21, 1.1477e-12, 3.0122e-21, 2.2346e-21],\n",
      "        [1.6845e-31, 8.9861e-19, 8.9833e-32, 5.3958e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([6.9040e-06, 9.9995e-01, 2.5114e-05, 1.8207e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.9055e-14, 1.0000e+00, 6.9667e-14, 3.7455e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4310e-18, 1.0000e+00, 2.7844e-18, 1.2141e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "94000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.5281e-21, 1.0760e-12, 2.9848e-21, 2.2134e-21],\n",
      "        [1.7295e-31, 8.3451e-19, 9.2516e-32, 5.5644e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.9955e-06, 9.9995e-01, 2.5527e-05, 1.8524e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.1299e-14, 1.0000e+00, 7.5337e-14, 4.0522e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.6192e-18, 1.0000e+00, 3.1697e-18, 1.3852e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "95000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.4851e-21, 1.0025e-12, 2.9585e-21, 2.1929e-21],\n",
      "        [1.7772e-31, 7.6786e-19, 9.5339e-32, 5.7414e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.1145e-06, 9.9995e-01, 2.6036e-05, 1.8910e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.3967e-14, 1.0000e+00, 8.2046e-14, 4.4148e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.8484e-18, 1.0000e+00, 3.6385e-18, 1.5933e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "96000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.4438e-21, 9.3082e-13, 2.9331e-21, 2.1731e-21],\n",
      "        [1.8252e-31, 7.0255e-19, 9.8173e-32, 5.9192e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.2494e-06, 9.9995e-01, 2.6604e-05, 1.9338e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.6969e-14, 1.0000e+00, 8.9600e-14, 4.8233e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.1160e-18, 1.0000e+00, 4.1876e-18, 1.8374e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "97000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.4033e-21, 8.6349e-13, 2.9080e-21, 2.1535e-21],\n",
      "        [1.8727e-31, 6.4160e-19, 1.0099e-31, 6.0958e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.3917e-06, 9.9995e-01, 2.7201e-05, 1.9788e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.0217e-14, 1.0000e+00, 9.7803e-14, 5.2669e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.4175e-18, 1.0000e+00, 4.8098e-18, 2.1145e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "98000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.3653e-21, 8.0237e-13, 2.8848e-21, 2.1354e-21],\n",
      "        [1.9191e-31, 5.8680e-19, 1.0376e-31, 6.2700e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.5373e-06, 9.9994e-01, 2.7813e-05, 2.0250e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.3658e-14, 1.0000e+00, 1.0653e-13, 5.7392e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.7500e-18, 1.0000e+00, 5.5005e-18, 2.4227e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "99000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.3306e-21, 7.4767e-13, 2.8636e-21, 2.1190e-21],\n",
      "        [1.9638e-31, 5.3827e-19, 1.0645e-31, 6.4393e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.6871e-06, 9.9994e-01, 2.8439e-05, 2.0721e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.7273e-14, 1.0000e+00, 1.1572e-13, 6.2364e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.1130e-18, 1.0000e+00, 6.2578e-18, 2.7611e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "100000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.2975e-21, 6.9885e-13, 2.8435e-21, 2.1033e-21],\n",
      "        [2.0065e-31, 4.9551e-19, 1.0903e-31, 6.6024e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.8361e-06, 9.9994e-01, 2.9062e-05, 2.1190e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.1025e-14, 1.0000e+00, 1.2529e-13, 6.7546e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.5050e-18, 1.0000e+00, 7.0801e-18, 3.1291e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "101000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.2673e-21, 6.5539e-13, 2.8252e-21, 2.0890e-21],\n",
      "        [2.0486e-31, 4.5803e-19, 1.1158e-31, 6.7631e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.9794e-06, 9.9994e-01, 2.9662e-05, 2.1641e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.4848e-14, 1.0000e+00, 1.3506e-13, 7.2838e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.9210e-18, 1.0000e+00, 7.9564e-18, 3.5218e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "102000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.2407e-21, 6.1698e-13, 2.8092e-21, 2.0765e-21],\n",
      "        [2.0906e-31, 4.2546e-19, 1.1412e-31, 6.9231e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.1197e-06, 9.9994e-01, 3.0251e-05, 2.2085e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.8762e-14, 1.0000e+00, 1.4511e-13, 7.8285e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.3632e-18, 1.0000e+00, 8.8929e-18, 3.9422e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "103000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.2155e-21, 5.8252e-13, 2.7941e-21, 2.0647e-21],\n",
      "        [2.1313e-31, 3.9664e-19, 1.1659e-31, 7.0795e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([8.2572e-06, 9.9994e-01, 3.0830e-05, 2.2521e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.2762e-14, 1.0000e+00, 1.5541e-13, 8.3867e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.8316e-18, 1.0000e+00, 9.8893e-18, 4.3902e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "104000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.1924e-21, 5.5160e-13, 2.7804e-21, 2.0540e-21],\n",
      "        [2.1717e-31, 3.7117e-19, 1.1905e-31, 7.2350e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.3890e-06, 9.9994e-01, 3.1386e-05, 2.2941e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.6791e-14, 1.0000e+00, 1.6582e-13, 8.9514e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.3208e-18, 1.0000e+00, 1.0935e-17, 4.8615e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "105000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.1705e-21, 5.2386e-13, 2.7675e-21, 2.0439e-21],\n",
      "        [2.2113e-31, 3.4867e-19, 1.2147e-31, 7.3883e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.5201e-06, 9.9994e-01, 3.1936e-05, 2.3356e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.0922e-14, 1.0000e+00, 1.7650e-13, 9.5310e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.8380e-18, 1.0000e+00, 1.2044e-17, 5.3617e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "106000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.1493e-21, 4.9850e-13, 2.7549e-21, 2.0341e-21],\n",
      "        [2.2495e-31, 3.2831e-19, 1.2381e-31, 7.5363e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.6433e-06, 9.9994e-01, 3.2462e-05, 2.3754e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.5044e-14, 1.0000e+00, 1.8724e-13, 1.0114e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.3708e-18, 1.0000e+00, 1.3196e-17, 5.8822e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "107000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.1294e-21, 4.7563e-13, 2.7432e-21, 2.0251e-21],\n",
      "        [2.2856e-31, 3.1010e-19, 1.2605e-31, 7.6785e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.7664e-06, 9.9993e-01, 3.2991e-05, 2.4154e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.9267e-14, 1.0000e+00, 1.9828e-13, 1.0715e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.9310e-18, 1.0000e+00, 1.4413e-17, 6.4332e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "108000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.1104e-21, 4.5462e-13, 2.7322e-21, 2.0165e-21],\n",
      "        [2.3202e-31, 2.9349e-19, 1.2821e-31, 7.8163e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.8866e-06, 9.9993e-01, 3.3507e-05, 2.4545e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.3508e-14, 1.0000e+00, 2.0939e-13, 1.1319e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.5102e-18, 1.0000e+00, 1.5674e-17, 7.0049e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "109000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.0920e-21, 4.3548e-13, 2.7213e-21, 2.0081e-21],\n",
      "        [2.3539e-31, 2.7855e-19, 1.3030e-31, 7.9491e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.0049e-06, 9.9993e-01, 3.4016e-05, 2.4931e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.7822e-14, 1.0000e+00, 2.2071e-13, 1.1935e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.1144e-18, 1.0000e+00, 1.6994e-17, 7.6033e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "110000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.0743e-21, 4.1779e-13, 2.7106e-21, 1.9998e-21],\n",
      "        [2.3865e-31, 2.6487e-19, 1.3232e-31, 8.0772e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.1236e-06, 9.9993e-01, 3.4520e-05, 2.5313e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.2241e-14, 1.0000e+00, 2.3228e-13, 1.2564e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.7478e-18, 1.0000e+00, 1.8377e-17, 8.2311e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "111000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.0570e-21, 4.0131e-13, 2.7002e-21, 1.9917e-21],\n",
      "        [2.4179e-31, 2.5219e-19, 1.3425e-31, 8.1998e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.2338e-06, 9.9993e-01, 3.4989e-05, 2.5669e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.6567e-14, 1.0000e+00, 2.4363e-13, 1.3181e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.3860e-18, 1.0000e+00, 1.9775e-17, 8.8662e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "112000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.0399e-21, 3.8632e-13, 2.6898e-21, 1.9836e-21],\n",
      "        [2.4474e-31, 2.4079e-19, 1.3608e-31, 8.3165e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.3492e-06, 9.9993e-01, 3.5475e-05, 2.6037e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0106e-13, 1.0000e+00, 2.5540e-13, 1.3822e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0059e-17, 1.0000e+00, 2.1249e-17, 9.5368e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "113000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.0230e-21, 3.7220e-13, 2.6795e-21, 1.9757e-21],\n",
      "        [2.4753e-31, 2.3007e-19, 1.3780e-31, 8.4266e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([9.4618e-06, 9.9993e-01, 3.5948e-05, 2.6395e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0559e-13, 1.0000e+00, 2.6727e-13, 1.4467e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0754e-17, 1.0000e+00, 2.2775e-17, 1.0231e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "114000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.0068e-21, 3.5906e-13, 2.6695e-21, 1.9679e-21],\n",
      "        [2.5027e-31, 2.2021e-19, 1.3950e-31, 8.5348e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.5691e-06, 9.9993e-01, 3.6402e-05, 2.6739e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1012e-13, 1.0000e+00, 2.7920e-13, 1.5116e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1468e-17, 1.0000e+00, 2.4346e-17, 1.0947e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "115000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.9909e-21, 3.4681e-13, 2.6598e-21, 1.9604e-21],\n",
      "        [2.5296e-31, 2.1110e-19, 1.4118e-31, 8.6415e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.6712e-06, 9.9993e-01, 3.6831e-05, 2.7064e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1462e-13, 1.0000e+00, 2.9100e-13, 1.5758e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2193e-17, 1.0000e+00, 2.5944e-17, 1.1675e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "116000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.9759e-21, 3.3548e-13, 2.6505e-21, 1.9532e-21],\n",
      "        [2.5566e-31, 2.0279e-19, 1.4284e-31, 8.7474e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.7763e-06, 9.9993e-01, 3.7265e-05, 2.7391e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1925e-13, 1.0000e+00, 3.0309e-13, 1.6414e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2952e-17, 1.0000e+00, 2.7610e-17, 1.2433e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "117000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.9613e-21, 3.2477e-13, 2.6413e-21, 1.9461e-21],\n",
      "        [2.5831e-31, 1.9499e-19, 1.4446e-31, 8.8501e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.8826e-06, 9.9992e-01, 3.7702e-05, 2.7721e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2397e-13, 1.0000e+00, 3.1542e-13, 1.7084e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3740e-17, 1.0000e+00, 2.9339e-17, 1.3221e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "118000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.9468e-21, 3.1465e-13, 2.6321e-21, 1.9389e-21],\n",
      "        [2.6086e-31, 1.8764e-19, 1.4601e-31, 8.9486e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.9895e-06, 9.9992e-01, 3.8137e-05, 2.8048e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2877e-13, 1.0000e+00, 3.2790e-13, 1.7761e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4555e-17, 1.0000e+00, 3.1124e-17, 1.4035e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "119000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.9328e-21, 3.0510e-13, 2.6231e-21, 1.9319e-21],\n",
      "        [2.6336e-31, 1.8077e-19, 1.4752e-31, 9.0448e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0089e-05, 9.9992e-01, 3.8548e-05, 2.8357e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3349e-13, 1.0000e+00, 3.4022e-13, 1.8430e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5373e-17, 1.0000e+00, 3.2924e-17, 1.4855e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "120000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.9188e-21, 2.9622e-13, 2.6142e-21, 1.9250e-21],\n",
      "        [2.6576e-31, 1.7443e-19, 1.4898e-31, 9.1371e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0187e-05, 9.9992e-01, 3.8952e-05, 2.8663e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3819e-13, 1.0000e+00, 3.5257e-13, 1.9101e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.6205e-17, 1.0000e+00, 3.4764e-17, 1.5695e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "121000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.9049e-21, 2.8787e-13, 2.6054e-21, 1.9182e-21],\n",
      "        [2.6806e-31, 1.6851e-19, 1.5038e-31, 9.2266e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0282e-05, 9.9992e-01, 3.9354e-05, 2.8966e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4294e-13, 1.0000e+00, 3.6510e-13, 1.9782e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.7062e-17, 1.0000e+00, 3.6665e-17, 1.6564e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "122000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.8913e-21, 2.7993e-13, 2.5969e-21, 1.9116e-21],\n",
      "        [2.7033e-31, 1.6293e-19, 1.5178e-31, 9.3159e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0380e-05, 9.9992e-01, 3.9762e-05, 2.9274e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4785e-13, 1.0000e+00, 3.7802e-13, 2.0483e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.7958e-17, 1.0000e+00, 3.8655e-17, 1.7473e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "123000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.8778e-21, 2.7228e-13, 2.5884e-21, 1.9050e-21],\n",
      "        [2.7255e-31, 1.5755e-19, 1.5315e-31, 9.4032e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([1.0480e-05, 9.9992e-01, 4.0176e-05, 2.9585e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5286e-13, 1.0000e+00, 3.9123e-13, 2.1200e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.8886e-17, 1.0000e+00, 4.0716e-17, 1.8414e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "124000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.8644e-21, 2.6496e-13, 2.5799e-21, 1.8985e-21],\n",
      "        [2.7466e-31, 1.5242e-19, 1.5446e-31, 9.4863e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0577e-05, 9.9992e-01, 4.0582e-05, 2.9891e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5785e-13, 1.0000e+00, 4.0442e-13, 2.1917e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.9826e-17, 1.0000e+00, 4.2812e-17, 1.9373e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "125000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.8510e-21, 2.5805e-13, 2.5715e-21, 1.8920e-21],\n",
      "        [2.7670e-31, 1.4763e-19, 1.5573e-31, 9.5674e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0663e-05, 9.9992e-01, 4.0949e-05, 3.0169e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.6262e-13, 1.0000e+00, 4.1709e-13, 2.2605e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.0745e-17, 1.0000e+00, 4.4872e-17, 2.0317e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "126000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.8389e-21, 2.5173e-13, 2.5638e-21, 1.8861e-21],\n",
      "        [2.7871e-31, 1.4327e-19, 1.5698e-31, 9.6476e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0750e-05, 9.9992e-01, 4.1324e-05, 3.0453e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.6751e-13, 1.0000e+00, 4.3013e-13, 2.3314e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.1699e-17, 1.0000e+00, 4.7019e-17, 2.1301e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "127000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.8269e-21, 2.4562e-13, 2.5563e-21, 1.8802e-21],\n",
      "        [2.8067e-31, 1.3906e-19, 1.5821e-31, 9.7264e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0836e-05, 9.9992e-01, 4.1698e-05, 3.0736e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.7244e-13, 1.0000e+00, 4.4333e-13, 2.4032e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.2675e-17, 1.0000e+00, 4.9223e-17, 2.2312e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "128000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.8151e-21, 2.3976e-13, 2.5489e-21, 1.8745e-21],\n",
      "        [2.8257e-31, 1.3505e-19, 1.5941e-31, 9.8029e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0921e-05, 9.9992e-01, 4.2068e-05, 3.1017e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.7738e-13, 1.0000e+00, 4.5660e-13, 2.4754e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.3667e-17, 1.0000e+00, 5.1472e-17, 2.3345e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "129000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.8032e-21, 2.3417e-13, 2.5415e-21, 1.8687e-21],\n",
      "        [2.8439e-31, 1.3124e-19, 1.6057e-31, 9.8771e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1008e-05, 9.9992e-01, 4.2449e-05, 3.1305e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.8246e-13, 1.0000e+00, 4.7027e-13, 2.5497e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.4698e-17, 1.0000e+00, 5.3816e-17, 2.4421e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "130000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.7918e-21, 2.2879e-13, 2.5344e-21, 1.8633e-21],\n",
      "        [2.8625e-31, 1.2759e-19, 1.6175e-31, 9.9531e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1097e-05, 9.9991e-01, 4.2838e-05, 3.1600e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.8762e-13, 1.0000e+00, 4.8421e-13, 2.6256e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.5759e-17, 1.0000e+00, 5.6237e-17, 2.5534e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "131000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.7811e-21, 2.2366e-13, 2.5279e-21, 1.8582e-21],\n",
      "        [2.8815e-31, 1.2415e-19, 1.6296e-31, 1.0030e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1187e-05, 9.9991e-01, 4.3231e-05, 3.1898e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.9288e-13, 1.0000e+00, 4.9844e-13, 2.7031e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.6854e-17, 1.0000e+00, 5.8739e-17, 2.6685e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "132000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.7705e-21, 2.1870e-13, 2.5213e-21, 1.8531e-21],\n",
      "        [2.9001e-31, 1.2082e-19, 1.6415e-31, 1.0107e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1274e-05, 9.9991e-01, 4.3617e-05, 3.2191e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.9821e-13, 1.0000e+00, 5.1288e-13, 2.7816e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.7980e-17, 1.0000e+00, 6.1315e-17, 2.7869e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "133000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.7619e-21, 2.1400e-13, 2.5161e-21, 1.8490e-21],\n",
      "        [2.9208e-31, 1.1770e-19, 1.6544e-31, 1.0189e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([1.1356e-05, 9.9991e-01, 4.3981e-05, 3.2468e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.0343e-13, 1.0000e+00, 5.2705e-13, 2.8587e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.9106e-17, 1.0000e+00, 6.3896e-17, 2.9057e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "134000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.7540e-21, 2.0958e-13, 2.5113e-21, 1.8452e-21],\n",
      "        [2.9423e-31, 1.1481e-19, 1.6678e-31, 1.0274e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1431e-05, 9.9991e-01, 4.4321e-05, 3.2728e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.0847e-13, 1.0000e+00, 5.4086e-13, 2.9340e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.0214e-17, 1.0000e+00, 6.6456e-17, 3.0237e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "135000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.7468e-21, 2.0546e-13, 2.5070e-21, 1.8417e-21],\n",
      "        [2.9639e-31, 1.1214e-19, 1.6813e-31, 1.0360e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1506e-05, 9.9991e-01, 4.4665e-05, 3.2991e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.1363e-13, 1.0000e+00, 5.5502e-13, 3.0112e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.1358e-17, 1.0000e+00, 6.9106e-17, 3.1458e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "136000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.7404e-21, 2.0147e-13, 2.5033e-21, 1.8388e-21],\n",
      "        [2.9858e-31, 1.0956e-19, 1.6950e-31, 1.0446e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1581e-05, 9.9991e-01, 4.5011e-05, 3.3254e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.1884e-13, 1.0000e+00, 5.6936e-13, 3.0894e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.2529e-17, 1.0000e+00, 7.1827e-17, 3.2713e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "137000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.7345e-21, 1.9765e-13, 2.4999e-21, 1.8361e-21],\n",
      "        [3.0082e-31, 1.0711e-19, 1.7091e-31, 1.0536e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1659e-05, 9.9991e-01, 4.5364e-05, 3.3523e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.2419e-13, 1.0000e+00, 5.8408e-13, 3.1696e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.3743e-17, 1.0000e+00, 7.4648e-17, 3.4015e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "138000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.7288e-21, 1.9393e-13, 2.4967e-21, 1.8335e-21],\n",
      "        [3.0308e-31, 1.0473e-19, 1.7232e-31, 1.0626e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1737e-05, 9.9991e-01, 4.5717e-05, 3.3791e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.2961e-13, 1.0000e+00, 5.9900e-13, 3.2509e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.4988e-17, 1.0000e+00, 7.7550e-17, 3.5355e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "139000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.7231e-21, 1.9033e-13, 2.4935e-21, 1.8309e-21],\n",
      "        [3.0534e-31, 1.0244e-19, 1.7374e-31, 1.0716e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1811e-05, 9.9991e-01, 4.6061e-05, 3.4054e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.3495e-13, 1.0000e+00, 6.1378e-13, 3.3315e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.6231e-17, 1.0000e+00, 8.0457e-17, 3.6698e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "140000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.7183e-21, 1.8695e-13, 2.4909e-21, 1.8288e-21],\n",
      "        [3.0765e-31, 1.0031e-19, 1.7519e-31, 1.0808e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1886e-05, 9.9991e-01, 4.6407e-05, 3.4318e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.4035e-13, 1.0000e+00, 6.2878e-13, 3.4134e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.7503e-17, 1.0000e+00, 8.3442e-17, 3.8079e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "141000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.7140e-21, 1.8369e-13, 2.4886e-21, 1.8269e-21],\n",
      "        [3.1001e-31, 9.8266e-20, 1.7667e-31, 1.0902e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1963e-05, 9.9991e-01, 4.6759e-05, 3.4587e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.4588e-13, 1.0000e+00, 6.4413e-13, 3.4973e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.8817e-17, 1.0000e+00, 8.6527e-17, 3.9506e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "142000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.7098e-21, 1.8051e-13, 2.4864e-21, 1.8251e-21],\n",
      "        [3.1239e-31, 9.6279e-20, 1.7815e-31, 1.0996e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2041e-05, 9.9991e-01, 4.7123e-05, 3.4865e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.5157e-13, 1.0000e+00, 6.5999e-13, 3.5840e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.0177e-17, 1.0000e+00, 8.9729e-17, 4.0989e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "143000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.7060e-21, 1.7740e-13, 2.4844e-21, 1.8234e-21],\n",
      "        [3.1471e-31, 9.4326e-20, 1.7960e-31, 1.1088e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([1.2121e-05, 9.9991e-01, 4.7490e-05, 3.5146e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.5736e-13, 1.0000e+00, 6.7615e-13, 3.6725e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.1578e-17, 1.0000e+00, 9.3032e-17, 4.2519e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "144000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.7025e-21, 1.7438e-13, 2.4826e-21, 1.8220e-21],\n",
      "        [3.1708e-31, 9.2442e-20, 1.8107e-31, 1.1182e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2200e-05, 9.9990e-01, 4.7860e-05, 3.5429e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.6325e-13, 1.0000e+00, 6.9261e-13, 3.7625e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.3014e-17, 1.0000e+00, 9.6428e-17, 4.4094e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "145000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6991e-21, 1.7145e-13, 2.4810e-21, 1.8206e-21],\n",
      "        [3.1945e-31, 9.0614e-20, 1.8255e-31, 1.1276e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2281e-05, 9.9990e-01, 4.8236e-05, 3.5718e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.6925e-13, 1.0000e+00, 7.0943e-13, 3.8546e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.4491e-17, 1.0000e+00, 9.9924e-17, 4.5717e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "146000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6959e-21, 1.6860e-13, 2.4794e-21, 1.8193e-21],\n",
      "        [3.2177e-31, 8.8829e-20, 1.8400e-31, 1.1368e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2362e-05, 9.9990e-01, 4.8615e-05, 3.6009e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.7531e-13, 1.0000e+00, 7.2647e-13, 3.9480e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.5998e-17, 1.0000e+00, 1.0350e-16, 4.7380e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "147000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6926e-21, 1.6582e-13, 2.4777e-21, 1.8179e-21],\n",
      "        [3.2406e-31, 8.7103e-20, 1.8543e-31, 1.1460e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2442e-05, 9.9990e-01, 4.8986e-05, 3.6295e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.8136e-13, 1.0000e+00, 7.4352e-13, 4.0415e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.7520e-17, 1.0000e+00, 1.0713e-16, 4.9066e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "148000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6892e-21, 1.6315e-13, 2.4761e-21, 1.8166e-21],\n",
      "        [3.2634e-31, 8.5449e-20, 1.8686e-31, 1.1551e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2507e-05, 9.9990e-01, 4.9304e-05, 3.6540e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.8688e-13, 1.0000e+00, 7.5918e-13, 4.1275e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.8934e-17, 1.0000e+00, 1.1053e-16, 5.0645e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "149000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6865e-21, 1.6074e-13, 2.4748e-21, 1.8155e-21],\n",
      "        [3.2847e-31, 8.3964e-20, 1.8820e-31, 1.1636e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2573e-05, 9.9990e-01, 4.9621e-05, 3.6785e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.9245e-13, 1.0000e+00, 7.7502e-13, 4.2143e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.0373e-17, 1.0000e+00, 1.1399e-16, 5.2257e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "150000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6841e-21, 1.5840e-13, 2.4738e-21, 1.8146e-21],\n",
      "        [3.3057e-31, 8.2518e-20, 1.8954e-31, 1.1721e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2639e-05, 9.9990e-01, 4.9939e-05, 3.7030e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.9809e-13, 1.0000e+00, 7.9108e-13, 4.3025e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.1844e-17, 1.0000e+00, 1.1753e-16, 5.3908e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "151000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6816e-21, 1.5611e-13, 2.4727e-21, 1.8137e-21],\n",
      "        [3.3268e-31, 8.1110e-20, 1.9087e-31, 1.1807e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2704e-05, 9.9990e-01, 5.0254e-05, 3.7273e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.0377e-13, 1.0000e+00, 8.0723e-13, 4.3911e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.3337e-17, 1.0000e+00, 1.2113e-16, 5.5584e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "152000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6795e-21, 1.5390e-13, 2.4718e-21, 1.8129e-21],\n",
      "        [3.3481e-31, 7.9752e-20, 1.9221e-31, 1.1892e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2770e-05, 9.9990e-01, 5.0573e-05, 3.7519e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.0958e-13, 1.0000e+00, 8.2375e-13, 4.4818e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.4871e-17, 1.0000e+00, 1.2483e-16, 5.7310e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "153000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6781e-21, 1.5174e-13, 2.4713e-21, 1.8124e-21],\n",
      "        [3.3692e-31, 7.8419e-20, 1.9354e-31, 1.1977e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([1.2836e-05, 9.9990e-01, 5.0891e-05, 3.7764e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.1541e-13, 1.0000e+00, 8.4040e-13, 4.5732e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.6429e-17, 1.0000e+00, 1.2860e-16, 5.9067e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "154000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6767e-21, 1.4964e-13, 2.4709e-21, 1.8120e-21],\n",
      "        [3.3902e-31, 7.7126e-20, 1.9487e-31, 1.2062e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2902e-05, 9.9990e-01, 5.1212e-05, 3.8011e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.2132e-13, 1.0000e+00, 8.5730e-13, 4.6660e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.8021e-17, 1.0000e+00, 1.3246e-16, 6.0869e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "155000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6753e-21, 1.4759e-13, 2.4704e-21, 1.8115e-21],\n",
      "        [3.4115e-31, 7.5869e-20, 1.9621e-31, 1.2148e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2969e-05, 9.9990e-01, 5.1538e-05, 3.8263e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.2733e-13, 1.0000e+00, 8.7450e-13, 4.7606e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.9651e-17, 1.0000e+00, 1.3642e-16, 6.2719e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "156000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6739e-21, 1.4558e-13, 2.4699e-21, 1.8111e-21],\n",
      "        [3.4328e-31, 7.4644e-20, 1.9757e-31, 1.2234e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3038e-05, 9.9990e-01, 5.1870e-05, 3.8519e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.3345e-13, 1.0000e+00, 8.9205e-13, 4.8570e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.1323e-17, 1.0000e+00, 1.4050e-16, 6.4622e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "157000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6725e-21, 1.4361e-13, 2.4695e-21, 1.8106e-21],\n",
      "        [3.4539e-31, 7.3441e-20, 1.9890e-31, 1.2320e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3107e-05, 9.9990e-01, 5.2204e-05, 3.8777e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.3968e-13, 1.0000e+00, 9.0991e-13, 4.9552e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.3039e-17, 1.0000e+00, 1.4467e-16, 6.6574e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "158000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6712e-21, 1.4167e-13, 2.4691e-21, 1.8102e-21],\n",
      "        [3.4751e-31, 7.2261e-20, 2.0024e-31, 1.2405e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3177e-05, 9.9990e-01, 5.2541e-05, 3.9037e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.4602e-13, 1.0000e+00, 9.2804e-13, 5.0548e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.4792e-17, 1.0000e+00, 1.4894e-16, 6.8567e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "159000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6700e-21, 1.3978e-13, 2.4687e-21, 1.8098e-21],\n",
      "        [3.4958e-31, 7.1104e-20, 2.0154e-31, 1.2488e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3245e-05, 9.9989e-01, 5.2870e-05, 3.9291e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.5229e-13, 1.0000e+00, 9.4606e-13, 5.1540e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.6543e-17, 1.0000e+00, 1.5322e-16, 7.0569e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "160000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6688e-21, 1.3795e-13, 2.4682e-21, 1.8094e-21],\n",
      "        [3.5161e-31, 6.9993e-20, 2.0282e-31, 1.2570e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3309e-05, 9.9989e-01, 5.3182e-05, 3.9532e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.5840e-13, 1.0000e+00, 9.6367e-13, 5.2509e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.8275e-17, 1.0000e+00, 1.5746e-16, 7.2550e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "161000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6675e-21, 1.3621e-13, 2.4679e-21, 1.8090e-21],\n",
      "        [3.5363e-31, 6.8944e-20, 2.0410e-31, 1.2651e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3374e-05, 9.9989e-01, 5.3493e-05, 3.9772e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.6460e-13, 1.0000e+00, 9.8147e-13, 5.3487e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.0043e-17, 1.0000e+00, 1.6178e-16, 7.4572e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "162000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6665e-21, 1.3451e-13, 2.4676e-21, 1.8087e-21],\n",
      "        [3.5567e-31, 6.7920e-20, 2.0539e-31, 1.2733e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3440e-05, 9.9989e-01, 5.3806e-05, 4.0014e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.7089e-13, 1.0000e+00, 9.9951e-13, 5.4479e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.1846e-17, 1.0000e+00, 1.6619e-16, 7.6634e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "163000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6654e-21, 1.3284e-13, 2.4673e-21, 1.8084e-21],\n",
      "        [3.5767e-31, 6.6916e-20, 2.0665e-31, 1.2814e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([1.3507e-05, 9.9989e-01, 5.4124e-05, 4.0258e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.7731e-13, 1.0000e+00, 1.0179e-12, 5.5489e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.3697e-17, 1.0000e+00, 1.7070e-16, 7.8746e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "164000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6643e-21, 1.3119e-13, 2.4670e-21, 1.8080e-21],\n",
      "        [3.5965e-31, 6.5921e-20, 2.0789e-31, 1.2893e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3575e-05, 9.9989e-01, 5.4447e-05, 4.0506e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.8385e-13, 1.0000e+00, 1.0366e-12, 5.6517e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.5588e-17, 1.0000e+00, 1.7532e-16, 8.0909e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "165000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6633e-21, 1.2957e-13, 2.4667e-21, 1.8077e-21],\n",
      "        [3.6156e-31, 6.4942e-20, 2.0910e-31, 1.2970e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3645e-05, 9.9989e-01, 5.4771e-05, 4.0755e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.9050e-13, 1.0000e+00, 1.0556e-12, 5.7561e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.7526e-17, 1.0000e+00, 1.8005e-16, 8.3121e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "166000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6624e-21, 1.2798e-13, 2.4664e-21, 1.8074e-21],\n",
      "        [3.6349e-31, 6.3982e-20, 2.1032e-31, 1.3048e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3715e-05, 9.9989e-01, 5.5094e-05, 4.1002e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.9726e-13, 1.0000e+00, 1.0749e-12, 5.8615e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.9509e-17, 1.0000e+00, 1.8488e-16, 8.5377e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "167000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6615e-21, 1.2642e-13, 2.4662e-21, 1.8071e-21],\n",
      "        [3.6543e-31, 6.3042e-20, 2.1153e-31, 1.3126e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3787e-05, 9.9989e-01, 5.5422e-05, 4.1252e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.0416e-13, 1.0000e+00, 1.0944e-12, 5.9684e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.1529e-17, 1.0000e+00, 1.8979e-16, 8.7671e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "168000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6607e-21, 1.2489e-13, 2.4659e-21, 1.8068e-21],\n",
      "        [3.6723e-31, 6.2109e-20, 2.1267e-31, 1.3199e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3864e-05, 9.9989e-01, 5.5764e-05, 4.1509e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.1131e-13, 1.0000e+00, 1.1145e-12, 6.0784e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.3610e-17, 1.0000e+00, 1.9485e-16, 9.0033e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "169000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6599e-21, 1.2338e-13, 2.4657e-21, 1.8065e-21],\n",
      "        [3.6882e-31, 6.1163e-20, 2.1369e-31, 1.3265e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3942e-05, 9.9989e-01, 5.6109e-05, 4.1769e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.1860e-13, 1.0000e+00, 1.1350e-12, 6.1904e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.5746e-17, 1.0000e+00, 2.0003e-16, 9.2453e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "170000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6591e-21, 1.2189e-13, 2.4654e-21, 1.8062e-21],\n",
      "        [3.7039e-31, 6.0232e-20, 2.1471e-31, 1.3331e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4021e-05, 9.9989e-01, 5.6454e-05, 4.2028e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.2596e-13, 1.0000e+00, 1.1557e-12, 6.3030e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.7915e-17, 1.0000e+00, 2.0528e-16, 9.4902e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "171000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6584e-21, 1.2043e-13, 2.4651e-21, 1.8059e-21],\n",
      "        [3.7194e-31, 5.9326e-20, 2.1570e-31, 1.3395e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4099e-05, 9.9989e-01, 5.6794e-05, 4.2284e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.3330e-13, 1.0000e+00, 1.1762e-12, 6.4152e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.0096e-17, 1.0000e+00, 2.1057e-16, 9.7369e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "172000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6577e-21, 1.1903e-13, 2.4649e-21, 1.8057e-21],\n",
      "        [3.7349e-31, 5.8454e-20, 2.1670e-31, 1.3459e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4176e-05, 9.9989e-01, 5.7134e-05, 4.2539e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.4070e-13, 1.0000e+00, 1.1970e-12, 6.5286e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.2311e-17, 1.0000e+00, 2.1595e-16, 9.9882e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "173000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6569e-21, 1.1765e-13, 2.4646e-21, 1.8054e-21],\n",
      "        [3.7504e-31, 5.7602e-20, 2.1769e-31, 1.3523e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([1.4254e-05, 9.9989e-01, 5.7473e-05, 4.2794e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.4819e-13, 1.0000e+00, 1.2181e-12, 6.6434e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.4571e-17, 1.0000e+00, 2.2144e-16, 1.0244e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "174000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6562e-21, 1.1629e-13, 2.4643e-21, 1.8051e-21],\n",
      "        [3.7660e-31, 5.6765e-20, 2.1869e-31, 1.3588e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4321e-05, 9.9988e-01, 5.7772e-05, 4.3019e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.5514e-13, 1.0000e+00, 1.2377e-12, 6.7503e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.6708e-17, 1.0000e+00, 2.2666e-16, 1.0488e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "175000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6555e-21, 1.1503e-13, 2.4641e-21, 1.8048e-21],\n",
      "        [3.7815e-31, 5.6003e-20, 2.1969e-31, 1.3652e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4380e-05, 9.9988e-01, 5.8039e-05, 4.3220e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.6166e-13, 1.0000e+00, 1.2561e-12, 6.8509e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.8747e-17, 1.0000e+00, 2.3164e-16, 1.0722e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "176000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6548e-21, 1.1385e-13, 2.4638e-21, 1.8045e-21],\n",
      "        [3.7971e-31, 5.5301e-20, 2.2069e-31, 1.3717e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4437e-05, 9.9988e-01, 5.8296e-05, 4.3414e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.6809e-13, 1.0000e+00, 1.2743e-12, 6.9503e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0078e-16, 1.0000e+00, 2.3662e-16, 1.0955e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "177000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6541e-21, 1.1271e-13, 2.4636e-21, 1.8042e-21],\n",
      "        [3.8127e-31, 5.4624e-20, 2.2170e-31, 1.3782e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4490e-05, 9.9988e-01, 5.8538e-05, 4.3597e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.7432e-13, 1.0000e+00, 1.2921e-12, 7.0469e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0276e-16, 1.0000e+00, 2.4151e-16, 1.1184e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "178000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6534e-21, 1.1162e-13, 2.4633e-21, 1.8040e-21],\n",
      "        [3.8279e-31, 5.3980e-20, 2.2268e-31, 1.3845e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4546e-05, 9.9988e-01, 5.8786e-05, 4.3783e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.8074e-13, 1.0000e+00, 1.3101e-12, 7.1453e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0481e-16, 1.0000e+00, 2.4651e-16, 1.1417e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "179000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6530e-21, 1.1054e-13, 2.4633e-21, 1.8038e-21],\n",
      "        [3.8432e-31, 5.3343e-20, 2.2365e-31, 1.3908e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4602e-05, 9.9988e-01, 5.9039e-05, 4.3972e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.8727e-13, 1.0000e+00, 1.3285e-12, 7.2455e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0690e-16, 1.0000e+00, 2.5161e-16, 1.1656e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "180000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6529e-21, 1.0948e-13, 2.4633e-21, 1.8038e-21],\n",
      "        [3.8588e-31, 5.2716e-20, 2.2464e-31, 1.3972e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4659e-05, 9.9988e-01, 5.9292e-05, 4.4162e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.9388e-13, 1.0000e+00, 1.3472e-12, 7.3471e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0903e-16, 1.0000e+00, 2.5682e-16, 1.1899e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "181000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6527e-21, 1.0843e-13, 2.4634e-21, 1.8037e-21],\n",
      "        [3.8743e-31, 5.2096e-20, 2.2562e-31, 1.4035e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4716e-05, 9.9988e-01, 5.9546e-05, 4.4352e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.0056e-13, 1.0000e+00, 1.3661e-12, 7.4499e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1119e-16, 1.0000e+00, 2.6211e-16, 1.2146e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "182000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6526e-21, 1.0740e-13, 2.4635e-21, 1.8037e-21],\n",
      "        [3.8895e-31, 5.1484e-20, 2.2659e-31, 1.4097e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4774e-05, 9.9988e-01, 5.9798e-05, 4.4540e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.0736e-13, 1.0000e+00, 1.3851e-12, 7.5533e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1340e-16, 1.0000e+00, 2.6747e-16, 1.2397e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "183000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6525e-21, 1.0637e-13, 2.4636e-21, 1.8037e-21],\n",
      "        [3.9050e-31, 5.0881e-20, 2.2757e-31, 1.4160e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([1.4833e-05, 9.9988e-01, 6.0053e-05, 4.4731e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.1419e-13, 1.0000e+00, 1.4042e-12, 7.6573e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1562e-16, 1.0000e+00, 2.7289e-16, 1.2649e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "184000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6525e-21, 1.0537e-13, 2.4637e-21, 1.8036e-21],\n",
      "        [3.9199e-31, 5.0292e-20, 2.2851e-31, 1.4220e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4893e-05, 9.9988e-01, 6.0317e-05, 4.4928e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.2117e-13, 1.0000e+00, 1.4238e-12, 7.7638e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1790e-16, 1.0000e+00, 2.7843e-16, 1.2908e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "185000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6524e-21, 1.0439e-13, 2.4637e-21, 1.8036e-21],\n",
      "        [3.9343e-31, 4.9704e-20, 2.2941e-31, 1.4278e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4955e-05, 9.9988e-01, 6.0586e-05, 4.5129e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.2827e-13, 1.0000e+00, 1.4437e-12, 7.8722e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2022e-16, 1.0000e+00, 2.8408e-16, 1.3172e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "186000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6523e-21, 1.0341e-13, 2.4639e-21, 1.8036e-21],\n",
      "        [3.9482e-31, 4.9121e-20, 2.3029e-31, 1.4335e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5017e-05, 9.9988e-01, 6.0853e-05, 4.5329e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.3542e-13, 1.0000e+00, 1.4638e-12, 7.9811e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2257e-16, 1.0000e+00, 2.8980e-16, 1.3439e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "187000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6522e-21, 1.0245e-13, 2.4639e-21, 1.8035e-21],\n",
      "        [3.9621e-31, 4.8550e-20, 2.3118e-31, 1.4392e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5078e-05, 9.9988e-01, 6.1114e-05, 4.5524e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.4255e-13, 1.0000e+00, 1.4837e-12, 8.0890e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2493e-16, 1.0000e+00, 2.9552e-16, 1.3706e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "188000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6523e-21, 1.0151e-13, 2.4641e-21, 1.8035e-21],\n",
      "        [3.9764e-31, 4.7997e-20, 2.3206e-31, 1.4449e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5141e-05, 9.9988e-01, 6.1377e-05, 4.5718e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.4984e-13, 1.0000e+00, 1.5038e-12, 8.1981e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2734e-16, 1.0000e+00, 3.0133e-16, 1.3976e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "189000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6524e-21, 1.0059e-13, 2.4641e-21, 1.8035e-21],\n",
      "        [3.9903e-31, 4.7449e-20, 2.3292e-31, 1.4504e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5204e-05, 9.9988e-01, 6.1642e-05, 4.5914e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.5725e-13, 1.0000e+00, 1.5242e-12, 8.3087e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2981e-16, 1.0000e+00, 3.0725e-16, 1.4251e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "190000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6526e-21, 9.9670e-14, 2.4643e-21, 1.8035e-21],\n",
      "        [4.0042e-31, 4.6907e-20, 2.3378e-31, 1.4558e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5269e-05, 9.9988e-01, 6.1910e-05, 4.6113e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.6478e-13, 1.0000e+00, 1.5450e-12, 8.4211e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3232e-16, 1.0000e+00, 3.1329e-16, 1.4533e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "191000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6527e-21, 9.8764e-14, 2.4644e-21, 1.8034e-21],\n",
      "        [4.0179e-31, 4.6370e-20, 2.3462e-31, 1.4612e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5335e-05, 9.9988e-01, 6.2182e-05, 4.6314e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.7242e-13, 1.0000e+00, 1.5661e-12, 8.5353e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3488e-16, 1.0000e+00, 3.1945e-16, 1.4820e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "192000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6528e-21, 9.7867e-14, 2.4645e-21, 1.8034e-21],\n",
      "        [4.0314e-31, 4.5839e-20, 2.3546e-31, 1.4666e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5400e-05, 9.9988e-01, 6.2455e-05, 4.6516e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.8012e-13, 1.0000e+00, 1.5873e-12, 8.6503e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3748e-16, 1.0000e+00, 3.2569e-16, 1.5110e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "193000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6529e-21, 9.6985e-14, 2.4646e-21, 1.8034e-21],\n",
      "        [4.0450e-31, 4.5318e-20, 2.3629e-31, 1.4719e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([1.5466e-05, 9.9988e-01, 6.2729e-05, 4.6719e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.8790e-13, 1.0000e+00, 1.6088e-12, 8.7667e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4011e-16, 1.0000e+00, 3.3204e-16, 1.5406e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "194000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6531e-21, 9.6114e-14, 2.4647e-21, 1.8033e-21],\n",
      "        [4.0585e-31, 4.4804e-20, 2.3713e-31, 1.4773e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5532e-05, 9.9987e-01, 6.3005e-05, 4.6923e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.9579e-13, 1.0000e+00, 1.6306e-12, 8.8845e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4280e-16, 1.0000e+00, 3.3851e-16, 1.5707e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "195000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6532e-21, 9.5252e-14, 2.4648e-21, 1.8033e-21],\n",
      "        [4.0721e-31, 4.4298e-20, 2.3797e-31, 1.4826e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5599e-05, 9.9987e-01, 6.3281e-05, 4.7128e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.0378e-13, 1.0000e+00, 1.6526e-12, 9.0039e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4553e-16, 1.0000e+00, 3.4509e-16, 1.6014e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "196000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6533e-21, 9.4398e-14, 2.4649e-21, 1.8033e-21],\n",
      "        [4.0856e-31, 4.3796e-20, 2.3881e-31, 1.4880e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5665e-05, 9.9987e-01, 6.3557e-05, 4.7332e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.1180e-13, 1.0000e+00, 1.6748e-12, 9.1240e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4830e-16, 1.0000e+00, 3.5176e-16, 1.6324e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "197000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6535e-21, 9.3558e-14, 2.4650e-21, 1.8032e-21],\n",
      "        [4.0992e-31, 4.3306e-20, 2.3965e-31, 1.4934e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5731e-05, 9.9987e-01, 6.3832e-05, 4.7535e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.1987e-13, 1.0000e+00, 1.6970e-12, 9.2445e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5109e-16, 1.0000e+00, 3.5849e-16, 1.6638e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "198000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6536e-21, 9.2734e-14, 2.4651e-21, 1.8032e-21],\n",
      "        [4.1128e-31, 4.2826e-20, 2.4049e-31, 1.4988e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5798e-05, 9.9987e-01, 6.4109e-05, 4.7740e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.2803e-13, 1.0000e+00, 1.7196e-12, 9.3667e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5394e-16, 1.0000e+00, 3.6536e-16, 1.6957e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "199000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6537e-21, 9.1919e-14, 2.4652e-21, 1.8032e-21],\n",
      "        [4.1263e-31, 4.2350e-20, 2.4132e-31, 1.5041e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5867e-05, 9.9987e-01, 6.4396e-05, 4.7954e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.3641e-13, 1.0000e+00, 1.7427e-12, 9.4919e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5684e-16, 1.0000e+00, 3.7235e-16, 1.7283e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "200000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6539e-21, 9.1110e-14, 2.4653e-21, 1.8032e-21],\n",
      "        [4.1381e-31, 4.1869e-20, 2.4206e-31, 1.5088e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5937e-05, 9.9987e-01, 6.4686e-05, 4.8170e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.4491e-13, 1.0000e+00, 1.7662e-12, 9.6190e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5979e-16, 1.0000e+00, 3.7947e-16, 1.7615e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "201000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6540e-21, 9.0310e-14, 2.4654e-21, 1.8032e-21],\n",
      "        [4.1497e-31, 4.1393e-20, 2.4280e-31, 1.5135e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.6008e-05, 9.9987e-01, 6.4974e-05, 4.8383e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.5346e-13, 1.0000e+00, 1.7896e-12, 9.7460e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.6278e-16, 1.0000e+00, 3.8665e-16, 1.7949e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "202000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6542e-21, 8.9526e-14, 2.4656e-21, 1.8031e-21],\n",
      "        [4.1615e-31, 4.0928e-20, 2.4353e-31, 1.5181e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.6078e-05, 9.9987e-01, 6.5258e-05, 4.8594e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.6207e-13, 1.0000e+00, 1.8131e-12, 9.8731e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.6580e-16, 1.0000e+00, 3.9388e-16, 1.8285e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "203000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6543e-21, 8.8757e-14, 2.4657e-21, 1.8031e-21],\n",
      "        [4.1734e-31, 4.0475e-20, 2.4427e-31, 1.5228e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([1.6149e-05, 9.9987e-01, 6.5542e-05, 4.8802e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.7071e-13, 1.0000e+00, 1.8366e-12, 1.0000e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.6885e-16, 1.0000e+00, 4.0117e-16, 1.8624e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "204000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6546e-21, 8.8005e-14, 2.4658e-21, 1.8031e-21],\n",
      "        [4.1853e-31, 4.0033e-20, 2.4500e-31, 1.5275e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.6216e-05, 9.9987e-01, 6.5808e-05, 4.8998e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.7906e-13, 1.0000e+00, 1.8594e-12, 1.0123e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.7182e-16, 1.0000e+00, 4.0826e-16, 1.8953e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "205000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6548e-21, 8.7287e-14, 2.4659e-21, 1.8031e-21],\n",
      "        [4.1971e-31, 3.9616e-20, 2.4574e-31, 1.5322e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.6280e-05, 9.9987e-01, 6.6065e-05, 4.9187e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.8725e-13, 1.0000e+00, 1.8816e-12, 1.0243e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.7476e-16, 1.0000e+00, 4.1528e-16, 1.9279e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "206000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6550e-21, 8.6595e-14, 2.4660e-21, 1.8031e-21],\n",
      "        [4.2091e-31, 3.9217e-20, 2.4648e-31, 1.5369e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.6346e-05, 9.9987e-01, 6.6328e-05, 4.9380e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.9555e-13, 1.0000e+00, 1.9042e-12, 1.0364e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.7773e-16, 1.0000e+00, 4.2237e-16, 1.9608e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "207000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6552e-21, 8.5915e-14, 2.4661e-21, 1.8030e-21],\n",
      "        [4.2199e-31, 3.8818e-20, 2.4715e-31, 1.5412e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.6413e-05, 9.9987e-01, 6.6591e-05, 4.9573e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.0379e-13, 1.0000e+00, 1.9266e-12, 1.0485e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.8067e-16, 1.0000e+00, 4.2940e-16, 1.9934e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "208000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6554e-21, 8.5257e-14, 2.4663e-21, 1.8030e-21],\n",
      "        [4.2296e-31, 3.8430e-20, 2.4777e-31, 1.5451e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.6479e-05, 9.9987e-01, 6.6856e-05, 4.9768e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.1211e-13, 1.0000e+00, 1.9492e-12, 1.0607e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.8365e-16, 1.0000e+00, 4.3651e-16, 2.0265e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "209000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6556e-21, 8.4607e-14, 2.4663e-21, 1.8030e-21],\n",
      "        [4.2393e-31, 3.8046e-20, 2.4838e-31, 1.5490e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.6547e-05, 9.9987e-01, 6.7127e-05, 4.9968e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.2057e-13, 1.0000e+00, 1.9722e-12, 1.0731e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.8668e-16, 1.0000e+00, 4.4378e-16, 2.0602e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "210000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6558e-21, 8.3963e-14, 2.4664e-21, 1.8030e-21],\n",
      "        [4.2489e-31, 3.7666e-20, 2.4898e-31, 1.5528e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.6615e-05, 9.9987e-01, 6.7399e-05, 5.0169e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.2911e-13, 1.0000e+00, 1.9954e-12, 1.0857e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.8976e-16, 1.0000e+00, 4.5116e-16, 2.0945e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "211000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6560e-21, 8.3323e-14, 2.4666e-21, 1.8030e-21],\n",
      "        [4.2583e-31, 3.7289e-20, 2.4958e-31, 1.5566e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.6685e-05, 9.9987e-01, 6.7679e-05, 5.0376e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.3783e-13, 1.0000e+00, 2.0192e-12, 1.0986e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.9290e-16, 1.0000e+00, 4.5866e-16, 2.1294e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "212000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6561e-21, 8.2689e-14, 2.4667e-21, 1.8029e-21],\n",
      "        [4.2665e-31, 3.6909e-20, 2.5010e-31, 1.5599e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.6756e-05, 9.9986e-01, 6.7964e-05, 5.0587e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.4669e-13, 1.0000e+00, 2.0433e-12, 1.1116e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.9608e-16, 1.0000e+00, 4.6630e-16, 2.1648e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "213000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6563e-21, 8.2059e-14, 2.4667e-21, 1.8029e-21],\n",
      "        [4.2742e-31, 3.6529e-20, 2.5059e-31, 1.5630e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([1.6827e-05, 9.9986e-01, 6.8250e-05, 5.0798e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.5565e-13, 1.0000e+00, 2.0677e-12, 1.1248e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.9931e-16, 1.0000e+00, 4.7404e-16, 2.2008e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "214000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6565e-21, 8.1436e-14, 2.4668e-21, 1.8029e-21],\n",
      "        [4.2819e-31, 3.6155e-20, 2.5108e-31, 1.5662e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.6899e-05, 9.9986e-01, 6.8537e-05, 5.1011e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.6472e-13, 1.0000e+00, 2.0924e-12, 1.1381e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.0261e-16, 1.0000e+00, 4.8192e-16, 2.2374e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "215000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6567e-21, 8.0816e-14, 2.4669e-21, 1.8029e-21],\n",
      "        [4.2895e-31, 3.5783e-20, 2.5157e-31, 1.5693e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.6971e-05, 9.9986e-01, 6.8825e-05, 5.1224e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.7390e-13, 1.0000e+00, 2.1174e-12, 1.1516e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.0594e-16, 1.0000e+00, 4.8992e-16, 2.2745e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "216000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6569e-21, 8.0202e-14, 2.4670e-21, 1.8029e-21],\n",
      "        [4.2973e-31, 3.5416e-20, 2.5207e-31, 1.5724e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.7043e-05, 9.9986e-01, 6.9114e-05, 5.1437e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.8315e-13, 1.0000e+00, 2.1426e-12, 1.1652e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.0933e-16, 1.0000e+00, 4.9803e-16, 2.3122e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "217000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6570e-21, 7.9595e-14, 2.4671e-21, 1.8029e-21],\n",
      "        [4.3050e-31, 3.5055e-20, 2.5257e-31, 1.5756e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.7115e-05, 9.9986e-01, 6.9403e-05, 5.1650e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.9248e-13, 1.0000e+00, 2.1679e-12, 1.1789e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.1275e-16, 1.0000e+00, 5.0624e-16, 2.3503e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "218000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6572e-21, 7.8995e-14, 2.4672e-21, 1.8028e-21],\n",
      "        [4.3127e-31, 3.4699e-20, 2.5307e-31, 1.5788e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.7187e-05, 9.9986e-01, 6.9692e-05, 5.1864e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.0191e-13, 1.0000e+00, 2.1936e-12, 1.1928e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.1623e-16, 1.0000e+00, 5.1458e-16, 2.3891e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "219000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6574e-21, 7.8400e-14, 2.4673e-21, 1.8028e-21],\n",
      "        [4.3205e-31, 3.4346e-20, 2.5356e-31, 1.5819e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.7260e-05, 9.9986e-01, 6.9983e-05, 5.2078e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.1141e-13, 1.0000e+00, 2.2194e-12, 1.2068e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.1975e-16, 1.0000e+00, 5.2301e-16, 2.4283e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "220000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6576e-21, 7.7812e-14, 2.4674e-21, 1.8028e-21],\n",
      "        [4.3283e-31, 3.4000e-20, 2.5406e-31, 1.5851e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.7331e-05, 9.9986e-01, 7.0269e-05, 5.2290e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.2092e-13, 1.0000e+00, 2.2453e-12, 1.2207e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.2330e-16, 1.0000e+00, 5.3151e-16, 2.4678e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "221000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6577e-21, 7.7232e-14, 2.4675e-21, 1.8028e-21],\n",
      "        [4.3360e-31, 3.3658e-20, 2.5456e-31, 1.5883e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.7403e-05, 9.9986e-01, 7.0553e-05, 5.2500e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.3052e-13, 1.0000e+00, 2.2714e-12, 1.2349e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.2689e-16, 1.0000e+00, 5.4011e-16, 2.5078e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "222000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6579e-21, 7.6658e-14, 2.4676e-21, 1.8028e-21],\n",
      "        [4.3438e-31, 3.3322e-20, 2.5506e-31, 1.5914e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.7475e-05, 9.9986e-01, 7.0841e-05, 5.2713e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.4024e-13, 1.0000e+00, 2.2978e-12, 1.2491e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.3053e-16, 1.0000e+00, 5.4886e-16, 2.5484e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "223000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.6580e-21, 7.6089e-14, 2.4677e-21, 1.8028e-21],\n",
      "        [4.3511e-31, 3.2987e-20, 2.5554e-31, 1.5945e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([1.8739e-06, 9.9998e-01, 7.0537e-06, 6.8039e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.9040e-15, 1.0000e+00, 1.2036e-14, 1.0447e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.5162e-19, 1.0000e+00, 7.5110e-19, 6.2954e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "224000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.2021e-21, 4.5933e-13, 7.8373e-22, 7.0525e-22],\n",
      "        [8.1138e-32, 4.3242e-19, 4.6045e-32, 4.0010e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.8663e-06, 9.9998e-01, 7.0431e-06, 6.7994e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.9302e-15, 1.0000e+00, 1.2138e-14, 1.0544e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.5623e-19, 1.0000e+00, 7.6402e-19, 6.4125e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "225000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.1977e-21, 4.5339e-13, 7.8135e-22, 7.0310e-22],\n",
      "        [8.1264e-32, 4.2575e-19, 4.6184e-32, 4.0152e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.8642e-06, 9.9998e-01, 7.0533e-06, 6.8151e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.9906e-15, 1.0000e+00, 1.2326e-14, 1.0717e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.6409e-19, 1.0000e+00, 7.8409e-19, 6.5903e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "226000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.1933e-21, 4.4577e-13, 7.7898e-22, 7.0096e-22],\n",
      "        [8.1395e-32, 4.1677e-19, 4.6330e-32, 4.0301e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.8691e-06, 9.9998e-01, 7.0904e-06, 6.8572e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.0938e-15, 1.0000e+00, 1.2621e-14, 1.0984e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.7604e-19, 1.0000e+00, 8.1320e-19, 6.8448e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "227000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.1890e-21, 4.3630e-13, 7.7663e-22, 6.9884e-22],\n",
      "        [8.1523e-32, 4.0522e-19, 4.6474e-32, 4.0448e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.8814e-06, 9.9998e-01, 7.1556e-06, 6.9265e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.2430e-15, 1.0000e+00, 1.3033e-14, 1.1352e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.9249e-19, 1.0000e+00, 8.5230e-19, 7.1842e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "228000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.1847e-21, 4.2513e-13, 7.7428e-22, 6.9672e-22],\n",
      "        [8.1646e-32, 3.9137e-19, 4.6614e-32, 4.0593e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.9022e-06, 9.9998e-01, 7.2516e-06, 7.0259e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.4421e-15, 1.0000e+00, 1.3566e-14, 1.1827e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.1345e-19, 1.0000e+00, 9.0124e-19, 7.6070e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "229000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.1808e-21, 4.1273e-13, 7.7210e-22, 6.9477e-22],\n",
      "        [8.1574e-32, 3.7531e-19, 4.6643e-32, 4.0635e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.9293e-06, 9.9998e-01, 7.3706e-06, 7.1480e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.6820e-15, 1.0000e+00, 1.4201e-14, 1.2393e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.3840e-19, 1.0000e+00, 9.5914e-19, 8.1063e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "230000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.1770e-21, 3.9964e-13, 7.6999e-22, 6.9287e-22],\n",
      "        [8.1382e-32, 3.5814e-19, 4.6605e-32, 4.0615e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.9604e-06, 9.9998e-01, 7.5044e-06, 7.2844e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.9534e-15, 1.0000e+00, 1.4916e-14, 1.3028e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.6684e-19, 1.0000e+00, 1.0248e-18, 8.6724e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "231000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.1732e-21, 3.8635e-13, 7.6788e-22, 6.9097e-22],\n",
      "        [8.1192e-32, 3.4096e-19, 4.6562e-32, 4.0592e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.9944e-06, 9.9998e-01, 7.6485e-06, 7.4306e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.2497e-15, 1.0000e+00, 1.5693e-14, 1.3719e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.9824e-19, 1.0000e+00, 1.0973e-18, 9.2965e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "232000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.1696e-21, 3.7325e-13, 7.6584e-22, 6.8912e-22],\n",
      "        [8.1002e-32, 3.2425e-19, 4.6517e-32, 4.0567e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.0293e-06, 9.9998e-01, 7.7958e-06, 7.5801e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.5607e-15, 1.0000e+00, 1.6510e-14, 1.4445e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.3169e-19, 1.0000e+00, 1.1745e-18, 9.9625e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "233000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.1661e-21, 3.6068e-13, 7.6383e-22, 6.8732e-22],\n",
      "        [8.0817e-32, 3.0845e-19, 4.6472e-32, 4.0539e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([2.0649e-06, 9.9998e-01, 7.9456e-06, 7.7319e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.8864e-15, 1.0000e+00, 1.7364e-14, 1.5205e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.6721e-19, 1.0000e+00, 1.2566e-18, 1.0670e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "234000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.1627e-21, 3.4864e-13, 7.6191e-22, 6.8558e-22],\n",
      "        [8.0629e-32, 2.9353e-19, 4.6420e-32, 4.0505e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.1010e-06, 9.9998e-01, 8.0969e-06, 7.8850e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.2241e-15, 1.0000e+00, 1.8251e-14, 1.5992e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.0458e-19, 1.0000e+00, 1.3430e-18, 1.1415e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "235000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.1593e-21, 3.3718e-13, 7.6001e-22, 6.8386e-22],\n",
      "        [8.0442e-32, 2.7955e-19, 4.6366e-32, 4.0469e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.1371e-06, 9.9998e-01, 8.2483e-06, 8.0383e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.5704e-15, 1.0000e+00, 1.9161e-14, 1.6802e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.4349e-19, 1.0000e+00, 1.4331e-18, 1.2194e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "236000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.1561e-21, 3.2638e-13, 7.5817e-22, 6.8219e-22],\n",
      "        [8.0260e-32, 2.6656e-19, 4.6314e-32, 4.0435e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.1741e-06, 9.9998e-01, 8.4019e-06, 8.1937e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.9308e-15, 1.0000e+00, 2.0104e-14, 1.7641e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.8451e-19, 1.0000e+00, 1.5279e-18, 1.3012e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "237000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.1530e-21, 3.1609e-13, 7.5634e-22, 6.8054e-22],\n",
      "        [8.0087e-32, 2.5438e-19, 4.6259e-32, 4.0396e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.2119e-06, 9.9998e-01, 8.5570e-06, 8.3502e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.3033e-15, 1.0000e+00, 2.1076e-14, 1.8505e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.2746e-19, 1.0000e+00, 1.6269e-18, 1.3867e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "238000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.1500e-21, 3.0635e-13, 7.5454e-22, 6.7890e-22],\n",
      "        [7.9921e-32, 2.4300e-19, 4.6200e-32, 4.0353e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.2493e-06, 9.9998e-01, 8.7101e-06, 8.5046e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.6830e-15, 1.0000e+00, 2.2065e-14, 1.9383e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.7184e-19, 1.0000e+00, 1.7289e-18, 1.4748e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "239000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.1472e-21, 2.9719e-13, 7.5282e-22, 6.7733e-22],\n",
      "        [7.9756e-32, 2.3244e-19, 4.6137e-32, 4.0305e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.2852e-06, 9.9998e-01, 8.8569e-06, 8.6527e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.0607e-15, 1.0000e+00, 2.3049e-14, 2.0259e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.1668e-19, 1.0000e+00, 1.8323e-18, 1.5641e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "240000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.1444e-21, 2.8863e-13, 7.5112e-22, 6.7577e-22],\n",
      "        [7.9594e-32, 2.2273e-19, 4.6076e-32, 4.0259e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.3208e-06, 9.9998e-01, 9.0035e-06, 8.8009e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.4438e-15, 1.0000e+00, 2.4051e-14, 2.1151e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.6263e-19, 1.0000e+00, 1.9387e-18, 1.6561e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "241000   actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(2.9637, grad_fn=<DivBackward0>)   , return=  16061.75\n",
      "discReturns/1000= tensor([6.4135, 6.5111, 5.5493])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.1417e-21, 2.8058e-13, 7.4950e-22, 6.7429e-22],\n",
      "        [7.9413e-32, 2.1366e-19, 4.6005e-32, 4.0204e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "algorithm.solver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advModeNames=\"\"\n",
    "for i in range(len(adversaryProbs)):\n",
    "    if adversaryProbs[i]!=0:\n",
    "        tmp=\"{:.1f}\".format(adversaryProbs[i])\n",
    "        advModeNames+=f\"{(AdversaryModes(i)).name}-{tmp}-\"\n",
    "    \n",
    "name=f\"ep {algorithm.numberEpisodes}, {advModeNames}, {game.advHistoryNum} hist, {neuralNet.lr} lr\"\n",
    "neuralNet.save(name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "profits = pd.DataFrame(game.profit).T\n",
    "prices = pd.DataFrame(game.prices).T\n",
    "demandPotential = pd.DataFrame(game.demandPotential).T\n",
    "learning = pd.DataFrame(algorithm.returns.mean(axis = 0),columns=['entry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = pd.DataFrame(algorithm.loss.mean(axis = 0),columns=['entry'])\n",
    "loss.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demandPotential.plot()\n",
    "demandPotential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    16041.703125\n",
       "1    11864.703125\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profits.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5112.250000</td>\n",
       "      <td>4160.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5361.562500</td>\n",
       "      <td>3937.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5567.890625</td>\n",
       "      <td>3766.890625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0            1\n",
       "0  5112.250000  4160.250000\n",
       "1  5361.562500  3937.562500\n",
       "2  5567.890625  3766.890625"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "profits.plot()\n",
    "profits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128.500</td>\n",
       "      <td>135.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128.250</td>\n",
       "      <td>133.750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>130.625</td>\n",
       "      <td>132.375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0        1\n",
       "0  128.500  135.500\n",
       "1  128.250  133.750\n",
       "2  130.625  132.375"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "prices.plot()\n",
    "prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learning.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pricelearning = pd.DataFrame(game.prices.mean(axis = 0))\n",
    "# pricelearning.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_1 = learning.to_numpy()\n",
    "learning_2 = [0]*len(learning)\n",
    "for i in range(len(learning_1)):\n",
    "    learning_2[i] = learning_1[i][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_learning = np.convolve(learning_2, np.ones(1000)/1000, mode = 'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(avg_learning)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidIndexError",
     "evalue": "(slice(None, None, None), None)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\Documents\\Anaconda\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3621\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3620\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3621\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3622\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\Documents\\Anaconda\\lib\\site-packages\\pandas\\_libs\\index.pyx:136\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\Documents\\Anaconda\\lib\\site-packages\\pandas\\_libs\\index.pyx:142\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '(slice(None, None, None), None)' is an invalid key",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearning\u001b[49m\u001b[43m,\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\Anaconda\\lib\\site-packages\\matplotlib\\pyplot.py:2757\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2755\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mplot)\n\u001b[0;32m   2756\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot\u001b[39m(\u001b[38;5;241m*\u001b[39margs, scalex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, scaley\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m-> 2757\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m gca()\u001b[38;5;241m.\u001b[39mplot(\n\u001b[0;32m   2758\u001b[0m         \u001b[38;5;241m*\u001b[39margs, scalex\u001b[38;5;241m=\u001b[39mscalex, scaley\u001b[38;5;241m=\u001b[39mscaley,\n\u001b[0;32m   2759\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data} \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Documents\\Anaconda\\lib\\site-packages\\matplotlib\\axes\\_axes.py:1632\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1390\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1391\u001b[0m \u001b[38;5;124;03mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[0;32m   1392\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1629\u001b[0m \u001b[38;5;124;03m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[0;32m   1630\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1631\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m cbook\u001b[38;5;241m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[38;5;241m.\u001b[39mLine2D)\n\u001b[1;32m-> 1632\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_lines(\u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39mdata, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)]\n\u001b[0;32m   1633\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m lines:\n\u001b[0;32m   1634\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_line(line)\n",
      "File \u001b[1;32m~\\Documents\\Anaconda\\lib\\site-packages\\matplotlib\\axes\\_base.py:312\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    310\u001b[0m     this \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    311\u001b[0m     args \u001b[38;5;241m=\u001b[39m args[\u001b[38;5;241m1\u001b[39m:]\n\u001b[1;32m--> 312\u001b[0m \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plot_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Documents\\Anaconda\\lib\\site-packages\\matplotlib\\axes\\_base.py:487\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[1;34m(self, tup, kwargs, return_kwargs)\u001b[0m\n\u001b[0;32m    484\u001b[0m         kw[prop_name] \u001b[38;5;241m=\u001b[39m val\n\u001b[0;32m    486\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(xy) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m--> 487\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43m_check_1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxy\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    488\u001b[0m     y \u001b[38;5;241m=\u001b[39m _check_1d(xy[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m    489\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Documents\\Anaconda\\lib\\site-packages\\matplotlib\\cbook\\__init__.py:1327\u001b[0m, in \u001b[0;36m_check_1d\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1321\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m warnings\u001b[38;5;241m.\u001b[39mcatch_warnings(record\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m w:\n\u001b[0;32m   1322\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\n\u001b[0;32m   1323\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malways\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1324\u001b[0m         category\u001b[38;5;241m=\u001b[39m\u001b[38;5;167;01mWarning\u001b[39;00m,\n\u001b[0;32m   1325\u001b[0m         message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSupport for multi-dimensional indexing\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1327\u001b[0m     ndim \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mndim\n\u001b[0;32m   1328\u001b[0m     \u001b[38;5;66;03m# we have definitely hit a pandas index or series object\u001b[39;00m\n\u001b[0;32m   1329\u001b[0m     \u001b[38;5;66;03m# cast to a numpy array.\u001b[39;00m\n\u001b[0;32m   1330\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(w) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\Documents\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py:3505\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3505\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3506\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3507\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\Documents\\Anaconda\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3628\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3623\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3624\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3625\u001b[0m         \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3626\u001b[0m         \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3627\u001b[0m         \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m-> 3628\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_indexing_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3629\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m   3631\u001b[0m \u001b[38;5;66;03m# GH#42269\u001b[39;00m\n",
      "File \u001b[1;32m~\\Documents\\Anaconda\\lib\\site-packages\\pandas\\core\\indexes\\base.py:5637\u001b[0m, in \u001b[0;36mIndex._check_indexing_error\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   5633\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_indexing_error\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m   5634\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scalar(key):\n\u001b[0;32m   5635\u001b[0m         \u001b[38;5;66;03m# if key is not a scalar, directly raise an error (the code below\u001b[39;00m\n\u001b[0;32m   5636\u001b[0m         \u001b[38;5;66;03m# would convert to numpy arrays and raise later any way) - GH29926\u001b[39;00m\n\u001b[1;32m-> 5637\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n",
      "\u001b[1;31mInvalidIndexError\u001b[0m: (slice(None, None, None), None)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(learning,loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
