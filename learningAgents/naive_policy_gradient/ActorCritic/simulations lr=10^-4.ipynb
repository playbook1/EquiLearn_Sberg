{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from learningActorCritic import ReinforceAlgorithm\n",
    "from environmentModel import Model, AdversaryModes\n",
    "from neuralNetwork import NeuralNetwork\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions import Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adversaryProbs=torch.zeros(len(AdversaryModes))\n",
    "adversaryProbs[0]=1\n",
    "adversaryProbs[1]=0\n",
    "adversaryProbs[8]=0\n",
    "game = Model(totalDemand = 400, \n",
    "               tupleCosts = (57, 71),\n",
    "              totalStages = 25, adversaryProbs=adversaryProbs, advHistoryNum=0)\n",
    "adversaryProbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  0.0000, 200.0000, 128.5000]), 0, False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135.5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game.adversaryChoosePrice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuralNet=NeuralNetwork(num_input=3+game.advHistoryNum, lr=0.0001)\n",
    "algorithm = ReinforceAlgorithm(game, neuralNet, numberIterations=1, numberEpisodes=1000_000, discountFactor =0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "0   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([ 4,  6,  2, 45, 26, 43,  3, 47, 23, 39, 23, 22, 38, 31, 40, 32, 30, 15,\n",
      "        41,  9, 46, 15,  5, 16, 17])\n",
      "loss=  tensor(1934.0676, grad_fn=<AddBackward0>)   , actor=  tensor(449.7137, grad_fn=<DivBackward0>)   , critic=  tensor(14843.5381, grad_fn=<SumBackward0>)   , return=  166956.53055921535\n",
      "probs of actions:  tensor([0.0222, 0.0149, 0.0183, 0.0189, 0.0198, 0.0213, 0.0179, 0.0209, 0.0193,\n",
      "        0.0221, 0.0193, 0.0191, 0.0256, 0.0242, 0.0207, 0.0157, 0.0205, 0.0205,\n",
      "        0.0191, 0.0217, 0.0213, 0.0201, 0.0193, 0.0204, 0.0187],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "1000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([27, 19, 41, 14, 23, 35, 38,  2, 14,  0, 22, 42, 16, 15, 30, 46, 25,  9,\n",
      "        33,  5,  2, 39, 25, 11, 34])\n",
      "loss=  tensor(1824.7794, grad_fn=<AddBackward0>)   , actor=  tensor(429.6995, grad_fn=<DivBackward0>)   , critic=  tensor(13950.7998, grad_fn=<SumBackward0>)   , return=  163880.7395040804\n",
      "probs of actions:  tensor([0.0246, 0.0223, 0.0212, 0.0222, 0.0196, 0.0143, 0.0246, 0.0191, 0.0224,\n",
      "        0.0173, 0.0203, 0.0221, 0.0226, 0.0234, 0.0220, 0.0225, 0.0199, 0.0182,\n",
      "        0.0238, 0.0201, 0.0195, 0.0190, 0.0202, 0.0152, 0.0286],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "2000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([48,  6, 42, 12, 49, 38, 14, 15,  6, 12, 18, 31,  0, 10,  6, 19, 17, 22,\n",
      "        27, 38, 39, 21, 45,  6,  5])\n",
      "loss=  tensor(1848.1609, grad_fn=<AddBackward0>)   , actor=  tensor(445.6644, grad_fn=<DivBackward0>)   , critic=  tensor(14024.9639, grad_fn=<SumBackward0>)   , return=  164268.36982155184\n",
      "probs of actions:  tensor([0.0118, 0.0142, 0.0237, 0.0183, 0.0210, 0.0226, 0.0222, 0.0247, 0.0143,\n",
      "        0.0188, 0.0159, 0.0226, 0.0171, 0.0194, 0.0144, 0.0203, 0.0200, 0.0221,\n",
      "        0.0192, 0.0211, 0.0167, 0.0181, 0.0233, 0.0147, 0.0214],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "3000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([35,  1, 19, 39, 42, 46, 26,  5, 40, 27, 39,  9, 13,  6, 22, 31, 15,  8,\n",
      "        33, 21, 25, 14, 43, 23, 27])\n",
      "loss=  tensor(1881.9005, grad_fn=<AddBackward0>)   , actor=  tensor(443.8128, grad_fn=<DivBackward0>)   , critic=  tensor(14380.8770, grad_fn=<SumBackward0>)   , return=  165712.64291598083\n",
      "probs of actions:  tensor([0.0137, 0.0211, 0.0221, 0.0156, 0.0236, 0.0247, 0.0188, 0.0203, 0.0268,\n",
      "        0.0211, 0.0158, 0.0176, 0.0131, 0.0139, 0.0236, 0.0204, 0.0255, 0.0202,\n",
      "        0.0264, 0.0170, 0.0197, 0.0203, 0.0179, 0.0219, 0.0202],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "4000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([ 3, 30, 20, 21, 10, 47, 43, 44, 36, 49, 34, 31,  7, 32, 26, 38, 34,  7,\n",
      "        47, 31, 37, 46, 45, 41, 36])\n",
      "loss=  tensor(1972.4824, grad_fn=<AddBackward0>)   , actor=  tensor(452.7652, grad_fn=<DivBackward0>)   , critic=  tensor(15197.1709, grad_fn=<SumBackward0>)   , return=  169661.78501027267\n",
      "probs of actions:  tensor([0.0185, 0.0274, 0.0214, 0.0158, 0.0190, 0.0219, 0.0188, 0.0161, 0.0172,\n",
      "        0.0229, 0.0307, 0.0248, 0.0175, 0.0165, 0.0185, 0.0172, 0.0303, 0.0176,\n",
      "        0.0223, 0.0242, 0.0170, 0.0232, 0.0279, 0.0214, 0.0179],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "5000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([ 1, 38, 24, 28, 33, 21,  2, 39, 33, 34, 25, 15, 28,  3, 15, 17, 22, 14,\n",
      "        48, 19, 35,  3, 46, 40,  4])\n",
      "loss=  tensor(1872.3132, grad_fn=<AddBackward0>)   , actor=  tensor(443.6362, grad_fn=<DivBackward0>)   , critic=  tensor(14286.7695, grad_fn=<SumBackward0>)   , return=  165526.84154119986\n",
      "probs of actions:  tensor([0.0193, 0.0178, 0.0179, 0.0146, 0.0294, 0.0151, 0.0192, 0.0121, 0.0299,\n",
      "        0.0306, 0.0198, 0.0271, 0.0150, 0.0175, 0.0269, 0.0185, 0.0257, 0.0206,\n",
      "        0.0091, 0.0223, 0.0123, 0.0178, 0.0256, 0.0310, 0.0181],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "6000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([11,  2, 33, 14, 47, 34, 47,  3, 40, 26,  0, 43, 46, 40,  9, 28,  9,  9,\n",
      "        47,  1, 16, 13, 12, 35, 32])\n",
      "loss=  tensor(1823.4182, grad_fn=<AddBackward0>)   , actor=  tensor(426.7574, grad_fn=<DivBackward0>)   , critic=  tensor(13966.6074, grad_fn=<SumBackward0>)   , return=  162863.4364112562\n",
      "probs of actions:  tensor([0.0152, 0.0194, 0.0309, 0.0210, 0.0290, 0.0304, 0.0290, 0.0178, 0.0329,\n",
      "        0.0175, 0.0161, 0.0175, 0.0241, 0.0321, 0.0154, 0.0163, 0.0154, 0.0153,\n",
      "        0.0294, 0.0211, 0.0197, 0.0112, 0.0262, 0.0119, 0.0212],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "7000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([34,  8,  2, 38, 41, 18, 24, 37, 38, 23, 41,  5, 23, 14, 43, 11,  1, 41,\n",
      "         5, 13, 43,  7, 26, 13,  6])\n",
      "loss=  tensor(1865.3514, grad_fn=<AddBackward0>)   , actor=  tensor(441.4802, grad_fn=<DivBackward0>)   , critic=  tensor(14238.7119, grad_fn=<SumBackward0>)   , return=  165023.83027266446\n",
      "probs of actions:  tensor([0.0294, 0.0187, 0.0192, 0.0179, 0.0228, 0.0136, 0.0172, 0.0157, 0.0176,\n",
      "        0.0246, 0.0229, 0.0263, 0.0246, 0.0188, 0.0194, 0.0155, 0.0218, 0.0228,\n",
      "        0.0261, 0.0111, 0.0195, 0.0187, 0.0193, 0.0113, 0.0136],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "8000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([35,  7, 27, 45,  4, 15, 29, 43, 18, 34, 17, 19, 24, 25, 22, 24, 32, 41,\n",
      "        27,  1, 35, 49, 13, 34, 19])\n",
      "loss=  tensor(1925.4965, grad_fn=<AddBackward0>)   , actor=  tensor(454.8486, grad_fn=<DivBackward0>)   , critic=  tensor(14706.4775, grad_fn=<SumBackward0>)   , return=  167577.48526414193\n",
      "probs of actions:  tensor([0.0103, 0.0171, 0.0192, 0.0239, 0.0182, 0.0272, 0.0157, 0.0204, 0.0123,\n",
      "        0.0277, 0.0203, 0.0183, 0.0164, 0.0190, 0.0242, 0.0166, 0.0279, 0.0234,\n",
      "        0.0179, 0.0220, 0.0101, 0.0226, 0.0113, 0.0269, 0.0189],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "9000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([16,  5, 24, 20, 33, 18, 32,  2, 43, 18,  5, 28, 28,  1, 12, 17, 16, 31,\n",
      "        20, 14, 30, 13, 31,  3, 40])\n",
      "loss=  tensor(1795.0070, grad_fn=<AddBackward0>)   , actor=  tensor(431.6086, grad_fn=<DivBackward0>)   , critic=  tensor(13633.9824, grad_fn=<SumBackward0>)   , return=  161942.90373772845\n",
      "probs of actions:  tensor([0.0208, 0.0221, 0.0144, 0.0215, 0.0341, 0.0127, 0.0299, 0.0196, 0.0196,\n",
      "        0.0128, 0.0221, 0.0142, 0.0141, 0.0240, 0.0291, 0.0194, 0.0202, 0.0208,\n",
      "        0.0213, 0.0153, 0.0190, 0.0110, 0.0207, 0.0183, 0.0349],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "10000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([43, 46, 32, 22, 42,  7, 12, 11, 47, 26,  5, 25, 40, 46, 23, 47, 46,  1,\n",
      "        49,  8,  0, 33,  2, 10, 14])\n",
      "loss=  tensor(1878.0314, grad_fn=<AddBackward0>)   , actor=  tensor(428.7307, grad_fn=<DivBackward0>)   , critic=  tensor(14493.0059, grad_fn=<SumBackward0>)   , return=  166296.12745740308\n",
      "probs of actions:  tensor([0.0187, 0.0165, 0.0281, 0.0207, 0.0321, 0.0171, 0.0308, 0.0121, 0.0291,\n",
      "        0.0235, 0.0233, 0.0196, 0.0518, 0.0167, 0.0272, 0.0294, 0.0169, 0.0200,\n",
      "        0.0244, 0.0190, 0.0151, 0.0372, 0.0219, 0.0226, 0.0137],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "11000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([11,  9,  1, 36, 38, 41, 40, 49,  0, 32, 15, 10, 33, 37, 47, 22, 14, 31,\n",
      "        16, 43, 33, 46, 32,  7, 37])\n",
      "loss=  tensor(1904.5972, grad_fn=<AddBackward0>)   , actor=  tensor(436.8900, grad_fn=<DivBackward0>)   , critic=  tensor(14677.0713, grad_fn=<SumBackward0>)   , return=  166824.91116603822\n",
      "probs of actions:  tensor([0.0113, 0.0147, 0.0194, 0.0145, 0.0214, 0.0252, 0.0499, 0.0241, 0.0149,\n",
      "        0.0291, 0.0300, 0.0243, 0.0387, 0.0159, 0.0293, 0.0194, 0.0142, 0.0218,\n",
      "        0.0226, 0.0209, 0.0386, 0.0206, 0.0285, 0.0170, 0.0162],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "12000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([36,  9, 46,  0, 16, 31, 26, 14, 40, 27, 31, 34, 40,  9,  4,  7, 30, 19,\n",
      "         5, 32, 11, 11, 43,  8, 30])\n",
      "loss=  tensor(1834.4082, grad_fn=<AddBackward0>)   , actor=  tensor(430.4747, grad_fn=<DivBackward0>)   , critic=  tensor(14039.3350, grad_fn=<SumBackward0>)   , return=  163708.8136166578\n",
      "probs of actions:  tensor([0.0158, 0.0149, 0.0186, 0.0144, 0.0233, 0.0228, 0.0254, 0.0151, 0.0578,\n",
      "        0.0142, 0.0225, 0.0308, 0.0570, 0.0147, 0.0189, 0.0180, 0.0206, 0.0182,\n",
      "        0.0236, 0.0290, 0.0109, 0.0109, 0.0190, 0.0207, 0.0203],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "13000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([ 7, 29, 11, 42, 43, 22, 46, 37, 23, 14, 16, 37,  8, 20, 17, 22, 40, 47,\n",
      "        15, 34, 47, 28, 31, 38,  2])\n",
      "loss=  tensor(1951.2400, grad_fn=<AddBackward0>)   , actor=  tensor(448.0898, grad_fn=<DivBackward0>)   , critic=  tensor(15031.5020, grad_fn=<SumBackward0>)   , return=  169431.23905832306\n",
      "probs of actions:  tensor([0.0205, 0.0141, 0.0090, 0.0257, 0.0182, 0.0206, 0.0159, 0.0177, 0.0362,\n",
      "        0.0167, 0.0248, 0.0179, 0.0204, 0.0174, 0.0174, 0.0210, 0.0741, 0.0345,\n",
      "        0.0324, 0.0371, 0.0346, 0.0117, 0.0201, 0.0223, 0.0166],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "14000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([29, 30, 14, 40, 33, 45, 40, 20, 40, 16, 25,  9, 12,  7, 22, 29, 41, 38,\n",
      "        49, 47, 35, 46,  4, 16, 10])\n",
      "loss=  tensor(1949.6801, grad_fn=<AddBackward0>)   , actor=  tensor(432.3452, grad_fn=<DivBackward0>)   , critic=  tensor(15173.3486, grad_fn=<SumBackward0>)   , return=  170616.16500920325\n",
      "probs of actions:  tensor([0.0157, 0.0229, 0.0178, 0.0716, 0.0254, 0.0201, 0.0722, 0.0153, 0.0722,\n",
      "        0.0255, 0.0183, 0.0149, 0.0285, 0.0174, 0.0228, 0.0159, 0.0234, 0.0223,\n",
      "        0.0300, 0.0431, 0.0070, 0.0171, 0.0173, 0.0253, 0.0220],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "15000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([ 5, 23, 45, 40, 40, 45, 49, 40,  9,  1, 18,  3,  3, 47, 40, 34, 27,  5,\n",
      "        42,  9, 44, 12, 32, 11, 48])\n",
      "loss=  tensor(1825.0857, grad_fn=<AddBackward0>)   , actor=  tensor(409.3825, grad_fn=<DivBackward0>)   , critic=  tensor(14157.0312, grad_fn=<SumBackward0>)   , return=  164185.47198932868\n",
      "probs of actions:  tensor([0.0232, 0.0421, 0.0208, 0.0666, 0.0668, 0.0208, 0.0315, 0.0669, 0.0165,\n",
      "        0.0176, 0.0061, 0.0118, 0.0119, 0.0408, 0.0651, 0.0365, 0.0133, 0.0236,\n",
      "        0.0275, 0.0166, 0.0137, 0.0275, 0.0262, 0.0073, 0.0043],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "16000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([ 4, 23, 23, 15, 15,  6, 34, 47,  5, 34, 40,  5, 46,  1, 17, 47, 16, 29,\n",
      "        16,  0, 32, 15, 27, 26, 10])\n",
      "loss=  tensor(1804.6067, grad_fn=<AddBackward0>)   , actor=  tensor(412.3293, grad_fn=<DivBackward0>)   , critic=  tensor(13922.7744, grad_fn=<SumBackward0>)   , return=  163462.37097280342\n",
      "probs of actions:  tensor([0.0126, 0.0406, 0.0408, 0.0284, 0.0285, 0.0049, 0.0490, 0.0490, 0.0247,\n",
      "        0.0490, 0.0661, 0.0246, 0.0174, 0.0154, 0.0159, 0.0498, 0.0183, 0.0175,\n",
      "        0.0184, 0.0086, 0.0226, 0.0271, 0.0120, 0.0284, 0.0261],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "17000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([ 9, 33, 12, 10, 40,  9, 33, 27, 47, 17, 34, 21, 32, 12, 33, 38, 34, 29,\n",
      "        21, 15,  5, 49, 33, 41, 47])\n",
      "loss=  tensor(1850.6973, grad_fn=<AddBackward0>)   , actor=  tensor(405.6036, grad_fn=<DivBackward0>)   , critic=  tensor(14450.9365, grad_fn=<SumBackward0>)   , return=  165686.45954345565\n",
      "probs of actions:  tensor([0.0222, 0.0276, 0.0338, 0.0271, 0.0618, 0.0225, 0.0279, 0.0144, 0.0486,\n",
      "        0.0163, 0.0440, 0.0212, 0.0199, 0.0339, 0.0283, 0.0307, 0.0434, 0.0146,\n",
      "        0.0219, 0.0313, 0.0213, 0.0254, 0.0285, 0.0250, 0.0490],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "18000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([30, 26, 41, 38, 48, 15, 33, 49,  3, 32, 30, 19,  5, 20, 40, 32, 33, 35,\n",
      "        49, 23, 23, 12, 15, 14, 10])\n",
      "loss=  tensor(1984.0735, grad_fn=<AddBackward0>)   , actor=  tensor(458.5512, grad_fn=<DivBackward0>)   , critic=  tensor(15255.2217, grad_fn=<SumBackward0>)   , return=  170484.28355169322\n",
      "probs of actions:  tensor([0.0151, 0.0284, 0.0213, 0.0317, 0.0035, 0.0317, 0.0273, 0.0223, 0.0093,\n",
      "        0.0202, 0.0142, 0.0142, 0.0222, 0.0115, 0.0540, 0.0201, 0.0277, 0.0052,\n",
      "        0.0227, 0.0436, 0.0438, 0.0438, 0.0306, 0.0177, 0.0309],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "19000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([34, 36, 40, 23, 43, 10, 17,  5, 12, 22, 12, 19, 33, 23, 38, 12, 25, 49,\n",
      "         8,  2,  1, 40, 38, 45, 43])\n",
      "loss=  tensor(1779.5568, grad_fn=<AddBackward0>)   , actor=  tensor(400.8188, grad_fn=<DivBackward0>)   , critic=  tensor(13787.3789, grad_fn=<SumBackward0>)   , return=  163054.3484651628\n",
      "probs of actions:  tensor([0.0570, 0.0102, 0.0509, 0.0413, 0.0211, 0.0270, 0.0135, 0.0242, 0.0496,\n",
      "        0.0190, 0.0493, 0.0123, 0.0257, 0.0424, 0.0294, 0.0488, 0.0136, 0.0245,\n",
      "        0.0146, 0.0117, 0.0146, 0.0495, 0.0292, 0.0250, 0.0211],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "20000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([42, 12, 41, 46, 14, 31, 40, 31, 40, 30, 34, 43, 23,  9, 34, 33, 27, 22,\n",
      "        14,  7, 10, 27, 38, 38, 40])\n",
      "loss=  tensor(1910.5619, grad_fn=<AddBackward0>)   , actor=  tensor(404.5587, grad_fn=<DivBackward0>)   , critic=  tensor(15060.0312, grad_fn=<SumBackward0>)   , return=  168666.25417203968\n",
      "probs of actions:  tensor([0.0316, 0.0529, 0.0219, 0.0200, 0.0195, 0.0383, 0.0522, 0.0382, 0.0522,\n",
      "        0.0153, 0.0560, 0.0206, 0.0415, 0.0223, 0.0555, 0.0261, 0.0159, 0.0189,\n",
      "        0.0190, 0.0204, 0.0294, 0.0157, 0.0286, 0.0286, 0.0494],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "21000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([43, 31, 38, 45, 40, 30, 13, 10, 28, 30, 22, 34, 12, 34, 17, 35, 40, 14,\n",
      "        34, 47,  4, 26, 34, 38, 47])\n",
      "loss=  tensor(1912.7351, grad_fn=<AddBackward0>)   , actor=  tensor(424.3539, grad_fn=<DivBackward0>)   , critic=  tensor(14883.8105, grad_fn=<SumBackward0>)   , return=  168409.66633387658\n",
      "probs of actions:  tensor([0.0228, 0.0345, 0.0274, 0.0289, 0.0611, 0.0160, 0.0055, 0.0261, 0.0081,\n",
      "        0.0157, 0.0156, 0.0582, 0.0615, 0.0580, 0.0124, 0.0062, 0.0595, 0.0186,\n",
      "        0.0573, 0.0517, 0.0164, 0.0232, 0.0564, 0.0262, 0.0516],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "22000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([38, 46, 34, 47, 22,  7, 32, 43, 34,  5, 43, 32, 31, 29, 31, 29, 23, 34,\n",
      "        23, 30,  5, 32, 27, 44, 33])\n",
      "loss=  tensor(1954.1024, grad_fn=<AddBackward0>)   , actor=  tensor(425.2961, grad_fn=<DivBackward0>)   , critic=  tensor(15288.0635, grad_fn=<SumBackward0>)   , return=  170152.6350041157\n",
      "probs of actions:  tensor([0.0233, 0.0186, 0.0592, 0.0468, 0.0165, 0.0199, 0.0177, 0.0229, 0.0601,\n",
      "        0.0203, 0.0225, 0.0176, 0.0341, 0.0131, 0.0338, 0.0132, 0.0482, 0.0590,\n",
      "        0.0480, 0.0166, 0.0205, 0.0178, 0.0162, 0.0078, 0.0358],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "23000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([ 1, 23,  7, 40, 40, 12, 42, 43, 26, 15, 15, 34, 12, 27, 45,  7, 23, 15,\n",
      "        21, 12, 34, 48, 38, 12, 26])\n",
      "loss=  tensor(1832.5764, grad_fn=<AddBackward0>)   , actor=  tensor(382.9427, grad_fn=<DivBackward0>)   , critic=  tensor(14496.3359, grad_fn=<SumBackward0>)   , return=  166122.25052608163\n",
      "probs of actions:  tensor([0.0169, 0.0425, 0.0223, 0.0693, 0.0698, 0.0642, 0.0244, 0.0307, 0.0233,\n",
      "        0.0390, 0.0390, 0.0516, 0.0647, 0.0185, 0.0377, 0.0218, 0.0435, 0.0381,\n",
      "        0.0174, 0.0641, 0.0505, 0.0035, 0.0183, 0.0634, 0.0236],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "24000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([42, 14, 23, 45, 12, 47, 33, 35, 45, 21, 43,  4, 34, 34, 38, 22, 43, 47,\n",
      "         2, 30, 23, 23, 42, 40, 19])\n",
      "loss=  tensor(1941.1002, grad_fn=<AddBackward0>)   , actor=  tensor(411.2881, grad_fn=<DivBackward0>)   , critic=  tensor(15298.1211, grad_fn=<SumBackward0>)   , return=  170392.35371716938\n",
      "probs of actions:  tensor([0.0271, 0.0180, 0.0488, 0.0418, 0.0598, 0.0474, 0.0315, 0.0061, 0.0424,\n",
      "        0.0153, 0.0333, 0.0175, 0.0644, 0.0641, 0.0230, 0.0156, 0.0331, 0.0481,\n",
      "        0.0138, 0.0141, 0.0498, 0.0498, 0.0262, 0.0639, 0.0098],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "25000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([49, 33, 43, 19, 12, 35, 33, 16, 15, 23, 43, 42, 38, 40, 38,  4, 38, 31,\n",
      "        34, 43, 33, 44, 40, 23, 37])\n",
      "loss=  tensor(1978.7489, grad_fn=<AddBackward0>)   , actor=  tensor(430.5833, grad_fn=<DivBackward0>)   , critic=  tensor(15481.6562, grad_fn=<SumBackward0>)   , return=  171523.86665746494\n",
      "probs of actions:  tensor([0.0169, 0.0315, 0.0267, 0.0081, 0.0493, 0.0063, 0.0318, 0.0131, 0.0330,\n",
      "        0.0517, 0.0265, 0.0283, 0.0244, 0.0920, 0.0243, 0.0136, 0.0240, 0.0392,\n",
      "        0.0685, 0.0266, 0.0323, 0.0076, 0.0867, 0.0511, 0.0189],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "26000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([10, 37,  2, 31, 34,  3, 45,  7, 37, 40, 34, 27, 11,  2, 21,  9, 23, 33,\n",
      "        26, 20, 49, 13, 30, 32, 34])\n",
      "loss=  tensor(1850.4479, grad_fn=<AddBackward0>)   , actor=  tensor(434.2155, grad_fn=<DivBackward0>)   , critic=  tensor(14162.3223, grad_fn=<SumBackward0>)   , return=  164493.95772424008\n",
      "probs of actions:  tensor([0.0196, 0.0176, 0.0105, 0.0449, 0.0690, 0.0069, 0.0307, 0.0218, 0.0178,\n",
      "        0.0738, 0.0695, 0.0153, 0.0058, 0.0106, 0.0170, 0.0250, 0.0478, 0.0325,\n",
      "        0.0213, 0.0058, 0.0167, 0.0052, 0.0142, 0.0133, 0.0666],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "27000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 24, 22, 45,  7,  5, 23, 40, 15, 26, 45, 32, 40,  9, 31, 15,  8, 12,\n",
      "        45, 44, 34, 27, 43,  0,  8])\n",
      "loss=  tensor(1891.5154, grad_fn=<AddBackward0>)   , actor=  tensor(416.3406, grad_fn=<DivBackward0>)   , critic=  tensor(14751.7480, grad_fn=<SumBackward0>)   , return=  168126.3379276226\n",
      "probs of actions:  tensor([0.0782, 0.0076, 0.0134, 0.0265, 0.0220, 0.0201, 0.0511, 0.0801, 0.0322,\n",
      "        0.0177, 0.0266, 0.0131, 0.0787, 0.0219, 0.0372, 0.0316, 0.0178, 0.0618,\n",
      "        0.0268, 0.0095, 0.0565, 0.0148, 0.0343, 0.0043, 0.0179],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "28000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([33,  9, 14, 37, 10,  4, 12, 26, 40, 23, 31, 47, 45,  2, 47, 46, 41, 21,\n",
      "        23,  8, 38, 40, 23, 30, 47])\n",
      "loss=  tensor(1852.0168, grad_fn=<AddBackward0>)   , actor=  tensor(406.4398, grad_fn=<DivBackward0>)   , critic=  tensor(14455.7695, grad_fn=<SumBackward0>)   , return=  165905.5261654769\n",
      "probs of actions:  tensor([0.0338, 0.0196, 0.0134, 0.0179, 0.0169, 0.0084, 0.0635, 0.0180, 0.0853,\n",
      "        0.0616, 0.0368, 0.0594, 0.0283, 0.0113, 0.0594, 0.0138, 0.0287, 0.0146,\n",
      "        0.0618, 0.0209, 0.0254, 0.0782, 0.0609, 0.0147, 0.0585],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "29000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([44, 45, 26, 32, 31, 12, 40, 25, 38, 42,  1, 40, 32, 40, 27, 33, 32, 37,\n",
      "        17, 10, 26, 46, 49, 45, 42])\n",
      "loss=  tensor(1941.8411, grad_fn=<AddBackward0>)   , actor=  tensor(425.8026, grad_fn=<DivBackward0>)   , critic=  tensor(15160.3838, grad_fn=<SumBackward0>)   , return=  169737.0666486782\n",
      "probs of actions:  tensor([0.0067, 0.0291, 0.0172, 0.0144, 0.0406, 0.0681, 0.1030, 0.0131, 0.0238,\n",
      "        0.0247, 0.0179, 0.1011, 0.0145, 0.1002, 0.0217, 0.0351, 0.0147, 0.0194,\n",
      "        0.0108, 0.0203, 0.0170, 0.0144, 0.0130, 0.0288, 0.0245],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "30000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([39,  1, 49, 40, 23, 26,  5, 16, 33, 30, 34,  1, 40, 30, 12, 38,  5, 24,\n",
      "        40, 22, 12, 43,  7, 25, 47])\n",
      "loss=  tensor(1837.3821, grad_fn=<AddBackward0>)   , actor=  tensor(416.6577, grad_fn=<DivBackward0>)   , critic=  tensor(14207.2432, grad_fn=<SumBackward0>)   , return=  164343.2286534562\n",
      "probs of actions:  tensor([0.0035, 0.0178, 0.0092, 0.1357, 0.0713, 0.0171, 0.0185, 0.0088, 0.0344,\n",
      "        0.0107, 0.0543, 0.0177, 0.1330, 0.0107, 0.0631, 0.0266, 0.0191, 0.0062,\n",
      "        0.1262, 0.0135, 0.0627, 0.0322, 0.0210, 0.0135, 0.0600],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "31000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([45, 16, 47, 37, 24, 17, 14, 15,  9,  3, 12, 38, 23, 42, 27, 10, 15,  3,\n",
      "        40, 13, 12, 43, 40, 32, 47])\n",
      "loss=  tensor(1809.8481, grad_fn=<AddBackward0>)   , actor=  tensor(429.6126, grad_fn=<DivBackward0>)   , critic=  tensor(13802.3555, grad_fn=<SumBackward0>)   , return=  162979.0427944121\n",
      "probs of actions:  tensor([0.0337, 0.0070, 0.0698, 0.0144, 0.0051, 0.0095, 0.0123, 0.0217, 0.0217,\n",
      "        0.0067, 0.0580, 0.0278, 0.0679, 0.0186, 0.0238, 0.0262, 0.0213, 0.0071,\n",
      "        0.1137, 0.0046, 0.0569, 0.0409, 0.1099, 0.0113, 0.0707],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "32000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([23,  7, 42, 26,  9, 14, 38, 40, 35,  5, 47, 23, 17, 40, 17, 23, 12,  1,\n",
      "        28, 12, 40,  9, 31, 31, 40])\n",
      "loss=  tensor(1810.2644, grad_fn=<AddBackward0>)   , actor=  tensor(397.7045, grad_fn=<DivBackward0>)   , critic=  tensor(14125.5986, grad_fn=<SumBackward0>)   , return=  164266.18039263558\n",
      "probs of actions:  tensor([0.0639, 0.0230, 0.0178, 0.0179, 0.0226, 0.0141, 0.0274, 0.1680, 0.0049,\n",
      "        0.0193, 0.0781, 0.0677, 0.0073, 0.1637, 0.0074, 0.0684, 0.0406, 0.0216,\n",
      "        0.0034, 0.0405, 0.1535, 0.0227, 0.0344, 0.0344, 0.1486],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "33000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([31,  8, 40, 23,  2, 40, 27,  8, 40, 40, 38, 31, 36, 33, 47, 40, 41, 43,\n",
      "        38, 47, 30, 27, 41, 45, 31])\n",
      "loss=  tensor(1942.7634, grad_fn=<AddBackward0>)   , actor=  tensor(382.7814, grad_fn=<DivBackward0>)   , critic=  tensor(15599.8203, grad_fn=<SumBackward0>)   , return=  171807.71165710632\n",
      "probs of actions:  tensor([0.0398, 0.0120, 0.2224, 0.0771, 0.0047, 0.2258, 0.0165, 0.0115, 0.2256,\n",
      "        0.2243, 0.0222, 0.0385, 0.0066, 0.0281, 0.0922, 0.2150, 0.0234, 0.0344,\n",
      "        0.0222, 0.0918, 0.0097, 0.0164, 0.0235, 0.0298, 0.0378],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "34000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([47, 41, 16, 31, 42, 23, 12, 15, 43, 40, 42,  7, 40, 47, 34,  1, 40, 47,\n",
      "        40, 45, 31, 40, 49, 47, 21])\n",
      "loss=  tensor(1899.3230, grad_fn=<AddBackward0>)   , actor=  tensor(364.4943, grad_fn=<DivBackward0>)   , critic=  tensor(15348.2871, grad_fn=<SumBackward0>)   , return=  171174.61292724346\n",
      "probs of actions:  tensor([0.0884, 0.0324, 0.0044, 0.0428, 0.0224, 0.0714, 0.0350, 0.0156, 0.0285,\n",
      "        0.2603, 0.0221, 0.0174, 0.2572, 0.0927, 0.0400, 0.0158, 0.2488, 0.0925,\n",
      "        0.2424, 0.0338, 0.0416, 0.2376, 0.0083, 0.0919, 0.0204],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "35000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([23, 45, 45, 31, 38, 38, 40, 40, 41, 40, 40, 40, 40, 47, 21, 40, 15,  1,\n",
      "        40, 40, 37, 27, 26,  1, 40])\n",
      "loss=  tensor(1906.9243, grad_fn=<AddBackward0>)   , actor=  tensor(312.2659, grad_fn=<DivBackward0>)   , critic=  tensor(15946.5830, grad_fn=<SumBackward0>)   , return=  173154.96749020036\n",
      "probs of actions:  tensor([0.0459, 0.0303, 0.0301, 0.0377, 0.0159, 0.0158, 0.3803, 0.3808, 0.0336,\n",
      "        0.3799, 0.3787, 0.3769, 0.3748, 0.0966, 0.0162, 0.3677, 0.0091, 0.0144,\n",
      "        0.3555, 0.3486, 0.0081, 0.0154, 0.0158, 0.0151, 0.3366],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "36000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 47, 40, 40, 26, 33,  4, 12, 45, 40, 43, 40, 43, 45, 40, 45, 46, 47,\n",
      "        34, 40, 45, 23, 38, 33, 41])\n",
      "loss=  tensor(1940.4596, grad_fn=<AddBackward0>)   , actor=  tensor(329.1897, grad_fn=<DivBackward0>)   , critic=  tensor(16112.6992, grad_fn=<SumBackward0>)   , return=  174242.14052957445\n",
      "probs of actions:  tensor([0.3594, 0.0779, 0.3699, 0.3752, 0.0162, 0.0290, 0.0022, 0.0293, 0.0435,\n",
      "        0.3813, 0.0323, 0.3797, 0.0323, 0.0437, 0.3731, 0.0438, 0.0068, 0.0816,\n",
      "        0.0452, 0.3589, 0.0442, 0.0456, 0.0144, 0.0317, 0.0309],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "37000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([47, 40, 47, 40, 43, 34, 21, 40, 47, 43, 22, 40, 40, 36, 47, 34, 47, 21,\n",
      "        26, 27, 37,  3, 27, 40, 40])\n",
      "loss=  tensor(1950.2042, grad_fn=<AddBackward0>)   , actor=  tensor(338.7780, grad_fn=<DivBackward0>)   , critic=  tensor(16114.2617, grad_fn=<SumBackward0>)   , return=  173621.9703902889\n",
      "probs of actions:  tensor([0.0974, 0.3161, 0.0987, 0.3241, 0.0411, 0.0424, 0.0174, 0.3316, 0.1018,\n",
      "        0.0409, 0.0055, 0.3282, 0.3253, 0.0036, 0.1029, 0.0429, 0.1031, 0.0189,\n",
      "        0.0154, 0.0201, 0.0083, 0.0032, 0.0203, 0.2936, 0.2913],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "38000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([31, 40, 40, 27, 43, 40, 12, 34, 40, 34, 40, 45,  5, 47, 40, 26, 40, 45,\n",
      "        27, 46, 40, 47, 40, 47, 23])\n",
      "loss=  tensor(1903.6860, grad_fn=<AddBackward0>)   , actor=  tensor(308.3848, grad_fn=<DivBackward0>)   , critic=  tensor(15953.0127, grad_fn=<SumBackward0>)   , return=  174210.27376657238\n",
      "probs of actions:  tensor([0.0357, 0.2630, 0.2657, 0.0245, 0.0462, 0.2714, 0.0219, 0.0524, 0.2722,\n",
      "        0.0524, 0.2704, 0.0591, 0.0099, 0.1049, 0.2614, 0.0177, 0.2590, 0.0589,\n",
      "        0.0239, 0.0109, 0.2479, 0.1039, 0.2440, 0.1037, 0.0316],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "39000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([35, 40, 40, 45, 41, 47, 45, 40, 30, 10, 21, 40, 40, 45, 41, 43, 43, 47,\n",
      "         3, 28, 47, 40, 23,  4, 40])\n",
      "loss=  tensor(1950.4392, grad_fn=<AddBackward0>)   , actor=  tensor(352.0874, grad_fn=<DivBackward0>)   , critic=  tensor(15983.5176, grad_fn=<SumBackward0>)   , return=  173537.06367083805\n",
      "probs of actions:  tensor([0.0070, 0.3138, 0.3174, 0.0649, 0.0375, 0.0956, 0.0651, 0.3256, 0.0050,\n",
      "        0.0148, 0.0172, 0.3212, 0.3183, 0.0654, 0.0377, 0.0436, 0.0437, 0.0974,\n",
      "        0.0020, 0.0024, 0.0976, 0.2916, 0.0315, 0.0028, 0.2852],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "40000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([47, 41, 43, 47, 34, 40, 34, 40, 38, 43, 40, 14, 27, 41, 21, 47, 40, 47,\n",
      "        26, 14, 40, 45, 42, 40, 40])\n",
      "loss=  tensor(1938.1335, grad_fn=<AddBackward0>)   , actor=  tensor(327.5223, grad_fn=<DivBackward0>)   , critic=  tensor(16106.1123, grad_fn=<SumBackward0>)   , return=  174154.0815492963\n",
      "probs of actions:  tensor([0.1075, 0.0394, 0.0539, 0.1100, 0.0622, 0.2445, 0.0625, 0.2444, 0.0167,\n",
      "        0.0539, 0.2411, 0.0127, 0.0204, 0.0395, 0.0272, 0.1126, 0.2278, 0.1121,\n",
      "        0.0179, 0.0130, 0.2197, 0.0486, 0.0390, 0.2132, 0.2114],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "41000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 36, 27, 40, 40, 40, 33, 40, 40,  2, 41, 30, 34, 40, 10, 38, 26, 12,\n",
      "        40, 40, 26, 46, 40, 45, 34])\n",
      "loss=  tensor(1899.1803, grad_fn=<AddBackward0>)   , actor=  tensor(346.5873, grad_fn=<DivBackward0>)   , critic=  tensor(15525.9297, grad_fn=<SumBackward0>)   , return=  171922.08809270166\n",
      "probs of actions:  tensor([0.2581, 0.0044, 0.0231, 0.2682, 0.2693, 0.2704, 0.0288, 0.2712, 0.2704,\n",
      "        0.0042, 0.0332, 0.0052, 0.0502, 0.2624, 0.0142, 0.0137, 0.0178, 0.0182,\n",
      "        0.2497, 0.2455, 0.0180, 0.0114, 0.2393, 0.0491, 0.0505],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "42000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([34, 32, 43,  3, 25, 40, 32, 41, 45, 42, 38, 40, 23, 38, 21, 40, 40, 41,\n",
      "        45, 21, 42, 40, 11, 40, 40])\n",
      "loss=  tensor(1990.8116, grad_fn=<AddBackward0>)   , actor=  tensor(405.9772, grad_fn=<DivBackward0>)   , critic=  tensor(15848.3447, grad_fn=<SumBackward0>)   , return=  172826.86316042294\n",
      "probs of actions:  tensor([0.0458, 0.0094, 0.0414, 0.0028, 0.0064, 0.2702, 0.0091, 0.0262, 0.0484,\n",
      "        0.0272, 0.0146, 0.2665, 0.0296, 0.0145, 0.0299, 0.2582, 0.2546, 0.0263,\n",
      "        0.0485, 0.0307, 0.0276, 0.2427, 0.0031, 0.2395, 0.2349],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "43000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([34,  2, 15, 33, 15,  9, 43, 34, 47,  8, 40, 29, 41, 47, 27, 43, 43, 33,\n",
      "        21, 40, 43, 31, 30, 47, 26])\n",
      "loss=  tensor(1934.7596, grad_fn=<AddBackward0>)   , actor=  tensor(398.5946, grad_fn=<DivBackward0>)   , critic=  tensor(15361.6504, grad_fn=<SumBackward0>)   , return=  170501.07910383225\n",
      "probs of actions:  tensor([0.0544, 0.0051, 0.0120, 0.0352, 0.0117, 0.0191, 0.0518, 0.0551, 0.1433,\n",
      "        0.0156, 0.1661, 0.0102, 0.0251, 0.1432, 0.0232, 0.0520, 0.0523, 0.0361,\n",
      "        0.0333, 0.1565, 0.0520, 0.0250, 0.0060, 0.1392, 0.0197],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "44000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([41, 40, 47, 40,  7, 27, 44, 47,  9, 34, 23, 47, 41, 45, 42, 40, 46,  9,\n",
      "         8, 27, 45, 34, 26, 28, 21])\n",
      "loss=  tensor(1958.9130, grad_fn=<AddBackward0>)   , actor=  tensor(385.0005, grad_fn=<DivBackward0>)   , critic=  tensor(15739.1250, grad_fn=<SumBackward0>)   , return=  172462.66492684738\n",
      "probs of actions:  tensor([0.0256, 0.1684, 0.1276, 0.1715, 0.0093, 0.0281, 0.0051, 0.1321, 0.0162,\n",
      "        0.0408, 0.0323, 0.1337, 0.0250, 0.0728, 0.0324, 0.1681, 0.0106, 0.0161,\n",
      "        0.0155, 0.0275, 0.0714, 0.0410, 0.0228, 0.0053, 0.0319],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "45000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([31, 40, 47, 23, 47, 45, 45, 33,  5, 42, 47, 46, 25, 42, 42, 47, 21, 40,\n",
      "        15, 31, 21, 13, 34, 10, 47])\n",
      "loss=  tensor(1942.5558, grad_fn=<AddBackward0>)   , actor=  tensor(369.1435, grad_fn=<DivBackward0>)   , critic=  tensor(15734.1230, grad_fn=<SumBackward0>)   , return=  171770.52927745812\n",
      "probs of actions:  tensor([0.0367, 0.1775, 0.1327, 0.0306, 0.1355, 0.0564, 0.0565, 0.0387, 0.0102,\n",
      "        0.0400, 0.1382, 0.0102, 0.0097, 0.0396, 0.0394, 0.1376, 0.0290, 0.1733,\n",
      "        0.0118, 0.0355, 0.0296, 0.0036, 0.0484, 0.0159, 0.1342],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "46000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([42, 16, 26, 49, 23, 31,  0, 30, 43,  5, 42, 17, 40, 26, 41, 47, 41, 40,\n",
      "        42, 41, 40, 43, 25, 45, 47])\n",
      "loss=  tensor(1953.8489, grad_fn=<AddBackward0>)   , actor=  tensor(434.0124, grad_fn=<DivBackward0>)   , critic=  tensor(15198.3652, grad_fn=<SumBackward0>)   , return=  169956.35907053328\n",
      "probs of actions:  tensor([0.0664, 0.0059, 0.0231, 0.0046, 0.0360, 0.0355, 0.0022, 0.0058, 0.0473,\n",
      "        0.0084, 0.0670, 0.0028, 0.1884, 0.0227, 0.0274, 0.1004, 0.0274, 0.1820,\n",
      "        0.0652, 0.0274, 0.1773, 0.0474, 0.0118, 0.0489, 0.0990],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "47000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 38, 40, 47, 42, 42, 47, 23, 40, 23, 41, 43, 33, 29, 43, 40, 47, 33,\n",
      "        31, 40, 47, 31, 43, 25,  9])\n",
      "loss=  tensor(2022.1404, grad_fn=<AddBackward0>)   , actor=  tensor(347.9472, grad_fn=<DivBackward0>)   , critic=  tensor(16741.9316, grad_fn=<SumBackward0>)   , return=  177577.44162311134\n",
      "probs of actions:  tensor([0.1659, 0.0163, 0.1702, 0.1141, 0.0511, 0.0512, 0.1166, 0.0397, 0.1727,\n",
      "        0.0398, 0.0285, 0.0441, 0.0342, 0.0145, 0.0439, 0.1654, 0.1182, 0.0345,\n",
      "        0.0311, 0.1602, 0.1172, 0.0312, 0.0440, 0.0121, 0.0124],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "48000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([21, 42, 47, 29, 10, 27, 23, 47, 46, 47, 46, 40, 40, 26, 23, 10, 43, 40,\n",
      "        12,  3, 40, 47, 42, 45, 42])\n",
      "loss=  tensor(1895.0851, grad_fn=<AddBackward0>)   , actor=  tensor(372.1323, grad_fn=<DivBackward0>)   , critic=  tensor(15229.5273, grad_fn=<SumBackward0>)   , return=  169782.09082993094\n",
      "probs of actions:  tensor([0.0332, 0.0514, 0.1662, 0.0133, 0.0083, 0.0293, 0.0435, 0.1740, 0.0117,\n",
      "        0.1740, 0.0116, 0.1651, 0.1643, 0.0196, 0.0438, 0.0085, 0.0431, 0.1571,\n",
      "        0.0139, 0.0030, 0.1535, 0.1687, 0.0493, 0.0403, 0.0492],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "49000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([45, 42, 40, 40, 10, 23, 41, 42, 42, 47, 41, 40, 34, 11, 40, 40, 40, 40,\n",
      "        43, 34, 40, 34, 33, 12, 47])\n",
      "loss=  tensor(1949.2179, grad_fn=<AddBackward0>)   , actor=  tensor(336.9052, grad_fn=<DivBackward0>)   , critic=  tensor(16123.1270, grad_fn=<SumBackward0>)   , return=  174024.07765591634\n",
      "probs of actions:  tensor([0.0574, 0.0568, 0.1534, 0.1547, 0.0082, 0.0378, 0.0378, 0.0567, 0.0566,\n",
      "        0.1630, 0.0376, 0.1561, 0.0757, 0.0015, 0.1535, 0.1525, 0.1519, 0.1510,\n",
      "        0.0367, 0.0752, 0.1482, 0.0750, 0.0335, 0.0109, 0.1593],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "50000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([47, 40, 33, 43, 10, 23, 42, 21, 40, 47, 40, 40, 40, 40, 34, 40, 40, 47,\n",
      "        40, 31, 31, 43, 10, 43, 47])\n",
      "loss=  tensor(1897.4397, grad_fn=<AddBackward0>)   , actor=  tensor(295.2003, grad_fn=<DivBackward0>)   , critic=  tensor(16022.3936, grad_fn=<SumBackward0>)   , return=  173390.75777404525\n",
      "probs of actions:  tensor([0.1487, 0.2400, 0.0275, 0.0313, 0.0056, 0.0333, 0.0745, 0.0337, 0.2538,\n",
      "        0.1599, 0.2534, 0.2531, 0.2524, 0.2514, 0.0655, 0.2491, 0.2475, 0.1606,\n",
      "        0.2446, 0.0172, 0.0172, 0.0313, 0.0059, 0.0312, 0.1584],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "51000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 38, 12, 40, 45, 34, 41, 43, 21, 38, 40, 40, 40, 17, 47, 23, 47, 24,\n",
      "        23, 41, 47, 27, 47, 34, 34])\n",
      "loss=  tensor(1972.7800, grad_fn=<AddBackward0>)   , actor=  tensor(373.8938, grad_fn=<DivBackward0>)   , critic=  tensor(15988.8623, grad_fn=<SumBackward0>)   , return=  173792.00390315338\n",
      "probs of actions:  tensor([0.2701, 0.0080, 0.0063, 0.2819, 0.0392, 0.0476, 0.0277, 0.0294, 0.0305,\n",
      "        0.0069, 0.2894, 0.2887, 0.2879, 0.0007, 0.2249, 0.0289, 0.2241, 0.0050,\n",
      "        0.0292, 0.0278, 0.2214, 0.0268, 0.2213, 0.0489, 0.0490],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "52000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([41, 40, 34, 43, 21, 40, 47, 47, 27, 10, 40, 22, 21, 27, 40, 12, 47, 34,\n",
      "        27, 47, 45, 40, 47, 42, 40])\n",
      "loss=  tensor(1882.0869, grad_fn=<AddBackward0>)   , actor=  tensor(323.2399, grad_fn=<DivBackward0>)   , critic=  tensor(15588.4697, grad_fn=<SumBackward0>)   , return=  172209.99797255316\n",
      "probs of actions:  tensor([0.0263, 0.2768, 0.0396, 0.0307, 0.0289, 0.2890, 0.2117, 0.2125, 0.0341,\n",
      "        0.0060, 0.2920, 0.0246, 0.0293, 0.0337, 0.2882, 0.0057, 0.2160, 0.0399,\n",
      "        0.0338, 0.2143, 0.0444, 0.2775, 0.2126, 0.0640, 0.2729],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "53000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([42, 21, 40, 40, 45, 47, 47, 47, 42, 42, 23, 45, 47,  7, 40, 40, 23, 40,\n",
      "        38, 45, 35, 47,  9, 40, 47])\n",
      "loss=  tensor(1913.4150, grad_fn=<AddBackward0>)   , actor=  tensor(310.8380, grad_fn=<DivBackward0>)   , critic=  tensor(16025.7695, grad_fn=<SumBackward0>)   , return=  173432.20510563417\n",
      "probs of actions:  tensor([0.0716, 0.0251, 0.3529, 0.3568, 0.0345, 0.1982, 0.1992, 0.2001, 0.0688,\n",
      "        0.0687, 0.0319, 0.0338, 0.2026, 0.0022, 0.3631, 0.3606, 0.0325, 0.3578,\n",
      "        0.0060, 0.0346, 0.0031, 0.2019, 0.0029, 0.3454, 0.2005],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "54000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([33, 22, 26, 45, 45, 16, 40, 47, 40, 22, 40, 40, 25, 42, 47, 40, 40, 40,\n",
      "        40, 27, 34, 41, 42, 40, 39])\n",
      "loss=  tensor(1929.1096, grad_fn=<AddBackward0>)   , actor=  tensor(315.3784, grad_fn=<DivBackward0>)   , critic=  tensor(16137.3125, grad_fn=<SumBackward0>)   , return=  174516.30504297005\n",
      "probs of actions:  tensor([0.0297, 0.0292, 0.0214, 0.0426, 0.0425, 0.0023, 0.3461, 0.1641, 0.3483,\n",
      "        0.0284, 0.3489, 0.3479, 0.0078, 0.0773, 0.1658, 0.3425, 0.3414, 0.3395,\n",
      "        0.3373, 0.0341, 0.0447, 0.0153, 0.0759, 0.3257, 0.0009],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "55000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([43, 26, 40, 10, 40, 47, 27, 40, 33, 47, 40, 40, 40, 10, 12, 26, 42, 40,\n",
      "        47, 40, 47, 40, 26, 40, 23])\n",
      "loss=  tensor(1894.4506, grad_fn=<AddBackward0>)   , actor=  tensor(298.3205, grad_fn=<DivBackward0>)   , critic=  tensor(15961.3008, grad_fn=<SumBackward0>)   , return=  173901.51550909627\n",
      "probs of actions:  tensor([0.0205, 0.0423, 0.2471, 0.0104, 0.2509, 0.1631, 0.0387, 0.2548, 0.0367,\n",
      "        0.1664, 0.2540, 0.2536, 0.2526, 0.0102, 0.0043, 0.0403, 0.0865, 0.2437,\n",
      "        0.1656, 0.2412, 0.1651, 0.2381, 0.0407, 0.2350, 0.0422],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "56000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([27, 40, 47, 45, 42, 40, 36, 45, 26, 37, 29, 45, 10, 47, 14, 34, 26, 33,\n",
      "        22, 47, 47, 23, 47, 21, 47])\n",
      "loss=  tensor(1952.9753, grad_fn=<AddBackward0>)   , actor=  tensor(376.9277, grad_fn=<DivBackward0>)   , critic=  tensor(15760.4756, grad_fn=<SumBackward0>)   , return=  172558.93871528696\n",
      "probs of actions:  tensor([0.0409, 0.2515, 0.1690, 0.0340, 0.1111, 0.2606, 0.0044, 0.0336, 0.0384,\n",
      "        0.0023, 0.0127, 0.0336, 0.0072, 0.1783, 0.0153, 0.0417, 0.0381, 0.0297,\n",
      "        0.0316, 0.1765, 0.1753, 0.0368, 0.1755, 0.0235, 0.1746],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "57000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([43, 40, 33, 40, 42, 40, 47, 23, 47, 34, 42, 23, 47, 26, 27, 40, 43, 40,\n",
      "        47, 34, 40, 43, 26, 34, 34])\n",
      "loss=  tensor(1950.5826, grad_fn=<AddBackward0>)   , actor=  tensor(303.2906, grad_fn=<DivBackward0>)   , critic=  tensor(16472.9199, grad_fn=<SumBackward0>)   , return=  176152.7298561289\n",
      "probs of actions:  tensor([0.0242, 0.2055, 0.0363, 0.2099, 0.1351, 0.2127, 0.1267, 0.0305, 0.1280,\n",
      "        0.0549, 0.1357, 0.0308, 0.1288, 0.0408, 0.0514, 0.2084, 0.0238, 0.2061,\n",
      "        0.1278, 0.0559, 0.2023, 0.0242, 0.0408, 0.0563, 0.0563],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "58000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([19, 21, 41, 27, 27, 22,  1, 26, 40, 34, 40, 40, 40, 34, 42, 27, 40, 40,\n",
      "        40, 12, 14, 14, 10, 27, 27])\n",
      "loss=  tensor(1883.1145, grad_fn=<AddBackward0>)   , actor=  tensor(342.8173, grad_fn=<DivBackward0>)   , critic=  tensor(15402.9717, grad_fn=<SumBackward0>)   , return=  170704.38847908634\n",
      "probs of actions:  tensor([0.0040, 0.0262, 0.0264, 0.0583, 0.0584, 0.0288, 0.0060, 0.0439, 0.2187,\n",
      "        0.0713, 0.2183, 0.2178, 0.2171, 0.0717, 0.1039, 0.0574, 0.2128, 0.2113,\n",
      "        0.2101, 0.0067, 0.0196, 0.0197, 0.0083, 0.0568, 0.0566],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "59000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 43, 41, 31, 30, 45, 40, 47, 35, 42, 40, 45, 27, 32, 42, 40, 37, 33,\n",
      "        33, 29, 37, 45, 23, 42, 29])\n",
      "loss=  tensor(2065.2161, grad_fn=<AddBackward0>)   , actor=  tensor(405.2301, grad_fn=<DivBackward0>)   , critic=  tensor(16599.8594, grad_fn=<SumBackward0>)   , return=  176582.5452396331\n",
      "probs of actions:  tensor([0.1654, 0.0212, 0.0226, 0.0210, 0.0059, 0.0372, 0.1757, 0.1224, 0.0067,\n",
      "        0.1032, 0.1762, 0.0373, 0.0482, 0.0087, 0.1013, 0.1727, 0.0026, 0.0413,\n",
      "        0.0414, 0.0185, 0.0027, 0.0377, 0.0395, 0.0977, 0.0189],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "60000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 43, 27, 10, 14, 42, 23, 10, 26, 46, 34, 17, 22, 34, 47, 34, 34, 12,\n",
      "        34,  5, 27, 42, 34, 43, 47])\n",
      "loss=  tensor(1873.6284, grad_fn=<AddBackward0>)   , actor=  tensor(395.7643, grad_fn=<DivBackward0>)   , critic=  tensor(14778.6416, grad_fn=<SumBackward0>)   , return=  167685.1336480978\n",
      "probs of actions:  tensor([0.1726, 0.0232, 0.0592, 0.0098, 0.0171, 0.1092, 0.0322, 0.0095, 0.0461,\n",
      "        0.0076, 0.0764, 0.0011, 0.0242, 0.0768, 0.1409, 0.0764, 0.0766, 0.0074,\n",
      "        0.0767, 0.0050, 0.0579, 0.1034, 0.0760, 0.0229, 0.1366],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "61000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([31, 45, 42, 41, 44, 26, 43, 23, 20, 47, 41, 47, 40, 23, 40,  9, 47, 47,\n",
      "        47, 34, 40, 34, 41, 40, 47])\n",
      "loss=  tensor(1972.1832, grad_fn=<AddBackward0>)   , actor=  tensor(378.8188, grad_fn=<DivBackward0>)   , critic=  tensor(15933.6445, grad_fn=<SumBackward0>)   , return=  173520.84451664618\n",
      "probs of actions:  tensor([0.0193, 0.0448, 0.0799, 0.0233, 0.0023, 0.0469, 0.0216, 0.0393, 0.0039,\n",
      "        0.1442, 0.0230, 0.1437, 0.1938, 0.0399, 0.1922, 0.0028, 0.1429, 0.1414,\n",
      "        0.1414, 0.0842, 0.1868, 0.0841, 0.0234, 0.1829, 0.1390],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "62000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 34, 34, 30, 40, 47, 47, 27, 22, 40,  7, 12, 31, 47, 43, 47, 33, 47,\n",
      "        40, 42, 43,  7, 23, 45, 27])\n",
      "loss=  tensor(1934.8679, grad_fn=<AddBackward0>)   , actor=  tensor(356.4716, grad_fn=<DivBackward0>)   , critic=  tensor(15783.9629, grad_fn=<SumBackward0>)   , return=  173076.32865821663\n",
      "probs of actions:  tensor([0.1587, 0.0599, 0.0602, 0.0043, 0.1672, 0.1240, 0.1244, 0.0845, 0.0167,\n",
      "        0.1702, 0.0067, 0.0079, 0.0242, 0.1250, 0.0261, 0.1245, 0.0356, 0.1242,\n",
      "        0.1654, 0.0719, 0.0263, 0.0071, 0.0409, 0.0556, 0.0809],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "63000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([47, 47, 26, 27, 27, 23, 27, 31, 40, 40, 47, 40, 41, 41, 22, 33, 10, 27,\n",
      "        47, 27, 42, 26, 47, 45, 45])\n",
      "loss=  tensor(1892.2144, grad_fn=<AddBackward0>)   , actor=  tensor(324.2747, grad_fn=<DivBackward0>)   , critic=  tensor(15679.3965, grad_fn=<SumBackward0>)   , return=  172105.96689582008\n",
      "probs of actions:  tensor([0.1411, 0.1422, 0.0426, 0.0762, 0.0762, 0.0355, 0.0764, 0.0253, 0.1529,\n",
      "        0.1528, 0.1490, 0.1523, 0.0281, 0.0281, 0.0180, 0.0321, 0.0086, 0.0748,\n",
      "        0.1460, 0.0739, 0.0672, 0.0418, 0.1443, 0.0628, 0.0628],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "64000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([47, 39, 42, 30, 25, 47, 47, 27, 10, 47, 38, 21, 45, 47, 47, 42, 33, 19,\n",
      "        47, 47, 34, 47, 42, 47, 26])\n",
      "loss=  tensor(1984.8193, grad_fn=<AddBackward0>)   , actor=  tensor(372.1967, grad_fn=<DivBackward0>)   , critic=  tensor(16126.2266, grad_fn=<SumBackward0>)   , return=  174633.10666467805\n",
      "probs of actions:  tensor([0.1829, 0.0020, 0.0575, 0.0061, 0.0109, 0.1936, 0.1937, 0.0593, 0.0094,\n",
      "        0.1970, 0.0140, 0.0262, 0.0618, 0.1945, 0.1941, 0.0558, 0.0359, 0.0032,\n",
      "        0.1924, 0.1900, 0.0550, 0.1895, 0.0548, 0.1874, 0.0443],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "65000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([32,  7, 27, 23, 26, 42, 47, 42, 31, 40, 31, 43, 42, 34, 34, 27, 33, 47,\n",
      "        47, 38,  5, 43, 46, 33, 21])\n",
      "loss=  tensor(1988.1757, grad_fn=<AddBackward0>)   , actor=  tensor(389.8658, grad_fn=<DivBackward0>)   , critic=  tensor(15983.0977, grad_fn=<SumBackward0>)   , return=  173772.72361840305\n",
      "probs of actions:  tensor([0.0062, 0.0063, 0.0516, 0.0291, 0.0510, 0.0429, 0.1872, 0.0425, 0.0263,\n",
      "        0.1544, 0.0262, 0.0296, 0.0419, 0.0555, 0.0556, 0.0502, 0.0422, 0.1856,\n",
      "        0.1842, 0.0129, 0.0086, 0.0297, 0.0087, 0.0427, 0.0293],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "66000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([14, 40, 22, 49, 47, 40, 40, 40, 38, 11, 45, 47, 41, 43, 16, 47, 45, 42,\n",
      "        41, 10, 45, 40, 21, 26, 47])\n",
      "loss=  tensor(1966.0580, grad_fn=<AddBackward0>)   , actor=  tensor(378.4311, grad_fn=<DivBackward0>)   , critic=  tensor(15876.2686, grad_fn=<SumBackward0>)   , return=  172689.31829423655\n",
      "probs of actions:  tensor([0.0203, 0.1626, 0.0187, 0.0052, 0.1671, 0.1674, 0.1681, 0.1684, 0.0105,\n",
      "        0.0030, 0.0535, 0.1715, 0.0435, 0.0295, 0.0026, 0.1718, 0.0537, 0.0453,\n",
      "        0.0431, 0.0084, 0.0538, 0.1578, 0.0243, 0.0576, 0.1657],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "67000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([26, 26, 38, 40, 38, 26, 45, 34,  3, 40, 36, 36, 22, 40, 26,  7, 14, 47,\n",
      "        45, 31, 47, 40, 35, 30, 47])\n",
      "loss=  tensor(1919.0579, grad_fn=<AddBackward0>)   , actor=  tensor(392.5379, grad_fn=<DivBackward0>)   , critic=  tensor(15265.1992, grad_fn=<SumBackward0>)   , return=  170674.15584359824\n",
      "probs of actions:  tensor([0.0639, 0.0647, 0.0083, 0.1618, 0.0081, 0.0647, 0.0587, 0.0450, 0.0027,\n",
      "        0.1636, 0.0139, 0.0140, 0.0195, 0.1622, 0.0639, 0.0056, 0.0214, 0.1629,\n",
      "        0.0589, 0.0197, 0.1614, 0.1551, 0.0072, 0.0076, 0.1590],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "68000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([41, 21, 41, 41, 47, 26, 22, 47, 47, 34, 42, 40, 47, 47, 45, 19, 21, 47,\n",
      "        40, 40, 15, 47, 40, 26, 46])\n",
      "loss=  tensor(1935.9998, grad_fn=<AddBackward0>)   , actor=  tensor(328.2297, grad_fn=<DivBackward0>)   , critic=  tensor(16077.7002, grad_fn=<SumBackward0>)   , return=  173860.81925396374\n",
      "probs of actions:  tensor([0.0526, 0.0169, 0.0523, 0.0521, 0.2061, 0.0640, 0.0146, 0.2112, 0.2103,\n",
      "        0.0460, 0.0389, 0.1955, 0.2116, 0.2109, 0.0497, 0.0019, 0.0173, 0.2099,\n",
      "        0.1887, 0.1882, 0.0060, 0.2074, 0.1841, 0.0624, 0.0052],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "69000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([26, 47, 38, 42, 31, 33, 40, 47, 22, 33, 40, 34, 40, 47, 47, 45, 40, 47,\n",
      "        14, 40, 35, 27, 47, 47, 21])\n",
      "loss=  tensor(1959.4614, grad_fn=<AddBackward0>)   , actor=  tensor(321.0421, grad_fn=<DivBackward0>)   , critic=  tensor(16384.1934, grad_fn=<SumBackward0>)   , return=  175805.2573237658\n",
      "probs of actions:  tensor([0.0701, 0.1932, 0.0060, 0.0480, 0.0183, 0.0481, 0.2233, 0.2027, 0.0162,\n",
      "        0.0482, 0.2235, 0.0480, 0.2223, 0.2042, 0.2036, 0.0402, 0.2185, 0.2029,\n",
      "        0.0184, 0.2147, 0.0049, 0.0491, 0.1999, 0.1982, 0.0168],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "70000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 32, 47, 26, 40, 47, 40, 42, 47, 47, 32, 40, 41, 37, 47, 33, 40, 22,\n",
      "        40, 40, 42, 47, 27, 47, 40])\n",
      "loss=  tensor(1950.5181, grad_fn=<AddBackward0>)   , actor=  tensor(300.4617, grad_fn=<DivBackward0>)   , critic=  tensor(16500.5625, grad_fn=<SumBackward0>)   , return=  175947.86496708682\n",
      "probs of actions:  tensor([0.2545, 0.0056, 0.2183, 0.0739, 0.2673, 0.2241, 0.2702, 0.0459, 0.2274,\n",
      "        0.2278, 0.0050, 0.2708, 0.0444, 0.0015, 0.2290, 0.0424, 0.2653, 0.0181,\n",
      "        0.2622, 0.2602, 0.0452, 0.2252, 0.0406, 0.2248, 0.2524],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "71000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 47, 41, 46, 40, 30, 42, 10, 26, 23, 46, 47, 47, 49, 23, 27, 47, 21,\n",
      "        45, 41, 34, 40, 47, 31,  5])\n",
      "loss=  tensor(2034.5222, grad_fn=<AddBackward0>)   , actor=  tensor(402.6420, grad_fn=<DivBackward0>)   , critic=  tensor(16318.8027, grad_fn=<SumBackward0>)   , return=  175651.95275741126\n",
      "probs of actions:  tensor([0.2213, 0.2540, 0.0506, 0.0041, 0.2306, 0.0071, 0.0406, 0.0026, 0.0753,\n",
      "        0.0151, 0.0038, 0.2722, 0.2724, 0.0027, 0.0153, 0.0436, 0.2722, 0.0107,\n",
      "        0.0239, 0.0486, 0.0410, 0.2213, 0.2665, 0.0180, 0.0044],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "72000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 26, 40, 30, 47, 40, 27, 40, 42, 45, 33, 31, 47, 39, 26, 47, 40, 26,\n",
      "         2, 12, 40, 40, 45, 34, 23])\n",
      "loss=  tensor(1938.0613, grad_fn=<AddBackward0>)   , actor=  tensor(335.1321, grad_fn=<DivBackward0>)   , critic=  tensor(16029.2920, grad_fn=<SumBackward0>)   , return=  174027.61829858657\n",
      "probs of actions:  tensor([0.2302, 0.0799, 0.2378, 0.0091, 0.1748, 0.2432, 0.0444, 0.2452, 0.0464,\n",
      "        0.0318, 0.0462, 0.0199, 0.1799, 0.0009, 0.0789, 0.1796, 0.2385, 0.0785,\n",
      "        0.0028, 0.0068, 0.2312, 0.2294, 0.0329, 0.0411, 0.0198],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "73000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 26, 40, 41, 26, 29, 26, 31, 33, 34, 40, 33, 26, 33, 14, 25, 42, 47,\n",
      "        10, 21, 22, 42, 47, 44, 27])\n",
      "loss=  tensor(1907.7290, grad_fn=<AddBackward0>)   , actor=  tensor(351.0570, grad_fn=<DivBackward0>)   , critic=  tensor(15566.7197, grad_fn=<SumBackward0>)   , return=  172165.99867898755\n",
      "probs of actions:  tensor([0.2456, 0.0911, 0.2544, 0.0623, 0.0913, 0.0108, 0.0911, 0.0198, 0.0461,\n",
      "        0.0309, 0.2629, 0.0464, 0.0905, 0.0466, 0.0173, 0.0080, 0.0570, 0.1154,\n",
      "        0.0055, 0.0174, 0.0157, 0.0566, 0.1148, 0.0067, 0.0460],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "74000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([26, 34, 25, 26, 31, 42, 26, 30, 26, 40, 40, 42, 41, 34, 21,  5, 26, 27,\n",
      "        21, 40, 14, 40, 40, 41, 12])\n",
      "loss=  tensor(1910.5181, grad_fn=<AddBackward0>)   , actor=  tensor(353.0750, grad_fn=<DivBackward0>)   , critic=  tensor(15574.4297, grad_fn=<SumBackward0>)   , return=  172356.5496182668\n",
      "probs of actions:  tensor([0.1008, 0.0353, 0.0105, 0.1027, 0.0215, 0.0525, 0.1033, 0.0111, 0.1031,\n",
      "        0.2070, 0.2066, 0.0517, 0.0615, 0.0360, 0.0222, 0.0061, 0.1005, 0.0428,\n",
      "        0.0228, 0.1958, 0.0189, 0.1935, 0.1915, 0.0592, 0.0087],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "75000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 40, 40, 40, 26, 26, 40, 23, 47, 47, 23, 40, 40, 42, 26, 40, 40, 44,\n",
      "        47, 27, 47, 20, 44, 33, 40])\n",
      "loss=  tensor(1895.1654, grad_fn=<AddBackward0>)   , actor=  tensor(274.9843, grad_fn=<DivBackward0>)   , critic=  tensor(16201.8105, grad_fn=<SumBackward0>)   , return=  174869.29062309302\n",
      "probs of actions:  tensor([0.3138, 0.3209, 0.3249, 0.3284, 0.0963, 0.0959, 0.3353, 0.0112, 0.1433,\n",
      "        0.1432, 0.0112, 0.3350, 0.3338, 0.0402, 0.0951, 0.3291, 0.3269, 0.0037,\n",
      "        0.1451, 0.0315, 0.1456, 0.0015, 0.0039, 0.0415, 0.3104],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "76000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([26, 40, 41, 41, 40, 40, 41, 15, 40, 47, 40, 30, 47, 24, 34, 40, 40, 26,\n",
      "        26, 40, 40, 47, 40, 42, 31])\n",
      "loss=  tensor(1912.5856, grad_fn=<AddBackward0>)   , actor=  tensor(285.5188, grad_fn=<DivBackward0>)   , critic=  tensor(16270.6670, grad_fn=<SumBackward0>)   , return=  175333.11594653182\n",
      "probs of actions:  tensor([0.1238, 0.2460, 0.0779, 0.0780, 0.2522, 0.2535, 0.0779, 0.0046, 0.2544,\n",
      "        0.1657, 0.2540, 0.0057, 0.1672, 0.0078, 0.0294, 0.2484, 0.2471, 0.1230,\n",
      "        0.1225, 0.2424, 0.2408, 0.1660, 0.2382, 0.0428, 0.0174],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "77000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([42, 29, 40, 47, 11, 40, 23, 34, 40, 40, 47, 47, 40, 33, 26, 33, 41, 47,\n",
      "        47, 40, 34, 33, 47, 40, 40])\n",
      "loss=  tensor(1928.1060, grad_fn=<AddBackward0>)   , actor=  tensor(307.9018, grad_fn=<DivBackward0>)   , critic=  tensor(16202.0410, grad_fn=<SumBackward0>)   , return=  174740.97953235978\n",
      "probs of actions:  tensor([0.0445, 0.0096, 0.2188, 0.1804, 0.0024, 0.2225, 0.0101, 0.0340, 0.2251,\n",
      "        0.2249, 0.1887, 0.1888, 0.2235, 0.0517, 0.1100, 0.0520, 0.0725, 0.1892,\n",
      "        0.1887, 0.2163, 0.0351, 0.0527, 0.1879, 0.2110, 0.2102],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "78000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([41, 40, 26, 40, 47, 33, 24, 42, 47, 26, 42, 40, 40, 33, 26, 40, 47, 22,\n",
      "        40, 41, 12, 26, 40, 34, 47])\n",
      "loss=  tensor(1886.1116, grad_fn=<AddBackward0>)   , actor=  tensor(282.9758, grad_fn=<DivBackward0>)   , critic=  tensor(16031.3574, grad_fn=<SumBackward0>)   , return=  173600.36778473092\n",
      "probs of actions:  tensor([0.0583, 0.2815, 0.1469, 0.2873, 0.1748, 0.0470, 0.0062, 0.0417, 0.1795,\n",
      "        0.1464, 0.0412, 0.2914, 0.2905, 0.0476, 0.1443, 0.2864, 0.1830, 0.0069,\n",
      "        0.2820, 0.0554, 0.0063, 0.1411, 0.2743, 0.0285, 0.1823],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "79000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 26, 42, 29, 33, 41, 40, 45, 26, 26, 47, 40, 47, 40, 40, 26, 12, 42,\n",
      "        26, 47, 47, 21, 44, 33, 40])\n",
      "loss=  tensor(1891.8264, grad_fn=<AddBackward0>)   , actor=  tensor(288.1180, grad_fn=<DivBackward0>)   , critic=  tensor(16037.0850, grad_fn=<SumBackward0>)   , return=  174073.9673496968\n",
      "probs of actions:  tensor([0.2610, 0.1810, 0.0568, 0.0095, 0.0543, 0.0563, 0.2774, 0.0174, 0.1834,\n",
      "        0.1828, 0.1220, 0.2777, 0.1226, 0.2763, 0.2754, 0.1804, 0.0060, 0.0547,\n",
      "        0.1781, 0.1250, 0.1246, 0.0215, 0.0046, 0.0569, 0.2610],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "80000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([26, 47, 42, 40, 41, 26, 47, 40, 27, 34, 27, 40, 40, 42, 47, 42, 24, 42,\n",
      "        47, 43, 26, 47, 41, 40, 40])\n",
      "loss=  tensor(1913.2576, grad_fn=<AddBackward0>)   , actor=  tensor(279.7280, grad_fn=<DivBackward0>)   , critic=  tensor(16335.2969, grad_fn=<SumBackward0>)   , return=  175455.47901343313\n",
      "probs of actions:  tensor([0.1579, 0.1823, 0.0742, 0.2287, 0.0520, 0.1609, 0.1912, 0.2324, 0.0541,\n",
      "        0.0207, 0.0541, 0.2315, 0.2309, 0.0716, 0.1965, 0.0712, 0.0061, 0.0712,\n",
      "        0.1966, 0.0257, 0.1554, 0.1969, 0.0500, 0.2200, 0.2189],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "81000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([41, 26, 21, 47, 26, 27, 47, 26, 40, 45, 40, 47, 40, 42, 40, 47, 37, 40,\n",
      "        47, 47, 40, 14, 33, 40, 40])\n",
      "loss=  tensor(1912.6306, grad_fn=<AddBackward0>)   , actor=  tensor(282.3148, grad_fn=<DivBackward0>)   , critic=  tensor(16303.1572, grad_fn=<SumBackward0>)   , return=  175091.17028973388\n",
      "probs of actions:  tensor([0.0339, 0.1361, 0.0126, 0.2733, 0.1359, 0.0688, 0.2817, 0.1351, 0.2151,\n",
      "        0.0130, 0.2148, 0.2879, 0.2138, 0.0568, 0.2122, 0.2891, 0.0008, 0.2098,\n",
      "        0.2884, 0.2875, 0.2073, 0.0093, 0.0553, 0.2035, 0.2028],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "82000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([26, 47, 47, 45, 47, 26, 27, 47, 24, 27, 47, 40, 27, 42, 40, 47, 40, 33,\n",
      "        27, 32, 27, 27, 33, 40, 42])\n",
      "loss=  tensor(1904.1316, grad_fn=<AddBackward0>)   , actor=  tensor(280.8685, grad_fn=<DivBackward0>)   , critic=  tensor(16232.6299, grad_fn=<SumBackward0>)   , return=  174443.03946398242\n",
      "probs of actions:  tensor([0.1387, 0.2175, 0.2196, 0.0172, 0.2244, 0.1395, 0.0966, 0.2310, 0.0031,\n",
      "        0.0965, 0.2347, 0.2657, 0.0961, 0.0394, 0.2628, 0.2365, 0.2608, 0.0561,\n",
      "        0.0960, 0.0028, 0.0959, 0.0960, 0.0571, 0.2512, 0.0395],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "83000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([29, 21, 23, 14, 40, 26, 33, 26, 26,  1, 26, 27, 27, 40, 40, 45, 40, 40,\n",
      "        40, 27, 41, 33, 26, 33, 40])\n",
      "loss=  tensor(1865.8400, grad_fn=<AddBackward0>)   , actor=  tensor(332.0604, grad_fn=<DivBackward0>)   , critic=  tensor(15337.7949, grad_fn=<SumBackward0>)   , return=  171097.08791489864\n",
      "probs of actions:  tensor([0.0089, 0.0131, 0.0042, 0.0099, 0.2956, 0.1859, 0.0428, 0.1852, 0.1845,\n",
      "        0.0011, 0.1823, 0.0858, 0.0858, 0.2946, 0.2937, 0.0163, 0.2916, 0.2905,\n",
      "        0.2891, 0.0861, 0.0270, 0.0450, 0.1771, 0.0454, 0.2798],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "84000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([26, 33, 26, 33, 26, 27, 40, 26, 47, 29, 40, 31, 47, 31, 26, 42, 47, 40,\n",
      "        26, 47, 28, 27, 47, 26, 47])\n",
      "loss=  tensor(1889.8198, grad_fn=<AddBackward0>)   , actor=  tensor(303.2254, grad_fn=<DivBackward0>)   , critic=  tensor(15865.9443, grad_fn=<SumBackward0>)   , return=  173397.11764065275\n",
      "probs of actions:  tensor([0.1384, 0.0357, 0.1385, 0.0349, 0.1374, 0.1042, 0.2924, 0.1360, 0.2922,\n",
      "        0.0056, 0.2910, 0.0086, 0.2967, 0.0087, 0.1328, 0.0159, 0.2977, 0.2832,\n",
      "        0.1320, 0.2988, 0.0005, 0.1036, 0.2980, 0.1311, 0.2974],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "85000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 33, 40, 26, 40, 27, 33, 40, 33, 47, 40, 47, 40, 26, 47, 27, 26, 40,\n",
      "        41, 40, 40, 26, 40, 40, 27])\n",
      "loss=  tensor(1859.9868, grad_fn=<AddBackward0>)   , actor=  tensor(219.4493, grad_fn=<DivBackward0>)   , critic=  tensor(16405.3750, grad_fn=<SumBackward0>)   , return=  176029.38159228486\n",
      "probs of actions:  tensor([0.3258, 0.0398, 0.3337, 0.1268, 0.3377, 0.1206, 0.0381, 0.3403, 0.0381,\n",
      "        0.2350, 0.3390, 0.2362, 0.3372, 0.1236, 0.2384, 0.1207, 0.1228, 0.3293,\n",
      "        0.0280, 0.3264, 0.3250, 0.1227, 0.3216, 0.3194, 0.1211],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "86000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([33, 40, 47, 40, 26, 45, 40, 27, 47, 47, 29, 27, 47, 40, 40, 26, 47, 27,\n",
      "        26, 47, 47, 40, 40, 47, 47])\n",
      "loss=  tensor(1846.1295, grad_fn=<AddBackward0>)   , actor=  tensor(232.6173, grad_fn=<DivBackward0>)   , critic=  tensor(16135.1221, grad_fn=<SumBackward0>)   , return=  174361.06408478122\n",
      "probs of actions:  tensor([0.0337, 0.4101, 0.2299, 0.4165, 0.0875, 0.0135, 0.4221, 0.1041, 0.2385,\n",
      "        0.2390, 0.0059, 0.1042, 0.2419, 0.4176, 0.4165, 0.0853, 0.2438, 0.1046,\n",
      "        0.0853, 0.2446, 0.2438, 0.4026, 0.4011, 0.2442, 0.2438],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "87000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 40, 40, 27, 40, 40, 27, 40, 40, 40, 40, 40, 40, 40, 40, 47, 40, 27,\n",
      "        40, 40, 41, 40, 27, 36, 33])\n",
      "loss=  tensor(1796.7354, grad_fn=<AddBackward0>)   , actor=  tensor(130.5580, grad_fn=<DivBackward0>)   , critic=  tensor(16661.7734, grad_fn=<SumBackward0>)   , return=  177059.3991693682\n",
      "probs of actions:  tensor([0.5556, 0.5635, 0.5693, 0.0840, 0.5779, 0.5808, 0.0824, 0.5841, 0.5846,\n",
      "        0.5845, 0.5840, 0.5830, 0.5816, 0.5799, 0.5780, 0.1798, 0.5735, 0.0828,\n",
      "        0.5688, 0.5656, 0.0299, 0.5611, 0.0844, 0.0009, 0.0242],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "88000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 31, 40, 47, 40, 40, 40, 47, 40, 47, 40, 40, 40, 40, 27, 27, 26, 40,\n",
      "        30, 47, 40, 40, 41, 47, 40])\n",
      "loss=  tensor(1833.6692, grad_fn=<AddBackward0>)   , actor=  tensor(185.8749, grad_fn=<DivBackward0>)   , critic=  tensor(16477.9414, grad_fn=<SumBackward0>)   , return=  175915.4351476879\n",
      "probs of actions:  tensor([0.4574, 0.0078, 0.4692, 0.1920, 0.4751, 0.4774, 0.4788, 0.1973, 0.4792,\n",
      "        0.1996, 0.4779, 0.4768, 0.4751, 0.4731, 0.0815, 0.0819, 0.0788, 0.4626,\n",
      "        0.0031, 0.2086, 0.4553, 0.4539, 0.0418, 0.2097, 0.4463],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "89000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 47, 40, 40, 40, 40, 40, 40, 33, 47, 26, 40, 47, 40, 47, 40, 40, 40,\n",
      "        40, 47, 34, 15, 27, 26, 40])\n",
      "loss=  tensor(1838.2657, grad_fn=<AddBackward0>)   , actor=  tensor(169.7902, grad_fn=<DivBackward0>)   , critic=  tensor(16684.7559, grad_fn=<SumBackward0>)   , return=  176673.71289521185\n",
      "probs of actions:  tensor([0.5054, 0.1543, 0.5190, 0.5241, 0.5279, 0.5307, 0.5327, 0.5338, 0.0442,\n",
      "        0.1608, 0.0573, 0.5318, 0.1634, 0.5281, 0.1649, 0.5240, 0.5218, 0.5190,\n",
      "        0.5163, 0.1684, 0.0153, 0.0016, 0.0797, 0.0589, 0.4972],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "90000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 40, 40, 40, 40, 40, 40, 40, 43, 22, 33, 40, 40, 40, 26, 40, 40, 40,\n",
      "        40, 47, 40, 40, 40, 40, 40])\n",
      "loss=  tensor(1817.3181, grad_fn=<AddBackward0>)   , actor=  tensor(165.6376, grad_fn=<DivBackward0>)   , critic=  tensor(16516.8047, grad_fn=<SumBackward0>)   , return=  176409.2336525403\n",
      "probs of actions:  tensor([0.5666, 0.5758, 0.5823, 0.5875, 0.5918, 0.5951, 0.5974, 0.5989, 0.0031,\n",
      "        0.0014, 0.0412, 0.5974, 0.5957, 0.5939, 0.0548, 0.5893, 0.5861, 0.5837,\n",
      "        0.5812, 0.1315, 0.5752, 0.5729, 0.5695, 0.5664, 0.5633],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "91000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 40, 26, 34, 33, 26, 40, 31, 30, 40, 40, 33, 47, 47, 26, 47, 40, 40,\n",
      "        40, 40, 40, 40, 40, 47, 40])\n",
      "loss=  tensor(1870.2925, grad_fn=<AddBackward0>)   , actor=  tensor(244.3312, grad_fn=<DivBackward0>)   , critic=  tensor(16259.6133, grad_fn=<SumBackward0>)   , return=  175369.19985999353\n",
      "probs of actions:  tensor([0.5096, 0.5181, 0.0642, 0.0136, 0.0419, 0.0618, 0.5369, 0.0107, 0.0030,\n",
      "        0.5378, 0.5369, 0.0415, 0.1689, 0.1695, 0.0604, 0.1717, 0.5244, 0.5225,\n",
      "        0.5198, 0.5170, 0.5141, 0.5111, 0.5082, 0.1765, 0.5024],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "92000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([26, 40, 27, 40, 40, 40, 47, 47, 40, 47, 40, 47, 40, 40, 40, 40, 40, 40,\n",
      "        47, 40, 33, 40, 40, 40, 47])\n",
      "loss=  tensor(1798.8101, grad_fn=<AddBackward0>)   , actor=  tensor(138.7418, grad_fn=<DivBackward0>)   , critic=  tensor(16600.6816, grad_fn=<SumBackward0>)   , return=  176411.57653628782\n",
      "probs of actions:  tensor([0.0364, 0.6482, 0.0746, 0.6590, 0.6628, 0.6657, 0.1300, 0.1306, 0.6692,\n",
      "        0.1321, 0.6685, 0.1339, 0.6658, 0.6642, 0.6618, 0.6593, 0.6567, 0.6540,\n",
      "        0.1412, 0.6482, 0.0249, 0.6427, 0.6388, 0.6360, 0.1463],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "93000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 29, 47, 40, 40, 40, 40, 40, 47, 40, 45, 40, 27, 40, 40, 14, 40, 40,\n",
      "        40, 47, 47, 47, 40, 40, 27])\n",
      "loss=  tensor(1842.4354, grad_fn=<AddBackward0>)   , actor=  tensor(182.3745, grad_fn=<DivBackward0>)   , critic=  tensor(16600.6094, grad_fn=<SumBackward0>)   , return=  176912.17438242436\n",
      "probs of actions:  tensor([0.5827, 0.0064, 0.1461, 0.5997, 0.6035, 0.6060, 0.6077, 0.6087, 0.1504,\n",
      "        0.6083, 0.0054, 0.6064, 0.1141, 0.6027, 0.6001, 0.0048, 0.5950, 0.5915,\n",
      "        0.5897, 0.1623, 0.1630, 0.1636, 0.5800, 0.5776, 0.1177],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "94000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([42, 40, 47, 47, 40, 27, 47, 34, 47, 40, 40, 47, 40, 47, 40, 27, 27, 40,\n",
      "        40, 47, 40, 27, 40, 40, 40])\n",
      "loss=  tensor(1862.3518, grad_fn=<AddBackward0>)   , actor=  tensor(198.6171, grad_fn=<DivBackward0>)   , critic=  tensor(16637.3477, grad_fn=<SumBackward0>)   , return=  176455.76268735938\n",
      "probs of actions:  tensor([0.0115, 0.5689, 0.1786, 0.1797, 0.5805, 0.0826, 0.1835, 0.0084, 0.1861,\n",
      "        0.5836, 0.5829, 0.1902, 0.5791, 0.1929, 0.5746, 0.0826, 0.0831, 0.5657,\n",
      "        0.5623, 0.2003, 0.5572, 0.0848, 0.5521, 0.5480, 0.5457],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "95000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 47, 41, 40, 40, 40, 27, 40, 40, 40, 40, 40, 27, 40, 29, 47, 33, 40,\n",
      "        40, 40, 40, 33, 47, 40, 40])\n",
      "loss=  tensor(1825.9248, grad_fn=<AddBackward0>)   , actor=  tensor(173.7553, grad_fn=<DivBackward0>)   , critic=  tensor(16521.6953, grad_fn=<SumBackward0>)   , return=  176236.01518796984\n",
      "probs of actions:  tensor([0.6617, 0.1310, 0.0212, 0.6791, 0.6826, 0.6852, 0.0736, 0.6880, 0.6880,\n",
      "        0.6877, 0.6868, 0.6855, 0.0735, 0.6817, 0.0034, 0.1412, 0.0094, 0.6718,\n",
      "        0.6686, 0.6658, 0.6629, 0.0100, 0.1485, 0.6535, 0.6518],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "96000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 40, 40, 40, 47, 40, 27, 40, 40, 47, 40, 40, 27, 40, 40, 40, 27, 40,\n",
      "        47, 40, 40, 40, 47, 26, 47])\n",
      "loss=  tensor(1766.9015, grad_fn=<AddBackward0>)   , actor=  tensor(116.2880, grad_fn=<DivBackward0>)   , critic=  tensor(16506.1348, grad_fn=<SumBackward0>)   , return=  176095.08973449864\n",
      "probs of actions:  tensor([0.6375, 0.6443, 0.6498, 0.6540, 0.1375, 0.6592, 0.0912, 0.6623, 0.6622,\n",
      "        0.1415, 0.6605, 0.6597, 0.0907, 0.6559, 0.6531, 0.6510, 0.0919, 0.6460,\n",
      "        0.1523, 0.6399, 0.6379, 0.6349, 0.1561, 0.0487, 0.1579],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "97000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([47, 40, 47, 40, 40, 40, 40, 40, 40, 47, 40, 40, 40, 40, 40, 40, 40, 40,\n",
      "        40, 47, 40, 47, 40, 40, 40])\n",
      "loss=  tensor(1764.5128, grad_fn=<AddBackward0>)   , actor=  tensor(80.0327, grad_fn=<DivBackward0>)   , critic=  tensor(16844.8008, grad_fn=<SumBackward0>)   , return=  177563.2480528031\n",
      "probs of actions:  tensor([0.0941, 0.7884, 0.0924, 0.7978, 0.8013, 0.8036, 0.8050, 0.8058, 0.8059,\n",
      "        0.0939, 0.8043, 0.8036, 0.8020, 0.8001, 0.7980, 0.7958, 0.7934, 0.7910,\n",
      "        0.7884, 0.1049, 0.7829, 0.1070, 0.7778, 0.7758, 0.7728],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "98000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 40, 40, 40, 40, 40, 40, 40, 27, 40, 40, 40, 40, 47, 40, 40, 40, 40,\n",
      "        40, 40, 40, 40, 40, 40, 40])\n",
      "loss=  tensor(1727.2877, grad_fn=<AddBackward0>)   , actor=  tensor(57.6052, grad_fn=<DivBackward0>)   , critic=  tensor(16696.8242, grad_fn=<SumBackward0>)   , return=  177141.1115374485\n",
      "probs of actions:  tensor([0.7979, 0.8035, 0.8083, 0.8120, 0.8148, 0.8168, 0.8181, 0.8187, 0.0270,\n",
      "        0.8186, 0.8173, 0.8162, 0.8148, 0.1041, 0.8109, 0.8093, 0.8070, 0.8046,\n",
      "        0.8021, 0.7996, 0.7972, 0.7945, 0.7920, 0.7895, 0.7870],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "99000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 47, 40, 40, 27, 40, 40, 40, 40, 47, 40, 27, 34, 40, 40, 40, 40, 40,\n",
      "        40, 40, 47, 47, 40, 27, 40])\n",
      "loss=  tensor(1801.8759, grad_fn=<AddBackward0>)   , actor=  tensor(135.9473, grad_fn=<DivBackward0>)   , critic=  tensor(16659.2852, grad_fn=<SumBackward0>)   , return=  176966.73356347837\n",
      "probs of actions:  tensor([0.7679, 0.0799, 0.7791, 0.7839, 0.0582, 0.7899, 0.7913, 0.7921, 0.7923,\n",
      "        0.0806, 0.7909, 0.0564, 0.0033, 0.7864, 0.7842, 0.7822, 0.7799, 0.7775,\n",
      "        0.7750, 0.7725, 0.0917, 0.0927, 0.7646, 0.0613, 0.7595],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "100000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 47, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40,\n",
      "        40, 47, 40, 40, 40, 40, 40])\n",
      "loss=  tensor(1731.7704, grad_fn=<AddBackward0>)   , actor=  tensor(51.3467, grad_fn=<DivBackward0>)   , critic=  tensor(16804.2363, grad_fn=<SumBackward0>)   , return=  177503.2982092025\n",
      "probs of actions:  tensor([0.7841, 0.0680, 0.7951, 0.7997, 0.8028, 0.8051, 0.8067, 0.8075, 0.8077,\n",
      "        0.8074, 0.8066, 0.8054, 0.8039, 0.8021, 0.8001, 0.7979, 0.7955, 0.7931,\n",
      "        0.7906, 0.0772, 0.7851, 0.7830, 0.7801, 0.7773, 0.7746],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "101000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 40, 41, 40, 47, 40, 47, 26, 40, 40, 40, 40, 42, 29, 40, 40, 40, 40,\n",
      "        27, 42, 40, 40, 47, 27, 41])\n",
      "loss=  tensor(1852.2449, grad_fn=<AddBackward0>)   , actor=  tensor(189.2673, grad_fn=<DivBackward0>)   , critic=  tensor(16629.7754, grad_fn=<SumBackward0>)   , return=  176670.9239291964\n",
      "probs of actions:  tensor([0.5960, 0.6030, 0.0374, 0.6120, 0.1225, 0.6168, 0.1240, 0.0420, 0.6190,\n",
      "        0.6181, 0.6169, 0.6153, 0.0145, 0.0044, 0.6086, 0.6054, 0.6029, 0.6002,\n",
      "        0.1174, 0.0152, 0.5902, 0.5879, 0.1414, 0.1199, 0.0356],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "102000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([27, 47, 27, 27, 40, 47, 27, 40, 40, 27, 14, 27, 27, 42, 40, 40, 40, 41,\n",
      "        30, 27, 40, 47, 40, 26, 40])\n",
      "loss=  tensor(1832.4404, grad_fn=<AddBackward0>)   , actor=  tensor(232.3969, grad_fn=<DivBackward0>)   , critic=  tensor(16000.4355, grad_fn=<SumBackward0>)   , return=  174055.472254452\n",
      "probs of actions:  tensor([0.1605, 0.1400, 0.1584, 0.1587, 0.5240, 0.1440, 0.1580, 0.5274, 0.5273,\n",
      "        0.1582, 0.0028, 0.1592, 0.1589, 0.0257, 0.5174, 0.5158, 0.5136, 0.0356,\n",
      "        0.0022, 0.1601, 0.5032, 0.1625, 0.4978, 0.0447, 0.4936],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "103000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 26, 40, 40, 40, 41, 40, 40, 40, 40, 27, 40, 40, 41, 31, 40, 40, 40,\n",
      "        40, 40, 40, 40, 40, 40, 40])\n",
      "loss=  tensor(1790.3743, grad_fn=<AddBackward0>)   , actor=  tensor(134.1126, grad_fn=<DivBackward0>)   , critic=  tensor(16562.6172, grad_fn=<SumBackward0>)   , return=  176566.26552589564\n",
      "probs of actions:  tensor([0.7170, 0.0425, 0.7312, 0.7354, 0.7390, 0.0300, 0.7435, 0.7446, 0.7449,\n",
      "        0.7446, 0.0581, 0.7426, 0.7403, 0.0288, 0.0049, 0.7339, 0.7306, 0.7281,\n",
      "        0.7253, 0.7221, 0.7189, 0.7157, 0.7126, 0.7095, 0.7064],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "104000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([41, 26, 40, 47, 40, 40, 26, 40, 40, 40, 40, 40, 47, 47, 40, 40, 27, 47,\n",
      "        47, 40, 40, 26, 40, 27, 47])\n",
      "loss=  tensor(1816.8452, grad_fn=<AddBackward0>)   , actor=  tensor(164.2193, grad_fn=<DivBackward0>)   , critic=  tensor(16526.2578, grad_fn=<SumBackward0>)   , return=  176070.27907009126\n",
      "probs of actions:  tensor([0.0454, 0.0540, 0.5915, 0.1268, 0.5975, 0.5998, 0.0502, 0.6014, 0.6010,\n",
      "        0.6002, 0.5990, 0.5972, 0.1367, 0.1379, 0.5905, 0.5880, 0.1078, 0.1431,\n",
      "        0.1443, 0.5754, 0.5729, 0.0516, 0.5661, 0.1112, 0.1500],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "105000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 40, 40, 21, 40, 27, 40, 40, 40, 40, 40, 40, 27, 27, 40, 26, 40, 40,\n",
      "        40, 43, 47, 40, 40, 41, 40])\n",
      "loss=  tensor(1798.8939, grad_fn=<AddBackward0>)   , actor=  tensor(169.2483, grad_fn=<DivBackward0>)   , critic=  tensor(16296.4561, grad_fn=<SumBackward0>)   , return=  175451.07494659265\n",
      "probs of actions:  tensor([0.6185, 0.6266, 0.6325, 0.0021, 0.6412, 0.0829, 0.6464, 0.6474, 0.6478,\n",
      "        0.6477, 0.6470, 0.6458, 0.0824, 0.0828, 0.6396, 0.0658, 0.6347, 0.6315,\n",
      "        0.6293, 0.0008, 0.1034, 0.6208, 0.6185, 0.0526, 0.6122],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "106000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 40, 40, 26, 40, 40, 40, 40, 40, 47, 40, 47, 26, 40, 40, 40, 40, 40,\n",
      "        40, 40, 40, 40, 27, 47, 47])\n",
      "loss=  tensor(1767.8008, grad_fn=<AddBackward0>)   , actor=  tensor(120.3333, grad_fn=<DivBackward0>)   , critic=  tensor(16474.6738, grad_fn=<SumBackward0>)   , return=  175847.413330327\n",
      "probs of actions:  tensor([0.5320, 0.5394, 0.5446, 0.0694, 0.5524, 0.5550, 0.5567, 0.5577, 0.5581,\n",
      "        0.1329, 0.5569, 0.1350, 0.0665, 0.5529, 0.5504, 0.5483, 0.5461, 0.5437,\n",
      "        0.5413, 0.5386, 0.5358, 0.5331, 0.0953, 0.1469, 0.1476],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "107000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 47, 47, 40, 40, 40, 26, 40, 40, 27, 40, 27, 47, 27, 40, 26, 41, 47,\n",
      "        32, 31, 36, 40, 41, 47, 40])\n",
      "loss=  tensor(1860.1967, grad_fn=<AddBackward0>)   , actor=  tensor(229.3316, grad_fn=<DivBackward0>)   , critic=  tensor(16308.6514, grad_fn=<SumBackward0>)   , return=  175145.3786085621\n",
      "probs of actions:  tensor([0.5082, 0.1524, 0.1534, 0.5218, 0.5249, 0.5268, 0.0683, 0.5285, 0.5281,\n",
      "        0.0868, 0.5263, 0.0871, 0.1672, 0.0875, 0.5184, 0.0678, 0.0781, 0.1734,\n",
      "        0.0007, 0.0062, 0.0013, 0.4984, 0.0780, 0.1784, 0.4909],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "108000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 26, 40, 40, 40, 40, 26, 40, 21,\n",
      "        26, 27, 40, 40, 41, 41, 40])\n",
      "loss=  tensor(1765.3293, grad_fn=<AddBackward0>)   , actor=  tensor(129.3890, grad_fn=<DivBackward0>)   , critic=  tensor(16359.4043, grad_fn=<SumBackward0>)   , return=  175395.20752854593\n",
      "probs of actions:  tensor([0.5858, 0.5935, 0.5994, 0.6042, 0.6081, 0.6110, 0.6132, 0.6145, 0.6151,\n",
      "        0.6151, 0.0603, 0.6135, 0.6117, 0.6101, 0.6082, 0.0609, 0.6037, 0.0027,\n",
      "        0.0615, 0.0951, 0.5903, 0.5871, 0.0571, 0.0572, 0.5805],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "109000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 40, 40, 40, 40, 47, 27, 40, 27, 40, 27, 47, 40, 40, 26, 40, 26, 40,\n",
      "        31, 40, 47, 41, 40, 33, 27])\n",
      "loss=  tensor(1825.9005, grad_fn=<AddBackward0>)   , actor=  tensor(172.9425, grad_fn=<DivBackward0>)   , critic=  tensor(16529.5801, grad_fn=<SumBackward0>)   , return=  176613.785999152\n",
      "probs of actions:  tensor([0.5055, 0.5129, 0.5179, 0.5219, 0.5252, 0.0983, 0.1981, 0.5304, 0.1986,\n",
      "        0.5310, 0.1990, 0.1022, 0.5284, 0.5274, 0.0542, 0.5238, 0.0546, 0.5193,\n",
      "        0.0047, 0.5143, 0.1095, 0.0518, 0.5078, 0.0227, 0.2040],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "110000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 27, 40, 40, 27, 40, 41, 42, 40, 40, 47, 40, 40, 40, 40, 40, 27, 40,\n",
      "        27, 27, 40, 40, 40, 27, 47])\n",
      "loss=  tensor(1795.3805, grad_fn=<AddBackward0>)   , actor=  tensor(152.8551, grad_fn=<DivBackward0>)   , critic=  tensor(16425.2539, grad_fn=<SumBackward0>)   , return=  175585.96223232846\n",
      "probs of actions:  tensor([0.4511, 0.2412, 0.4613, 0.4644, 0.2438, 0.4683, 0.0448, 0.0169, 0.4702,\n",
      "        0.4700, 0.1305, 0.4683, 0.4673, 0.4658, 0.4642, 0.4623, 0.2485, 0.4576,\n",
      "        0.2494, 0.2500, 0.4498, 0.4474, 0.4458, 0.2507, 0.1414],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "111000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 27, 40, 47, 40, 27, 40, 27, 40, 47, 27, 47, 27, 40, 40, 40, 40, 47,\n",
      "        14, 40, 40, 40, 41, 47, 29])\n",
      "loss=  tensor(1799.9324, grad_fn=<AddBackward0>)   , actor=  tensor(170.0046, grad_fn=<DivBackward0>)   , critic=  tensor(16299.2773, grad_fn=<SumBackward0>)   , return=  175439.5604957522\n",
      "probs of actions:  tensor([0.4684, 0.2187, 0.4786, 0.1410, 0.4834, 0.2206, 0.4861, 0.2213, 0.4863,\n",
      "        0.1466, 0.2219, 0.1487, 0.2224, 0.4805, 0.4787, 0.4767, 0.4743, 0.1547,\n",
      "        0.0028, 0.4669, 0.4631, 0.4615, 0.0371, 0.1592, 0.0026],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "112000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([33, 27, 27, 47, 40, 40, 40, 27, 30, 40, 40, 27, 40, 27, 27, 27, 40, 26,\n",
      "        27, 47, 27, 47, 27, 47, 40])\n",
      "loss=  tensor(1793.4324, grad_fn=<AddBackward0>)   , actor=  tensor(200.7385, grad_fn=<DivBackward0>)   , critic=  tensor(15926.9385, grad_fn=<SumBackward0>)   , return=  173589.84688154914\n",
      "probs of actions:  tensor([0.0201, 0.2191, 0.2198, 0.1482, 0.5013, 0.5030, 0.5040, 0.2218, 0.0019,\n",
      "        0.5036, 0.5029, 0.2235, 0.5000, 0.2244, 0.2253, 0.2260, 0.4910, 0.0316,\n",
      "        0.2280, 0.1627, 0.2286, 0.1638, 0.2295, 0.1650, 0.4724],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "113000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 40, 21, 40, 40, 40, 41, 47, 40, 47, 40, 47, 40, 40, 47, 40, 40, 27,\n",
      "        40, 40, 40, 26, 40, 27, 40])\n",
      "loss=  tensor(1837.4661, grad_fn=<AddBackward0>)   , actor=  tensor(167.6475, grad_fn=<DivBackward0>)   , critic=  tensor(16698.1855, grad_fn=<SumBackward0>)   , return=  176816.81686913522\n",
      "probs of actions:  tensor([0.5647, 0.5729, 0.0036, 0.5825, 0.5865, 0.5890, 0.0330, 0.1210, 0.5924,\n",
      "        0.1222, 0.5920, 0.1237, 0.5900, 0.5885, 0.1264, 0.5843, 0.5821, 0.1670,\n",
      "        0.5764, 0.5728, 0.5706, 0.0343, 0.5656, 0.1714, 0.5601],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "114000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([34, 40, 40, 47, 40, 27, 40, 27, 40, 33, 40, 27, 27, 27, 27, 47, 40, 31,\n",
      "        41, 40, 27, 33, 40, 43, 47])\n",
      "loss=  tensor(1817.7230, grad_fn=<AddBackward0>)   , actor=  tensor(212.3707, grad_fn=<DivBackward0>)   , critic=  tensor(16053.5225, grad_fn=<SumBackward0>)   , return=  174053.13101015033\n",
      "probs of actions:  tensor([0.0052, 0.3140, 0.3150, 0.1330, 0.3156, 0.3805, 0.3145, 0.3850, 0.3129,\n",
      "        0.0424, 0.3111, 0.3895, 0.3910, 0.3912, 0.3915, 0.1413, 0.3021, 0.0069,\n",
      "        0.0371, 0.2976, 0.3909, 0.0444, 0.2929, 0.0022, 0.1453],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "115000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([41, 40, 27, 40, 14, 40, 40, 40, 40, 27, 41, 40, 27, 40, 27, 33, 27, 41,\n",
      "        40, 30, 27, 40, 40, 40, 40])\n",
      "loss=  tensor(1817.3916, grad_fn=<AddBackward0>)   , actor=  tensor(209.3783, grad_fn=<DivBackward0>)   , critic=  tensor(16080.1328, grad_fn=<SumBackward0>)   , return=  174184.06228266636\n",
      "probs of actions:  tensor([0.0434, 0.4489, 0.2708, 0.4543, 0.0025, 0.4560, 0.4578, 0.4579, 0.4576,\n",
      "        0.2810, 0.0367, 0.4543, 0.2837, 0.4507, 0.2852, 0.0487, 0.2874, 0.0362,\n",
      "        0.4383, 0.0028, 0.2899, 0.4315, 0.4289, 0.4274, 0.4255],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "116000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 27, 40, 40, 40, 27, 40, 40, 27, 30, 40, 40, 40, 40, 41, 41, 40, 40,\n",
      "        47, 33, 27, 26, 40, 27, 27])\n",
      "loss=  tensor(1842.9867, grad_fn=<AddBackward0>)   , actor=  tensor(183.5430, grad_fn=<DivBackward0>)   , critic=  tensor(16594.4375, grad_fn=<SumBackward0>)   , return=  176824.65999462956\n",
      "probs of actions:  tensor([0.4862, 0.2171, 0.4962, 0.4990, 0.5011, 0.2199, 0.5034, 0.5037, 0.2218,\n",
      "        0.0022, 0.5015, 0.5003, 0.4989, 0.4972, 0.0355, 0.0355, 0.4898, 0.4871,\n",
      "        0.1428, 0.0406, 0.2304, 0.0377, 0.4731, 0.2324, 0.2331],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "117000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 47, 27, 40, 40, 40, 47, 47, 40, 47, 27, 40, 47, 40, 40, 40, 40, 27,\n",
      "        33, 33, 40, 40, 40, 40, 31])\n",
      "loss=  tensor(1836.8593, grad_fn=<AddBackward0>)   , actor=  tensor(164.0345, grad_fn=<DivBackward0>)   , critic=  tensor(16728.2480, grad_fn=<SumBackward0>)   , return=  177059.27358053933\n",
      "probs of actions:  tensor([0.4811, 0.1185, 0.1950, 0.4953, 0.4981, 0.5000, 0.1203, 0.1210, 0.5019,\n",
      "        0.1223, 0.1994, 0.4995, 0.1249, 0.4966, 0.4947, 0.4920, 0.4894, 0.2044,\n",
      "        0.0531, 0.0536, 0.4780, 0.4754, 0.4734, 0.4712, 0.0076],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "118000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([26, 47, 40, 27, 40, 33, 40, 40, 40, 40, 27, 33, 27, 40, 40, 40, 33, 40,\n",
      "        40, 27, 33, 47, 40, 27, 27])\n",
      "loss=  tensor(1831.8607, grad_fn=<AddBackward0>)   , actor=  tensor(182.2419, grad_fn=<DivBackward0>)   , critic=  tensor(16496.1875, grad_fn=<SumBackward0>)   , return=  176417.07335892445\n",
      "probs of actions:  tensor([0.0442, 0.0715, 0.6047, 0.1649, 0.6130, 0.0327, 0.6175, 0.6185, 0.6189,\n",
      "        0.6188, 0.1664, 0.0321, 0.1677, 0.6134, 0.6109, 0.6086, 0.0334, 0.6033,\n",
      "        0.5999, 0.1736, 0.0347, 0.0804, 0.5877, 0.1768, 0.1778],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "119000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([27, 40, 40, 40, 40, 27, 27, 41, 27, 27, 26, 40, 41, 40, 27, 26, 41, 27,\n",
      "        40, 40, 33, 27, 40, 27, 40])\n",
      "loss=  tensor(1792.6290, grad_fn=<AddBackward0>)   , actor=  tensor(184.4319, grad_fn=<DivBackward0>)   , critic=  tensor(16081.9717, grad_fn=<SumBackward0>)   , return=  174439.44495661423\n",
      "probs of actions:  tensor([0.2411, 0.5062, 0.5102, 0.5136, 0.5163, 0.2437, 0.2450, 0.0465, 0.2460,\n",
      "        0.2471, 0.0374, 0.5187, 0.0450, 0.5163, 0.2494, 0.0378, 0.0449, 0.2522,\n",
      "        0.5039, 0.5008, 0.0539, 0.2548, 0.4938, 0.2557, 0.4890],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "120000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 40, 40, 40, 27, 40, 40, 27, 40, 41, 41, 40, 40, 27, 26, 33, 40, 27,\n",
      "        31, 27, 33, 27, 40, 40, 41])\n",
      "loss=  tensor(1795.7332, grad_fn=<AddBackward0>)   , actor=  tensor(172.6869, grad_fn=<DivBackward0>)   , critic=  tensor(16230.4629, grad_fn=<SumBackward0>)   , return=  174751.09257635282\n",
      "probs of actions:  tensor([0.5119, 0.5190, 0.5236, 0.5274, 0.2290, 0.5330, 0.5348, 0.2308, 0.5363,\n",
      "        0.0500, 0.0498, 0.5351, 0.5341, 0.2338, 0.0392, 0.0616, 0.5255, 0.2369,\n",
      "        0.0091, 0.2385, 0.0638, 0.2398, 0.5104, 0.5076, 0.0498],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "121000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 41, 27, 42, 40, 40, 40, 40, 40, 27, 26, 26, 27, 40, 27, 27, 40, 40,\n",
      "        45, 40, 34, 33, 41, 40, 40])\n",
      "loss=  tensor(1837.2996, grad_fn=<AddBackward0>)   , actor=  tensor(217.4630, grad_fn=<DivBackward0>)   , critic=  tensor(16198.3652, grad_fn=<SumBackward0>)   , return=  174944.20361316815\n",
      "probs of actions:  tensor([0.4088, 0.0868, 0.2855, 0.0072, 0.4225, 0.4241, 0.4252, 0.4258, 0.4260,\n",
      "        0.2964, 0.0603, 0.0603, 0.2994, 0.4221, 0.2999, 0.3010, 0.4167, 0.4145,\n",
      "        0.0012, 0.4111, 0.0034, 0.0504, 0.0775, 0.4032, 0.4017],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "122000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([47, 27, 41, 27, 27, 40, 27, 41, 40, 27, 27, 40, 40, 27, 40, 41, 27, 40,\n",
      "        27, 26, 27, 27, 40, 40, 41])\n",
      "loss=  tensor(1774.0065, grad_fn=<AddBackward0>)   , actor=  tensor(174.4910, grad_fn=<DivBackward0>)   , critic=  tensor(15995.1553, grad_fn=<SumBackward0>)   , return=  173653.50497982252\n",
      "probs of actions:  tensor([0.0715, 0.2505, 0.1072, 0.2543, 0.2565, 0.3927, 0.2594, 0.1025, 0.3951,\n",
      "        0.2627, 0.2638, 0.3941, 0.3933, 0.2652, 0.3912, 0.0980, 0.2672, 0.3860,\n",
      "        0.2684, 0.0675, 0.2697, 0.2700, 0.3759, 0.3740, 0.0958],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "123000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([29, 27, 40, 41, 41, 47, 40, 41, 27, 40, 40, 40, 27, 40, 26, 27, 40, 47,\n",
      "        40, 27, 27, 40, 27, 27, 27])\n",
      "loss=  tensor(1855.0508, grad_fn=<AddBackward0>)   , actor=  tensor(206.6271, grad_fn=<DivBackward0>)   , critic=  tensor(16484.2363, grad_fn=<SumBackward0>)   , return=  176237.45862479907\n",
      "probs of actions:  tensor([0.0085, 0.3147, 0.3031, 0.0981, 0.0971, 0.0745, 0.3065, 0.0944, 0.3346,\n",
      "        0.3061, 0.3056, 0.3050, 0.3397, 0.3031, 0.0786, 0.3425, 0.2988, 0.0792,\n",
      "        0.2962, 0.3439, 0.3446, 0.2918, 0.3443, 0.3448, 0.3446],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "124000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([26, 27, 40, 40, 40, 27, 27, 26, 40, 27, 40, 27, 26, 40, 40, 40, 21, 27,\n",
      "        33, 41, 41, 27, 47, 40, 26])\n",
      "loss=  tensor(1795.7566, grad_fn=<AddBackward0>)   , actor=  tensor(196.0376, grad_fn=<DivBackward0>)   , critic=  tensor(15997.1895, grad_fn=<SumBackward0>)   , return=  174366.37444403183\n",
      "probs of actions:  tensor([0.1158, 0.3194, 0.3042, 0.3055, 0.3064, 0.3338, 0.3373, 0.1108, 0.3071,\n",
      "        0.3439, 0.3061, 0.3467, 0.1091, 0.3036, 0.3023, 0.3011, 0.0039, 0.3530,\n",
      "        0.0298, 0.0837, 0.0834, 0.3540, 0.0652, 0.2901, 0.1092],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "125000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([27, 12, 40, 42, 27, 47, 40, 26, 27, 40, 26, 26, 27, 40, 27, 26, 47, 33,\n",
      "        41, 31, 47, 41, 27, 27, 26])\n",
      "loss=  tensor(1860.6257, grad_fn=<AddBackward0>)   , actor=  tensor(256.6014, grad_fn=<DivBackward0>)   , critic=  tensor(16040.2432, grad_fn=<SumBackward0>)   , return=  174329.78638846165\n",
      "probs of actions:  tensor([0.2661, 0.0026, 0.2540, 0.0182, 0.2776, 0.0648, 0.2564, 0.1693, 0.2875,\n",
      "        0.2557, 0.1687, 0.1680, 0.2933, 0.2530, 0.2948, 0.1671, 0.0687, 0.0304,\n",
      "        0.1115, 0.0215, 0.0700, 0.1099, 0.2991, 0.2998, 0.1655],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "126000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([26, 41, 27, 26, 41, 26, 40, 47, 40, 33, 27, 31, 40, 27, 41, 27, 40, 27,\n",
      "        40, 33, 27, 40, 41, 40, 40])\n",
      "loss=  tensor(1828.3358, grad_fn=<AddBackward0>)   , actor=  tensor(225.9854, grad_fn=<DivBackward0>)   , critic=  tensor(16023.5049, grad_fn=<SumBackward0>)   , return=  174093.23869288695\n",
      "probs of actions:  tensor([0.1493, 0.1424, 0.2953, 0.1491, 0.1404, 0.1488, 0.2507, 0.0630, 0.2506,\n",
      "        0.0254, 0.3151, 0.0148, 0.2488, 0.3178, 0.1321, 0.3197, 0.2452, 0.3211,\n",
      "        0.2432, 0.0265, 0.3225, 0.2403, 0.1270, 0.2386, 0.2379],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "127000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([47, 27, 47, 33, 40, 40, 26, 27, 27, 41, 30, 27, 27, 27, 31, 27, 40, 26,\n",
      "        27, 41, 40, 47, 27, 40, 40])\n",
      "loss=  tensor(1828.9890, grad_fn=<AddBackward0>)   , actor=  tensor(237.2220, grad_fn=<DivBackward0>)   , critic=  tensor(15917.6689, grad_fn=<SumBackward0>)   , return=  173522.42795004798\n",
      "probs of actions:  tensor([0.0746, 0.2669, 0.0745, 0.0312, 0.2450, 0.2456, 0.1599, 0.2825, 0.2844,\n",
      "        0.1209, 0.0051, 0.2878, 0.2889, 0.2895, 0.0199, 0.2911, 0.2403, 0.1581,\n",
      "        0.2927, 0.1148, 0.2362, 0.0808, 0.2929, 0.2340, 0.2328],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "128000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 26, 27, 27, 27, 27, 40, 41, 27, 47, 41, 47, 27, 27, 41, 26, 33, 27,\n",
      "        26, 47, 33, 47, 26, 27, 27])\n",
      "loss=  tensor(1821.2272, grad_fn=<AddBackward0>)   , actor=  tensor(210.2656, grad_fn=<DivBackward0>)   , critic=  tensor(16109.6152, grad_fn=<SumBackward0>)   , return=  174736.94251074977\n",
      "probs of actions:  tensor([0.1721, 0.1364, 0.3351, 0.3392, 0.3433, 0.3471, 0.1725, 0.1530, 0.3550,\n",
      "        0.0718, 0.1504, 0.0725, 0.3604, 0.3620, 0.1475, 0.1321, 0.0326, 0.3644,\n",
      "        0.1314, 0.0755, 0.0335, 0.0759, 0.1315, 0.3648, 0.3644],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "129000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([41, 40, 41, 42, 27, 33, 47, 33, 42, 26, 40, 41, 27, 33, 27, 41, 27, 33,\n",
      "        40, 27, 41, 27, 27, 45, 27])\n",
      "loss=  tensor(1905.9048, grad_fn=<AddBackward0>)   , actor=  tensor(272.9779, grad_fn=<DivBackward0>)   , critic=  tensor(16329.2686, grad_fn=<SumBackward0>)   , return=  175429.86184368798\n",
      "probs of actions:  tensor([0.1503, 0.2612, 0.1486, 0.0181, 0.2767, 0.0321, 0.0689, 0.0316, 0.0164,\n",
      "        0.1301, 0.2652, 0.1411, 0.2922, 0.0313, 0.2946, 0.1381, 0.2964, 0.0318,\n",
      "        0.2582, 0.2984, 0.1348, 0.2993, 0.2999, 0.0026, 0.2999],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "130000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([33, 40, 27, 27, 27, 27, 27, 31, 27, 26, 33, 40, 27, 27, 27, 27, 41, 27,\n",
      "        27, 40, 33, 27, 40, 27, 27])\n",
      "loss=  tensor(1772.0770, grad_fn=<AddBackward0>)   , actor=  tensor(189.8737, grad_fn=<DivBackward0>)   , critic=  tensor(15822.0332, grad_fn=<SumBackward0>)   , return=  173634.74358787315\n",
      "probs of actions:  tensor([0.0378, 0.1834, 0.3735, 0.3792, 0.3849, 0.3898, 0.3940, 0.0172, 0.4006,\n",
      "        0.1230, 0.0337, 0.1799, 0.4074, 0.4092, 0.4103, 0.4112, 0.1230, 0.4118,\n",
      "        0.4128, 0.1747, 0.0349, 0.4128, 0.1731, 0.4121, 0.4124],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "131000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 41, 40, 27, 27, 27, 26, 21, 27, 26, 27, 40, 27, 26, 26, 41, 27, 43,\n",
      "        26, 27, 33, 41, 42, 27, 41])\n",
      "loss=  tensor(1792.1548, grad_fn=<AddBackward0>)   , actor=  tensor(227.0417, grad_fn=<DivBackward0>)   , critic=  tensor(15651.1299, grad_fn=<SumBackward0>)   , return=  172583.62956484198\n",
      "probs of actions:  tensor([0.2223, 0.1399, 0.2257, 0.3182, 0.3223, 0.3260, 0.1402, 0.0084, 0.3342,\n",
      "        0.1396, 0.3376, 0.2269, 0.3392, 0.1393, 0.1392, 0.1303, 0.3422, 0.0020,\n",
      "        0.1395, 0.3437, 0.0312, 0.1266, 0.0217, 0.3435, 0.1256],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "132000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([41, 41, 40, 41, 40, 27, 41, 27, 27, 27, 31, 27, 31, 40, 40, 40, 27, 41,\n",
      "        47, 41, 26, 27, 33, 27, 26])\n",
      "loss=  tensor(1858.6785, grad_fn=<AddBackward0>)   , actor=  tensor(221.9788, grad_fn=<DivBackward0>)   , critic=  tensor(16366.9971, grad_fn=<SumBackward0>)   , return=  175876.2197315135\n",
      "probs of actions:  tensor([0.1781, 0.1778, 0.2303, 0.1785, 0.2328, 0.2173, 0.1783, 0.2205, 0.2219,\n",
      "        0.2231, 0.0246, 0.2248, 0.0246, 0.2351, 0.2347, 0.2342, 0.2275, 0.1706,\n",
      "        0.0618, 0.1684, 0.1690, 0.2300, 0.0325, 0.2305, 0.1683],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "133000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([41, 21, 27, 26, 27, 40, 40, 33, 27, 29, 26, 40, 27, 26, 26, 47, 41, 30,\n",
      "        26, 41, 41, 47, 27, 47, 27])\n",
      "loss=  tensor(1853.1644, grad_fn=<AddBackward0>)   , actor=  tensor(266.3891, grad_fn=<DivBackward0>)   , critic=  tensor(15867.7529, grad_fn=<SumBackward0>)   , return=  173755.7018060816\n",
      "probs of actions:  tensor([0.1927, 0.0149, 0.1591, 0.2040, 0.1606, 0.2461, 0.2470, 0.0270, 0.1635,\n",
      "        0.0078, 0.2072, 0.2483, 0.1657, 0.2074, 0.2074, 0.0587, 0.1846, 0.0065,\n",
      "        0.2073, 0.1827, 0.1813, 0.0603, 0.1701, 0.0608, 0.1708],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "134000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([41, 41, 26, 31, 42, 40, 27, 26, 40, 27, 41, 47, 27, 41, 42, 41, 27, 26,\n",
      "        47, 41, 21, 27, 31, 26, 40])\n",
      "loss=  tensor(1868.1267, grad_fn=<AddBackward0>)   , actor=  tensor(251.1110, grad_fn=<DivBackward0>)   , critic=  tensor(16170.1572, grad_fn=<SumBackward0>)   , return=  174597.7703709052\n",
      "probs of actions:  tensor([0.1936, 0.1934, 0.2071, 0.0326, 0.0332, 0.1830, 0.1435, 0.2100, 0.1835,\n",
      "        0.1453, 0.1921, 0.1153, 0.1464, 0.1896, 0.0311, 0.1872, 0.1480, 0.2112,\n",
      "        0.1181, 0.1824, 0.0147, 0.1502, 0.0329, 0.2100, 0.1773],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "135000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([41, 41, 27, 40, 41, 26, 31, 27, 26, 41, 41, 26, 31, 40, 41, 27, 41, 40,\n",
      "        47, 40, 21, 31, 47, 41, 26])\n",
      "loss=  tensor(1865.0452, grad_fn=<AddBackward0>)   , actor=  tensor(244.2262, grad_fn=<DivBackward0>)   , critic=  tensor(16208.1895, grad_fn=<SumBackward0>)   , return=  175209.84335362393\n",
      "probs of actions:  tensor([0.1678, 0.1673, 0.1235, 0.1583, 0.1682, 0.2440, 0.0370, 0.1259, 0.2461,\n",
      "        0.1665, 0.1654, 0.2477, 0.0365, 0.1588, 0.1625, 0.1286, 0.1614, 0.1573,\n",
      "        0.1237, 0.1565, 0.0173, 0.0378, 0.1245, 0.1550, 0.2433],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "136000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([41, 41, 26, 40, 41, 26, 40, 40, 26, 41, 26, 27, 31, 26, 27, 26, 27, 31,\n",
      "        40, 26, 40, 26, 41, 12, 42])\n",
      "loss=  tensor(1816.2698, grad_fn=<AddBackward0>)   , actor=  tensor(226.1388, grad_fn=<DivBackward0>)   , critic=  tensor(15901.3096, grad_fn=<SumBackward0>)   , return=  173357.5093136458\n",
      "probs of actions:  tensor([0.1492, 0.1485, 0.2076, 0.2131, 0.1490, 0.2104, 0.2164, 0.2172, 0.2126,\n",
      "        0.1476, 0.2135, 0.1055, 0.0368, 0.2135, 0.1061, 0.2133, 0.1068, 0.0375,\n",
      "        0.2142, 0.2128, 0.2129, 0.2122, 0.1393, 0.0032, 0.0369],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "137000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([27, 29, 34, 40, 41, 40, 27, 40, 41, 27, 40, 41, 47, 27, 26, 41, 40, 27,\n",
      "        27, 26, 40, 41, 41, 27, 26])\n",
      "loss=  tensor(1893.6824, grad_fn=<AddBackward0>)   , actor=  tensor(260.6649, grad_fn=<DivBackward0>)   , critic=  tensor(16330.1738, grad_fn=<SumBackward0>)   , return=  175750.96304347963\n",
      "probs of actions:  tensor([0.1032, 0.0143, 0.0060, 0.2353, 0.1485, 0.2378, 0.1028, 0.2394, 0.1471,\n",
      "        0.1034, 0.2404, 0.1454, 0.1373, 0.1040, 0.1951, 0.1432, 0.2378, 0.1054,\n",
      "        0.1057, 0.1948, 0.2343, 0.1389, 0.1386, 0.1070, 0.1939],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "138000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([41, 42, 47, 26, 26, 40, 40, 26, 40, 34, 42, 41, 26, 26, 27, 47, 40, 26,\n",
      "        40, 41, 47, 27, 47, 29, 40])\n",
      "loss=  tensor(1868.1526, grad_fn=<AddBackward0>)   , actor=  tensor(249.1966, grad_fn=<DivBackward0>)   , critic=  tensor(16189.5586, grad_fn=<SumBackward0>)   , return=  174821.62275223059\n",
      "probs of actions:  tensor([0.1323, 0.0484, 0.1009, 0.2222, 0.2222, 0.2376, 0.2387, 0.2258, 0.2397,\n",
      "        0.0042, 0.0452, 0.1272, 0.2278, 0.2274, 0.1275, 0.1048, 0.2369, 0.2274,\n",
      "        0.2357, 0.1226, 0.1054, 0.1299, 0.1057, 0.0148, 0.2307],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "139000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([41, 26, 26, 40, 26, 26, 26, 27, 27, 26, 27, 26, 41, 47, 40, 27, 40, 26,\n",
      "        26, 41, 40, 40, 40, 26, 41])\n",
      "loss=  tensor(1775.8669, grad_fn=<AddBackward0>)   , actor=  tensor(199.5251, grad_fn=<DivBackward0>)   , critic=  tensor(15763.4189, grad_fn=<SumBackward0>)   , return=  173175.58774098862\n",
      "probs of actions:  tensor([0.1529, 0.2134, 0.2135, 0.2013, 0.2165, 0.2168, 0.2180, 0.1524, 0.1529,\n",
      "        0.2202, 0.1538, 0.2209, 0.1476, 0.1119, 0.2042, 0.1553, 0.2034, 0.2215,\n",
      "        0.2209, 0.1425, 0.2007, 0.2003, 0.1998, 0.2202, 0.1397],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "140000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([27, 27, 27, 40, 27, 27, 21, 26, 27, 26, 47, 27, 26, 34, 40, 27, 26, 26,\n",
      "        40, 26, 21, 26, 40, 27, 27])\n",
      "loss=  tensor(1790.8506, grad_fn=<AddBackward0>)   , actor=  tensor(226.2778, grad_fn=<DivBackward0>)   , critic=  tensor(15645.7275, grad_fn=<SumBackward0>)   , return=  172646.56784006523\n",
      "probs of actions:  tensor([0.2070, 0.2084, 0.2100, 0.2015, 0.2125, 0.2143, 0.0236, 0.2374, 0.2180,\n",
      "        0.2388, 0.1002, 0.2194, 0.2393, 0.0026, 0.2026, 0.2216, 0.2389, 0.2386,\n",
      "        0.2001, 0.2385, 0.0241, 0.2372, 0.1976, 0.2238, 0.2243],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "141000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([47, 47, 30, 41, 27, 40, 41, 40, 40, 40, 27, 27, 33, 47, 46, 40, 47, 26,\n",
      "        47, 42, 26, 47, 47, 40, 26])\n",
      "loss=  tensor(1941.0272, grad_fn=<AddBackward0>)   , actor=  tensor(288.6988, grad_fn=<DivBackward0>)   , critic=  tensor(16523.2852, grad_fn=<SumBackward0>)   , return=  176421.35801890405\n",
      "probs of actions:  tensor([0.0990, 0.0991, 0.0077, 0.1126, 0.1608, 0.1804, 0.1105, 0.1813, 0.1815,\n",
      "        0.1816, 0.1645, 0.1651, 0.0172, 0.1017, 0.0039, 0.1805, 0.1019, 0.2793,\n",
      "        0.1022, 0.0371, 0.2778, 0.1026, 0.1025, 0.1767, 0.2756],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "142000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([41, 26, 41, 42, 40, 26, 26, 40, 40, 41, 46, 26, 26, 26, 26, 41, 27, 42,\n",
      "        27, 31, 40, 26, 26, 41, 26])\n",
      "loss=  tensor(1853.9375, grad_fn=<AddBackward0>)   , actor=  tensor(236.4106, grad_fn=<DivBackward0>)   , critic=  tensor(16175.2695, grad_fn=<SumBackward0>)   , return=  174796.67642981198\n",
      "probs of actions:  tensor([0.1495, 0.3033, 0.1491, 0.0400, 0.1654, 0.3130, 0.3143, 0.1664, 0.1667,\n",
      "        0.1456, 0.0036, 0.3216, 0.3209, 0.3214, 0.3215, 0.1415, 0.1108, 0.0371,\n",
      "        0.1114, 0.0251, 0.1644, 0.3188, 0.3177, 0.1365, 0.3166],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "143000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([21, 26, 21, 26, 41, 26, 26, 40, 40, 33, 40, 26, 40, 26, 45, 40, 26, 21,\n",
      "        26, 26, 26, 26, 29, 26, 26])\n",
      "loss=  tensor(1815.3651, grad_fn=<AddBackward0>)   , actor=  tensor(229.1577, grad_fn=<DivBackward0>)   , critic=  tensor(15862.0742, grad_fn=<SumBackward0>)   , return=  173327.2007164591\n",
      "probs of actions:  tensor([0.0430, 0.3427, 0.0418, 0.3495, 0.1422, 0.3571, 0.3584, 0.1830, 0.1833,\n",
      "        0.0154, 0.1835, 0.3666, 0.1835, 0.3673, 0.0041, 0.1828, 0.3666, 0.0414,\n",
      "        0.3645, 0.3640, 0.3632, 0.3624, 0.0108, 0.3609, 0.3599],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "144000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([26, 26, 26, 40, 26, 40, 41, 26, 21, 40, 40, 26, 21, 40, 26, 41, 40, 26,\n",
      "        26, 27, 36, 26, 40, 26, 41])\n",
      "loss=  tensor(1774.4768, grad_fn=<AddBackward0>)   , actor=  tensor(200.9467, grad_fn=<DivBackward0>)   , critic=  tensor(15735.3018, grad_fn=<SumBackward0>)   , return=  172776.91393252029\n",
      "probs of actions:  tensor([0.3857, 0.3962, 0.4005, 0.1679, 0.4095, 0.1685, 0.1358, 0.4192, 0.0352,\n",
      "        0.1689, 0.1689, 0.4256, 0.0352, 0.1687, 0.4265, 0.1306, 0.1680, 0.4254,\n",
      "        0.4240, 0.0927, 0.0006, 0.4217, 0.1665, 0.4200, 0.1267],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "145000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([41, 42, 27, 26, 41, 31, 40, 40, 26, 33, 41, 26, 26, 41, 40, 40, 47, 40,\n",
      "        41, 42, 40, 26, 40, 40, 26])\n",
      "loss=  tensor(1881.8998, grad_fn=<AddBackward0>)   , actor=  tensor(242.2607, grad_fn=<DivBackward0>)   , critic=  tensor(16396.3906, grad_fn=<SumBackward0>)   , return=  176114.39049432072\n",
      "probs of actions:  tensor([0.2080, 0.0345, 0.0682, 0.3298, 0.2092, 0.0147, 0.2118, 0.2124, 0.3422,\n",
      "        0.0147, 0.2060, 0.3459, 0.3456, 0.2037, 0.2133, 0.2130, 0.0383, 0.2124,\n",
      "        0.1992, 0.0307, 0.2113, 0.3462, 0.2104, 0.2100, 0.3448],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "146000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([26, 21, 47, 40, 21, 47, 26, 26, 26, 40, 40, 26, 42, 40, 26, 41, 40, 41,\n",
      "        26, 41, 40, 26, 40, 21, 26])\n",
      "loss=  tensor(1840.2689, grad_fn=<AddBackward0>)   , actor=  tensor(222.4758, grad_fn=<DivBackward0>)   , critic=  tensor(16177.9307, grad_fn=<SumBackward0>)   , return=  174905.63755760866\n",
      "probs of actions:  tensor([0.2720, 0.0414, 0.0422, 0.2478, 0.0405, 0.0412, 0.2887, 0.2888, 0.2904,\n",
      "        0.2536, 0.2541, 0.2939, 0.0362, 0.2544, 0.2950, 0.1879, 0.2534, 0.1858,\n",
      "        0.2953, 0.1847, 0.2510, 0.2947, 0.2497, 0.0420, 0.2930],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "147000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 40, 41, 21, 26, 41, 41, 40, 26, 42, 40, 41, 41, 47, 26, 31, 20, 27,\n",
      "        27, 21, 26, 26, 27, 26, 40])\n",
      "loss=  tensor(1868.6079, grad_fn=<AddBackward0>)   , actor=  tensor(263.3314, grad_fn=<DivBackward0>)   , critic=  tensor(16052.7646, grad_fn=<SumBackward0>)   , return=  173694.52031096208\n",
      "probs of actions:  tensor([0.2305, 0.2341, 0.1602, 0.0322, 0.3064, 0.1600, 0.1589, 0.2417, 0.3159,\n",
      "        0.0388, 0.2430, 0.1561, 0.1555, 0.0481, 0.3207, 0.0167, 0.0005, 0.0931,\n",
      "        0.0934, 0.0324, 0.3189, 0.3188, 0.0947, 0.3180, 0.2370],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "148000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 27, 40, 26, 26, 26, 40, 26, 26, 40, 31, 41, 41, 40, 15, 40, 41, 47,\n",
      "        27, 41, 41, 40, 26, 27, 29])\n",
      "loss=  tensor(1845.4052, grad_fn=<AddBackward0>)   , actor=  tensor(233.6910, grad_fn=<DivBackward0>)   , critic=  tensor(16117.1406, grad_fn=<SumBackward0>)   , return=  174909.18033659185\n",
      "probs of actions:  tensor([0.2367, 0.0977, 0.2414, 0.3000, 0.3007, 0.3026, 0.2463, 0.3066, 0.3068,\n",
      "        0.2479, 0.0152, 0.1837, 0.1826, 0.2483, 0.0009, 0.2475, 0.1795, 0.0428,\n",
      "        0.0969, 0.1783, 0.1768, 0.2447, 0.3087, 0.0988, 0.0069],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "149000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([26, 26, 47, 40, 27, 26, 40, 27, 42, 41, 27, 40, 41, 41, 40, 43, 40, 40,\n",
      "        40, 42, 24, 30, 41, 40, 40])\n",
      "loss=  tensor(1891.6482, grad_fn=<AddBackward0>)   , actor=  tensor(266.2405, grad_fn=<DivBackward0>)   , critic=  tensor(16254.0771, grad_fn=<SumBackward0>)   , return=  175086.6123071372\n",
      "probs of actions:  tensor([0.2227, 0.2264, 0.0574, 0.2863, 0.0989, 0.2294, 0.2907, 0.0984, 0.0334,\n",
      "        0.1714, 0.0984, 0.2936, 0.1694, 0.1688, 0.2933, 0.0018, 0.2922, 0.2913,\n",
      "        0.2904, 0.0333, 0.0007, 0.0062, 0.1626, 0.2849, 0.2842],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "150000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 40, 40, 40, 26, 40, 26, 27, 41, 27, 27, 41, 26, 40, 40, 40, 27, 41,\n",
      "        40, 26, 41, 41, 26, 40, 40])\n",
      "loss=  tensor(1804.2336, grad_fn=<AddBackward0>)   , actor=  tensor(191.9213, grad_fn=<DivBackward0>)   , critic=  tensor(16123.1221, grad_fn=<SumBackward0>)   , return=  174594.1017927382\n",
      "probs of actions:  tensor([0.2694, 0.2734, 0.2753, 0.2769, 0.2926, 0.2795, 0.2954, 0.0673, 0.1879,\n",
      "        0.0669, 0.0671, 0.1857, 0.2999, 0.2826, 0.2824, 0.2821, 0.0678, 0.1817,\n",
      "        0.2800, 0.2996, 0.1797, 0.1783, 0.2987, 0.2762, 0.2752],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "151000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([26, 40, 26, 30, 41, 26, 41, 31, 47, 26, 26, 26, 27, 40, 31, 27, 40, 26,\n",
      "        27, 40, 41, 42, 26, 40, 26])\n",
      "loss=  tensor(1841.7231, grad_fn=<AddBackward0>)   , actor=  tensor(242.5875, grad_fn=<DivBackward0>)   , critic=  tensor(15991.3564, grad_fn=<SumBackward0>)   , return=  174294.21941357598\n",
      "probs of actions:  tensor([0.3028, 0.2117, 0.3134, 0.0061, 0.1621, 0.3191, 0.1615, 0.0270, 0.0539,\n",
      "        0.3250, 0.3243, 0.3250, 0.0794, 0.2184, 0.0269, 0.0796, 0.2179, 0.3254,\n",
      "        0.0803, 0.2163, 0.1516, 0.0543, 0.3230, 0.2145, 0.3215],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "152000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([26, 26, 40, 41, 26, 41, 26, 40, 41, 31, 41, 42, 41, 26, 26, 41, 26, 41,\n",
      "        26, 26, 42, 47, 41, 26, 42])\n",
      "loss=  tensor(1808.7111, grad_fn=<AddBackward0>)   , actor=  tensor(203.7681, grad_fn=<DivBackward0>)   , critic=  tensor(16049.4297, grad_fn=<SumBackward0>)   , return=  174239.2172456826\n",
      "probs of actions:  tensor([0.3219, 0.3294, 0.2295, 0.1634, 0.3377, 0.1633, 0.3420, 0.2354, 0.1606,\n",
      "        0.0245, 0.1596, 0.0440, 0.1578, 0.3486, 0.3479, 0.1562, 0.3486, 0.1551,\n",
      "        0.3480, 0.3470, 0.0438, 0.0465, 0.1517, 0.3457, 0.0441],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "153000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([26, 26, 40, 40, 41, 26, 26, 26, 40, 40, 31, 26, 47, 40, 26, 40, 26, 47,\n",
      "        26, 40, 41, 26, 26, 26, 42])\n",
      "loss=  tensor(1781.1829, grad_fn=<AddBackward0>)   , actor=  tensor(181.1041, grad_fn=<DivBackward0>)   , critic=  tensor(16000.7871, grad_fn=<SumBackward0>)   , return=  173982.72772832582\n",
      "probs of actions:  tensor([0.3921, 0.4014, 0.2300, 0.2312, 0.1462, 0.4150, 0.4168, 0.4196, 0.2353,\n",
      "        0.2357, 0.0179, 0.4255, 0.0290, 0.2367, 0.4272, 0.2368, 0.4270, 0.0297,\n",
      "        0.4265, 0.2364, 0.1347, 0.4247, 0.4235, 0.4226, 0.0325],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "154000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([41, 26, 26, 40, 41, 40, 26, 40, 26, 27, 27, 40, 40, 26, 26, 40, 26, 40,\n",
      "        47, 27, 27, 26, 40, 41, 40])\n",
      "loss=  tensor(1775.1333, grad_fn=<AddBackward0>)   , actor=  tensor(185.5826, grad_fn=<DivBackward0>)   , critic=  tensor(15895.5078, grad_fn=<SumBackward0>)   , return=  173457.91717338667\n",
      "probs of actions:  tensor([0.1372, 0.4157, 0.4182, 0.2295, 0.1319, 0.2313, 0.4333, 0.2327, 0.4386,\n",
      "        0.0606, 0.0604, 0.2343, 0.2344, 0.4437, 0.4430, 0.2346, 0.4438, 0.2345,\n",
      "        0.0362, 0.0607, 0.0609, 0.4407, 0.2330, 0.1190, 0.2324],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "155000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 42, 40, 26, 45, 40, 40, 26, 41, 26, 42, 26, 26, 26, 26, 26, 41, 40,\n",
      "        41, 26, 40, 40, 47, 27, 41])\n",
      "loss=  tensor(1820.6405, grad_fn=<AddBackward0>)   , actor=  tensor(214.1809, grad_fn=<DivBackward0>)   , critic=  tensor(16064.5957, grad_fn=<SumBackward0>)   , return=  174302.4089736139\n",
      "probs of actions:  tensor([0.2338, 0.0310, 0.2388, 0.3356, 0.0035, 0.2429, 0.2438, 0.3459, 0.1905,\n",
      "        0.3501, 0.0269, 0.3529, 0.3527, 0.3537, 0.3544, 0.3549, 0.1820, 0.2483,\n",
      "        0.1802, 0.3561, 0.2477, 0.2472, 0.0305, 0.0827, 0.1766],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "156000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([26, 41, 41, 26, 41, 41, 41, 26, 41, 41, 40, 26, 41, 40, 40, 41, 41, 26,\n",
      "        26, 40, 26, 34, 47, 40, 26])\n",
      "loss=  tensor(1815.7988, grad_fn=<AddBackward0>)   , actor=  tensor(175.9978, grad_fn=<DivBackward0>)   , critic=  tensor(16398.0098, grad_fn=<SumBackward0>)   , return=  175865.9625763251\n",
      "probs of actions:  tensor([0.2578, 0.2691, 0.2692, 0.2673, 0.2717, 0.2708, 0.2707, 0.2734, 0.2705,\n",
      "        0.2686, 0.2327, 0.2778, 0.2665, 0.2340, 0.2342, 0.2622, 0.2610, 0.2809,\n",
      "        0.2804, 0.2343, 0.2815, 0.0037, 0.0295, 0.2334, 0.2815],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "157000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([26, 40, 40, 26, 26, 26, 26, 41, 26, 26, 41, 26, 26, 41, 40, 26, 26, 40,\n",
      "        40, 47, 40, 26, 40, 26, 26])\n",
      "loss=  tensor(1757.1736, grad_fn=<AddBackward0>)   , actor=  tensor(156.7266, grad_fn=<DivBackward0>)   , critic=  tensor(16004.4688, grad_fn=<SumBackward0>)   , return=  174512.55694260038\n",
      "probs of actions:  tensor([0.2824, 0.3214, 0.3244, 0.2913, 0.2919, 0.2938, 0.2956, 0.2124, 0.2993,\n",
      "        0.2994, 0.2092, 0.3023, 0.3020, 0.2060, 0.3391, 0.3044, 0.3041, 0.3386,\n",
      "        0.3384, 0.0225, 0.3375, 0.3058, 0.3366, 0.3061, 0.3056],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "158000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([26, 26, 26, 27, 41, 33, 40, 47, 33, 26, 26, 40, 40, 40, 41, 41, 41, 26,\n",
      "        40, 40, 26, 40, 40, 41, 26])\n",
      "loss=  tensor(1839.6133, grad_fn=<AddBackward0>)   , actor=  tensor(214.5186, grad_fn=<DivBackward0>)   , critic=  tensor(16250.9453, grad_fn=<SumBackward0>)   , return=  175452.95076145054\n",
      "probs of actions:  tensor([0.2782, 0.2818, 0.2828, 0.0337, 0.2050, 0.0179, 0.3952, 0.0153, 0.0173,\n",
      "        0.2896, 0.2902, 0.4014, 0.4019, 0.4021, 0.1939, 0.1930, 0.1922, 0.2941,\n",
      "        0.4016, 0.4010, 0.2950, 0.3998, 0.3987, 0.1877, 0.2959],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "159000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([26, 40, 40, 26, 41, 40, 40, 40, 40, 40, 40, 26, 40, 26, 40, 40, 40, 41,\n",
      "        40, 41, 41, 40, 26, 27, 40])\n",
      "loss=  tensor(1784.6456, grad_fn=<AddBackward0>)   , actor=  tensor(135.2896, grad_fn=<DivBackward0>)   , critic=  tensor(16493.5605, grad_fn=<SumBackward0>)   , return=  176270.23881614313\n",
      "probs of actions:  tensor([0.2493, 0.4109, 0.4151, 0.2537, 0.1808, 0.4241, 0.4264, 0.4283, 0.4298,\n",
      "        0.4309, 0.4317, 0.2580, 0.4321, 0.2589, 0.4319, 0.4317, 0.4312, 0.1704,\n",
      "        0.4301, 0.1694, 0.1689, 0.4270, 0.2611, 0.0332, 0.4231],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "160000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([26, 40, 40, 26, 40, 26, 40, 26, 42, 40, 40, 26, 40, 34, 21, 40, 40, 40,\n",
      "        41, 27, 40, 40, 40, 40, 41])\n",
      "loss=  tensor(1806.3583, grad_fn=<AddBackward0>)   , actor=  tensor(196.1551, grad_fn=<DivBackward0>)   , critic=  tensor(16102.0312, grad_fn=<SumBackward0>)   , return=  174562.73485341395\n",
      "probs of actions:  tensor([0.1517, 0.5782, 0.5841, 0.1502, 0.5926, 0.1492, 0.5994, 0.1488, 0.0150,\n",
      "        0.6056, 0.6062, 0.1492, 0.6060, 0.0022, 0.0059, 0.6037, 0.6026, 0.6014,\n",
      "        0.1237, 0.0310, 0.5963, 0.5937, 0.5921, 0.5903, 0.1235],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "161000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([27, 40, 41, 26, 26, 26, 42, 40, 40, 40, 27, 40, 40, 41, 41, 40, 40, 40,\n",
      "        40, 26, 47, 41, 40, 40, 26])\n",
      "loss=  tensor(1837.1879, grad_fn=<AddBackward0>)   , actor=  tensor(192.2179, grad_fn=<DivBackward0>)   , critic=  tensor(16449.6992, grad_fn=<SumBackward0>)   , return=  176384.9830840993\n",
      "probs of actions:  tensor([0.0478, 0.5686, 0.1234, 0.1430, 0.1422, 0.1419, 0.0156, 0.5921, 0.5935,\n",
      "        0.5945, 0.0419, 0.5947, 0.5946, 0.1163, 0.1161, 0.5921, 0.5908, 0.5891,\n",
      "        0.5871, 0.1465, 0.0214, 0.1152, 0.5787, 0.5766, 0.1492],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "162000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([41, 40, 40, 26, 34, 26, 40, 40, 41, 40, 41, 41, 26, 41, 40, 40, 40, 40,\n",
      "        40, 40, 40, 47, 41, 21, 41])\n",
      "loss=  tensor(1837.2493, grad_fn=<AddBackward0>)   , actor=  tensor(186.3007, grad_fn=<DivBackward0>)   , critic=  tensor(16509.4844, grad_fn=<SumBackward0>)   , return=  176401.37510268125\n",
      "probs of actions:  tensor([0.1637, 0.5306, 0.5352, 0.1585, 0.0023, 0.1580, 0.5474, 0.5496, 0.1553,\n",
      "        0.5513, 0.1541, 0.1536, 0.1601, 0.1533, 0.5488, 0.5477, 0.5460, 0.5441,\n",
      "        0.5422, 0.5402, 0.5381, 0.0227, 0.1505, 0.0062, 0.1509],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "163000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([26, 41, 40, 26, 45, 31, 40, 40, 40, 40, 40, 40, 26, 27, 40, 40, 41, 40,\n",
      "        40, 33, 41, 26, 40, 40, 40])\n",
      "loss=  tensor(1832.1873, grad_fn=<AddBackward0>)   , actor=  tensor(195.7904, grad_fn=<DivBackward0>)   , critic=  tensor(16363.9678, grad_fn=<SumBackward0>)   , return=  175574.12777369528\n",
      "probs of actions:  tensor([0.1698, 0.1482, 0.5510, 0.1697, 0.0032, 0.0142, 0.5641, 0.5663, 0.5677,\n",
      "        0.5685, 0.5689, 0.5689, 0.1717, 0.0299, 0.5665, 0.5651, 0.1376, 0.5621,\n",
      "        0.5604, 0.0244, 0.1372, 0.1777, 0.5524, 0.5497, 0.5481],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "164000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([27, 26, 40, 40, 26, 40, 40, 41, 40, 26, 40, 40, 40, 40, 26, 40, 41, 26,\n",
      "        41, 40, 40, 33, 42, 40, 40])\n",
      "loss=  tensor(1783.5676, grad_fn=<AddBackward0>)   , actor=  tensor(156.7158, grad_fn=<DivBackward0>)   , critic=  tensor(16268.5176, grad_fn=<SumBackward0>)   , return=  175284.21246672017\n",
      "probs of actions:  tensor([0.0536, 0.1850, 0.4586, 0.4625, 0.1856, 0.4675, 0.4703, 0.1788, 0.4731,\n",
      "        0.1874, 0.4740, 0.4744, 0.4742, 0.4737, 0.1900, 0.4719, 0.1730, 0.1918,\n",
      "        0.1727, 0.4653, 0.4640, 0.0315, 0.0264, 0.4589, 0.4575],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "165000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 40, 26, 40, 41, 26, 40, 41, 41, 26, 27, 40, 26, 40, 40, 40, 40, 40,\n",
      "        40, 40, 40, 26, 27, 40, 40])\n",
      "loss=  tensor(1783.1741, grad_fn=<AddBackward0>)   , actor=  tensor(151.8043, grad_fn=<DivBackward0>)   , critic=  tensor(16313.6973, grad_fn=<SumBackward0>)   , return=  175373.71760378085\n",
      "probs of actions:  tensor([0.5183, 0.5287, 0.1544, 0.5374, 0.1268, 0.1538, 0.5473, 0.1244, 0.1237,\n",
      "        0.1544, 0.0600, 0.5528, 0.1558, 0.5517, 0.5510, 0.5501, 0.5486, 0.5468,\n",
      "        0.5450, 0.5430, 0.5410, 0.1604, 0.0626, 0.5340, 0.5316],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "166000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 41, 41, 40, 26, 26, 40, 26, 40, 41, 26, 47, 40, 40, 27, 45, 26, 40,\n",
      "        31, 41, 40, 42, 40, 47, 41])\n",
      "loss=  tensor(1839.5549, grad_fn=<AddBackward0>)   , actor=  tensor(222.4634, grad_fn=<DivBackward0>)   , critic=  tensor(16170.9141, grad_fn=<SumBackward0>)   , return=  174784.08718165575\n",
      "probs of actions:  tensor([0.4810, 0.1817, 0.1815, 0.4990, 0.1387, 0.1381, 0.5075, 0.1387, 0.5108,\n",
      "        0.1769, 0.1395, 0.0259, 0.5125, 0.5121, 0.0571, 0.0020, 0.1425, 0.5076,\n",
      "        0.0111, 0.1722, 0.5019, 0.0295, 0.4987, 0.0285, 0.1702],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "167000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([41, 40, 27, 27, 40, 41, 40, 40, 26, 26, 40, 41, 40, 40, 26, 40, 41, 40,\n",
      "        41, 41, 26, 40, 40, 41, 27])\n",
      "loss=  tensor(1819.2957, grad_fn=<AddBackward0>)   , actor=  tensor(175.1033, grad_fn=<DivBackward0>)   , critic=  tensor(16441.9238, grad_fn=<SumBackward0>)   , return=  176233.82998489548\n",
      "probs of actions:  tensor([0.1727, 0.5466, 0.0559, 0.0554, 0.5586, 0.1666, 0.5643, 0.5661, 0.1011,\n",
      "        0.1011, 0.5682, 0.1624, 0.5680, 0.5672, 0.1033, 0.5646, 0.1603, 0.5611,\n",
      "        0.1599, 0.1596, 0.1068, 0.5529, 0.5499, 0.1588, 0.0571],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "168000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 40, 40, 40, 40, 40, 40, 27, 40, 40, 41, 15, 40, 41, 40, 26, 42, 40,\n",
      "        41, 41, 41, 40, 40, 41, 33])\n",
      "loss=  tensor(1822.7017, grad_fn=<AddBackward0>)   , actor=  tensor(176.1692, grad_fn=<DivBackward0>)   , critic=  tensor(16465.3242, grad_fn=<SumBackward0>)   , return=  176311.08940041385\n",
      "probs of actions:  tensor([6.2581e-01, 6.3640e-01, 6.4128e-01, 6.4532e-01, 6.4882e-01, 6.5173e-01,\n",
      "        6.5407e-01, 3.5064e-02, 6.5684e-01, 6.5810e-01, 1.5045e-01, 2.9266e-04,\n",
      "        6.5635e-01, 1.4901e-01, 6.5517e-01, 8.4492e-02, 2.0835e-02, 6.4954e-01,\n",
      "        1.4843e-01, 1.4839e-01, 1.4838e-01, 6.4160e-01, 6.3940e-01, 1.4846e-01,\n",
      "        1.8527e-02], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "169000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 41, 41, 40, 40, 41, 40, 41, 27, 40, 40, 40, 40, 40, 26, 41, 40, 40,\n",
      "        40, 40, 40, 40, 40, 40, 40])\n",
      "loss=  tensor(1783.5663, grad_fn=<AddBackward0>)   , actor=  tensor(122.0094, grad_fn=<DivBackward0>)   , critic=  tensor(16615.5684, grad_fn=<SumBackward0>)   , return=  176755.54804074854\n",
      "probs of actions:  tensor([0.6984, 0.1599, 0.1585, 0.7174, 0.7209, 0.1546, 0.7264, 0.1522, 0.0177,\n",
      "        0.7305, 0.7314, 0.7314, 0.7311, 0.7305, 0.0582, 0.1483, 0.7268, 0.7254,\n",
      "        0.7237, 0.7220, 0.7202, 0.7183, 0.7164, 0.7145, 0.7126],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "170000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 40, 41, 40, 41, 40, 40, 40, 41, 27, 40, 40, 40, 26, 40, 40, 40, 40,\n",
      "        40, 40, 40, 40, 40, 41, 40])\n",
      "loss=  tensor(1768.3745, grad_fn=<AddBackward0>)   , actor=  tensor(108.4962, grad_fn=<DivBackward0>)   , critic=  tensor(16598.7832, grad_fn=<SumBackward0>)   , return=  176699.68420092599\n",
      "probs of actions:  tensor([0.7659, 0.7759, 0.1195, 0.7844, 0.1166, 0.7907, 0.7931, 0.7950, 0.1123,\n",
      "        0.0138, 0.7973, 0.7976, 0.7972, 0.0413, 0.7954, 0.7944, 0.7933, 0.7917,\n",
      "        0.7901, 0.7883, 0.7866, 0.7847, 0.7829, 0.1122, 0.7791],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "171000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([26, 40, 40, 40, 40, 40, 40, 40, 40, 40, 26, 41, 40, 26, 40, 40, 40, 40,\n",
      "        40, 33, 47, 40, 40, 40, 40])\n",
      "loss=  tensor(1765.5317, grad_fn=<AddBackward0>)   , actor=  tensor(116.9100, grad_fn=<DivBackward0>)   , critic=  tensor(16486.2168, grad_fn=<SumBackward0>)   , return=  176274.72712499282\n",
      "probs of actions:  tensor([0.0473, 0.7811, 0.7858, 0.7893, 0.7924, 0.7949, 0.7969, 0.7986, 0.7997,\n",
      "        0.8003, 0.0433, 0.1112, 0.7996, 0.0443, 0.7976, 0.7962, 0.7948, 0.7931,\n",
      "        0.7914, 0.0065, 0.0159, 0.7853, 0.7841, 0.7820, 0.7800],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "172000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40,\n",
      "        40, 40, 40, 40, 40, 40, 40])\n",
      "loss=  tensor(1698.4899, grad_fn=<AddBackward0>)   , actor=  tensor(21.3196, grad_fn=<DivBackward0>)   , critic=  tensor(16771.7031, grad_fn=<SumBackward0>)   , return=  177431.33359946805\n",
      "probs of actions:  tensor([0.8217, 0.8296, 0.8336, 0.8370, 0.8398, 0.8420, 0.8438, 0.8452, 0.8461,\n",
      "        0.8466, 0.8466, 0.8463, 0.8458, 0.8449, 0.8439, 0.8427, 0.8413, 0.8396,\n",
      "        0.8378, 0.8361, 0.8343, 0.8324, 0.8306, 0.8288, 0.8269],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "173000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 41, 40, 40, 40, 40, 40, 40, 40,\n",
      "        40, 40, 26, 40, 40, 40, 40])\n",
      "loss=  tensor(1713.3519, grad_fn=<AddBackward0>)   , actor=  tensor(40.2122, grad_fn=<DivBackward0>)   , critic=  tensor(16731.3965, grad_fn=<SumBackward0>)   , return=  177138.79585040457\n",
      "probs of actions:  tensor([0.9240, 0.9283, 0.9310, 0.9332, 0.9349, 0.9363, 0.9375, 0.9384, 0.9389,\n",
      "        0.9392, 0.0318, 0.9391, 0.9388, 0.9383, 0.9377, 0.9370, 0.9362, 0.9352,\n",
      "        0.9342, 0.9331, 0.0173, 0.9310, 0.9293, 0.9284, 0.9274],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "174000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 45, 40, 40, 40,\n",
      "        40, 40, 40, 40, 40, 40, 40])\n",
      "loss=  tensor(1731.3750, grad_fn=<AddBackward0>)   , actor=  tensor(53.0585, grad_fn=<DivBackward0>)   , critic=  tensor(16783.1641, grad_fn=<SumBackward0>)   , return=  177482.95067308572\n",
      "probs of actions:  tensor([9.3725e-01, 9.4093e-01, 9.4331e-01, 9.4524e-01, 9.4680e-01, 9.4810e-01,\n",
      "        9.4915e-01, 9.4990e-01, 9.5038e-01, 9.5063e-01, 9.5067e-01, 9.5054e-01,\n",
      "        9.5027e-01, 9.4986e-01, 1.0446e-04, 9.4870e-01, 9.4810e-01, 9.4722e-01,\n",
      "        9.4631e-01, 9.4537e-01, 9.4440e-01, 9.4344e-01, 9.4248e-01, 9.4151e-01,\n",
      "        9.4053e-01], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "175000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40,\n",
      "        40, 40, 40, 40, 40, 40, 40])\n",
      "loss=  tensor(1681.2494, grad_fn=<AddBackward0>)   , actor=  tensor(4.0791, grad_fn=<DivBackward0>)   , critic=  tensor(16771.7031, grad_fn=<SumBackward0>)   , return=  177431.33359946805\n",
      "probs of actions:  tensor([0.9597, 0.9623, 0.9641, 0.9656, 0.9668, 0.9678, 0.9686, 0.9692, 0.9695,\n",
      "        0.9698, 0.9698, 0.9698, 0.9696, 0.9693, 0.9690, 0.9686, 0.9681, 0.9676,\n",
      "        0.9670, 0.9664, 0.9657, 0.9650, 0.9644, 0.9637, 0.9630],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "176000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40,\n",
      "        40, 40, 40, 40, 40, 40, 40])\n",
      "loss=  tensor(1679.7400, grad_fn=<AddBackward0>)   , actor=  tensor(2.5697, grad_fn=<DivBackward0>)   , critic=  tensor(16771.7031, grad_fn=<SumBackward0>)   , return=  177431.33359946805\n",
      "probs of actions:  tensor([0.9739, 0.9758, 0.9771, 0.9781, 0.9789, 0.9797, 0.9802, 0.9806, 0.9808,\n",
      "        0.9810, 0.9810, 0.9810, 0.9809, 0.9807, 0.9805, 0.9802, 0.9799, 0.9795,\n",
      "        0.9791, 0.9786, 0.9782, 0.9777, 0.9773, 0.9768, 0.9763],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "177000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 40, 40, 40, 40, 41, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40,\n",
      "        40, 40, 40, 40, 40, 40, 40])\n",
      "loss=  tensor(1709.6743, grad_fn=<AddBackward0>)   , actor=  tensor(32.0133, grad_fn=<DivBackward0>)   , critic=  tensor(16776.6094, grad_fn=<SumBackward0>)   , return=  177445.17195993662\n",
      "probs of actions:  tensor([0.9786, 0.9801, 0.9812, 0.9821, 0.9828, 0.0099, 0.9838, 0.9841, 0.9843,\n",
      "        0.9844, 0.9844, 0.9844, 0.9842, 0.9841, 0.9839, 0.9836, 0.9833, 0.9830,\n",
      "        0.9826, 0.9822, 0.9818, 0.9814, 0.9810, 0.9806, 0.9801],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "178000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40,\n",
      "        40, 40, 40, 40, 40, 40, 40])\n",
      "loss=  tensor(1681.4163, grad_fn=<AddBackward0>)   , actor=  tensor(4.2460, grad_fn=<DivBackward0>)   , critic=  tensor(16771.7031, grad_fn=<SumBackward0>)   , return=  177431.33359946805\n",
      "probs of actions:  tensor([0.9594, 0.9619, 0.9636, 0.9649, 0.9660, 0.9668, 0.9675, 0.9680, 0.9683,\n",
      "        0.9684, 0.9684, 0.9683, 0.9680, 0.9677, 0.9673, 0.9668, 0.9662, 0.9656,\n",
      "        0.9649, 0.9642, 0.9635, 0.9627, 0.9620, 0.9613, 0.9605],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "179000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40,\n",
      "        40, 40, 40, 40, 40, 40, 40])\n",
      "loss=  tensor(1681.0416, grad_fn=<AddBackward0>)   , actor=  tensor(3.8714, grad_fn=<DivBackward0>)   , critic=  tensor(16771.7031, grad_fn=<SumBackward0>)   , return=  177431.33359946805\n",
      "probs of actions:  tensor([0.9631, 0.9654, 0.9669, 0.9681, 0.9691, 0.9699, 0.9705, 0.9709, 0.9711,\n",
      "        0.9712, 0.9712, 0.9710, 0.9708, 0.9704, 0.9700, 0.9696, 0.9690, 0.9684,\n",
      "        0.9677, 0.9671, 0.9664, 0.9657, 0.9649, 0.9642, 0.9635],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "180000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 40, 40, 40, 40, 40, 40, 27, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40,\n",
      "        40, 40, 40, 40, 40, 40, 40])\n",
      "loss=  tensor(1707.4657, grad_fn=<AddBackward0>)   , actor=  tensor(39.2841, grad_fn=<DivBackward0>)   , critic=  tensor(16681.8164, grad_fn=<SumBackward0>)   , return=  177082.22192801943\n",
      "probs of actions:  tensor([0.9767, 0.9782, 0.9793, 0.9802, 0.9809, 0.9815, 0.9819, 0.0028, 0.9823,\n",
      "        0.9823, 0.9823, 0.9822, 0.9820, 0.9818, 0.9815, 0.9812, 0.9808, 0.9803,\n",
      "        0.9799, 0.9794, 0.9789, 0.9784, 0.9778, 0.9773, 0.9768],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "181000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40,\n",
      "        40, 40, 40, 40, 40, 40, 40])\n",
      "loss=  tensor(1678.3868, grad_fn=<AddBackward0>)   , actor=  tensor(1.2166, grad_fn=<DivBackward0>)   , critic=  tensor(16771.7031, grad_fn=<SumBackward0>)   , return=  177431.33359946805\n",
      "probs of actions:  tensor([0.9877, 0.9885, 0.9892, 0.9898, 0.9902, 0.9905, 0.9908, 0.9910, 0.9911,\n",
      "        0.9911, 0.9911, 0.9910, 0.9909, 0.9908, 0.9906, 0.9904, 0.9902, 0.9900,\n",
      "        0.9897, 0.9894, 0.9891, 0.9888, 0.9885, 0.9882, 0.9879],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "182000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40,\n",
      "        40, 40, 40, 40, 40, 40, 40])\n",
      "loss=  tensor(1678.2117, grad_fn=<AddBackward0>)   , actor=  tensor(1.0413, grad_fn=<DivBackward0>)   , critic=  tensor(16771.7031, grad_fn=<SumBackward0>)   , return=  177431.33359946805\n",
      "probs of actions:  tensor([0.9893, 0.9901, 0.9907, 0.9912, 0.9916, 0.9919, 0.9921, 0.9923, 0.9923,\n",
      "        0.9924, 0.9924, 0.9923, 0.9922, 0.9921, 0.9920, 0.9918, 0.9917, 0.9914,\n",
      "        0.9912, 0.9910, 0.9907, 0.9905, 0.9902, 0.9899, 0.9897],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "183000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40,\n",
      "        40, 40, 40, 40, 40, 40, 40])\n",
      "loss=  tensor(1678.3103, grad_fn=<AddBackward0>)   , actor=  tensor(1.1400, grad_fn=<DivBackward0>)   , critic=  tensor(16771.7031, grad_fn=<SumBackward0>)   , return=  177431.33359946805\n",
      "probs of actions:  tensor([0.9884, 0.9893, 0.9899, 0.9904, 0.9908, 0.9911, 0.9914, 0.9915, 0.9916,\n",
      "        0.9916, 0.9916, 0.9916, 0.9915, 0.9914, 0.9912, 0.9910, 0.9908, 0.9906,\n",
      "        0.9904, 0.9901, 0.9898, 0.9895, 0.9893, 0.9890, 0.9887],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "184000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40,\n",
      "        40, 40, 40, 40, 40, 40, 40])\n",
      "loss=  tensor(1678.6622, grad_fn=<AddBackward0>)   , actor=  tensor(1.4920, grad_fn=<DivBackward0>)   , critic=  tensor(16771.7031, grad_fn=<SumBackward0>)   , return=  177431.33359946805\n",
      "probs of actions:  tensor([0.9851, 0.9861, 0.9869, 0.9875, 0.9880, 0.9884, 0.9887, 0.9888, 0.9890,\n",
      "        0.9890, 0.9890, 0.9889, 0.9888, 0.9886, 0.9885, 0.9882, 0.9880, 0.9877,\n",
      "        0.9874, 0.9871, 0.9868, 0.9864, 0.9861, 0.9857, 0.9854],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "185000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40,\n",
      "        40, 40, 40, 40, 40, 40, 40])\n",
      "loss=  tensor(1678.8478, grad_fn=<AddBackward0>)   , actor=  tensor(1.6774, grad_fn=<DivBackward0>)   , critic=  tensor(16771.7031, grad_fn=<SumBackward0>)   , return=  177431.33359946805\n",
      "probs of actions:  tensor([0.9831, 0.9843, 0.9852, 0.9859, 0.9864, 0.9869, 0.9872, 0.9875, 0.9876,\n",
      "        0.9876, 0.9876, 0.9876, 0.9874, 0.9873, 0.9871, 0.9868, 0.9866, 0.9863,\n",
      "        0.9860, 0.9856, 0.9852, 0.9849, 0.9845, 0.9841, 0.9837],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "186000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40,\n",
      "        40, 40, 40, 40, 40, 40, 40])\n",
      "loss=  tensor(1678.1857, grad_fn=<AddBackward0>)   , actor=  tensor(1.0153, grad_fn=<DivBackward0>)   , critic=  tensor(16771.7031, grad_fn=<SumBackward0>)   , return=  177431.33359946805\n",
      "probs of actions:  tensor([0.9898, 0.9905, 0.9911, 0.9915, 0.9919, 0.9921, 0.9923, 0.9925, 0.9925,\n",
      "        0.9926, 0.9925, 0.9925, 0.9924, 0.9923, 0.9921, 0.9919, 0.9918, 0.9916,\n",
      "        0.9913, 0.9911, 0.9908, 0.9906, 0.9903, 0.9900, 0.9897],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "187000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40,\n",
      "        40, 40, 40, 40, 40, 40, 40])\n",
      "loss=  tensor(1677.7488, grad_fn=<AddBackward0>)   , actor=  tensor(0.5785, grad_fn=<DivBackward0>)   , critic=  tensor(16771.7031, grad_fn=<SumBackward0>)   , return=  177431.33359946805\n",
      "probs of actions:  tensor([0.9941, 0.9945, 0.9949, 0.9951, 0.9954, 0.9955, 0.9957, 0.9957, 0.9958,\n",
      "        0.9958, 0.9958, 0.9957, 0.9957, 0.9956, 0.9955, 0.9954, 0.9953, 0.9952,\n",
      "        0.9950, 0.9949, 0.9947, 0.9946, 0.9944, 0.9942, 0.9941],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "188000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40,\n",
      "        40, 40, 40, 40, 40, 40, 40])\n",
      "loss=  tensor(1677.8217, grad_fn=<AddBackward0>)   , actor=  tensor(0.6514, grad_fn=<DivBackward0>)   , critic=  tensor(16771.7031, grad_fn=<SumBackward0>)   , return=  177431.33359946805\n",
      "probs of actions:  tensor([0.9934, 0.9938, 0.9942, 0.9945, 0.9948, 0.9950, 0.9951, 0.9952, 0.9952,\n",
      "        0.9953, 0.9952, 0.9952, 0.9951, 0.9951, 0.9950, 0.9948, 0.9947, 0.9946,\n",
      "        0.9944, 0.9943, 0.9941, 0.9939, 0.9937, 0.9936, 0.9934],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "189000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40,\n",
      "        40, 40, 40, 40, 40, 40, 40])\n",
      "loss=  tensor(1677.4650, grad_fn=<AddBackward0>)   , actor=  tensor(0.2947, grad_fn=<DivBackward0>)   , critic=  tensor(16771.7031, grad_fn=<SumBackward0>)   , return=  177431.33359946805\n",
      "probs of actions:  tensor([0.9969, 0.9971, 0.9973, 0.9975, 0.9976, 0.9977, 0.9978, 0.9978, 0.9979,\n",
      "        0.9979, 0.9979, 0.9979, 0.9978, 0.9978, 0.9977, 0.9977, 0.9976, 0.9976,\n",
      "        0.9975, 0.9974, 0.9973, 0.9972, 0.9971, 0.9970, 0.9970],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "190000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40,\n",
      "        40, 40, 40, 40, 40, 40, 40])\n",
      "loss=  tensor(1678.6260, grad_fn=<AddBackward0>)   , actor=  tensor(1.4556, grad_fn=<DivBackward0>)   , critic=  tensor(16771.7031, grad_fn=<SumBackward0>)   , return=  177431.33359946805\n",
      "probs of actions:  tensor([0.9858, 0.9866, 0.9874, 0.9879, 0.9883, 0.9887, 0.9889, 0.9891, 0.9892,\n",
      "        0.9892, 0.9892, 0.9891, 0.9890, 0.9888, 0.9886, 0.9884, 0.9882, 0.9879,\n",
      "        0.9876, 0.9873, 0.9870, 0.9867, 0.9863, 0.9860, 0.9857],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "191000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40,\n",
      "        40, 40, 40, 40, 40, 40, 40])\n",
      "loss=  tensor(1679.5273, grad_fn=<AddBackward0>)   , actor=  tensor(2.3570, grad_fn=<DivBackward0>)   , critic=  tensor(16771.7031, grad_fn=<SumBackward0>)   , return=  177431.33359946805\n",
      "probs of actions:  tensor([0.9774, 0.9786, 0.9796, 0.9804, 0.9810, 0.9815, 0.9819, 0.9821, 0.9823,\n",
      "        0.9823, 0.9823, 0.9822, 0.9821, 0.9819, 0.9817, 0.9814, 0.9811, 0.9808,\n",
      "        0.9804, 0.9800, 0.9796, 0.9791, 0.9787, 0.9783, 0.9779],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "192000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40,\n",
      "        40, 40, 40, 40, 40, 40, 40])\n",
      "loss=  tensor(1678.3643, grad_fn=<AddBackward0>)   , actor=  tensor(1.1939, grad_fn=<DivBackward0>)   , critic=  tensor(16771.7031, grad_fn=<SumBackward0>)   , return=  177431.33359946805\n",
      "probs of actions:  tensor([0.9882, 0.9889, 0.9895, 0.9899, 0.9903, 0.9906, 0.9908, 0.9910, 0.9911,\n",
      "        0.9911, 0.9911, 0.9911, 0.9910, 0.9909, 0.9907, 0.9906, 0.9904, 0.9902,\n",
      "        0.9900, 0.9898, 0.9895, 0.9893, 0.9890, 0.9888, 0.9885],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "193000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40,\n",
      "        40, 40, 40, 40, 40, 40, 40])\n",
      "loss=  tensor(1677.5890, grad_fn=<AddBackward0>)   , actor=  tensor(0.4187, grad_fn=<DivBackward0>)   , critic=  tensor(16771.7031, grad_fn=<SumBackward0>)   , return=  177431.33359946805\n",
      "probs of actions:  tensor([0.9956, 0.9959, 0.9962, 0.9964, 0.9966, 0.9967, 0.9968, 0.9969, 0.9969,\n",
      "        0.9970, 0.9970, 0.9969, 0.9969, 0.9969, 0.9968, 0.9967, 0.9967, 0.9966,\n",
      "        0.9965, 0.9964, 0.9963, 0.9962, 0.9961, 0.9960, 0.9958],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "194000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40,\n",
      "        40, 40, 40, 40, 40, 40, 40])\n",
      "loss=  tensor(1677.4910, grad_fn=<AddBackward0>)   , actor=  tensor(0.3207, grad_fn=<DivBackward0>)   , critic=  tensor(16771.7031, grad_fn=<SumBackward0>)   , return=  177431.33359946805\n",
      "probs of actions:  tensor([0.9966, 0.9968, 0.9971, 0.9972, 0.9974, 0.9975, 0.9976, 0.9976, 0.9977,\n",
      "        0.9977, 0.9977, 0.9977, 0.9976, 0.9976, 0.9976, 0.9975, 0.9974, 0.9974,\n",
      "        0.9973, 0.9972, 0.9971, 0.9971, 0.9970, 0.9969, 0.9968],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "195000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40,\n",
      "        40, 40, 40, 40, 40, 40, 40])\n",
      "loss=  tensor(1677.6536, grad_fn=<AddBackward0>)   , actor=  tensor(0.4833, grad_fn=<DivBackward0>)   , critic=  tensor(16771.7031, grad_fn=<SumBackward0>)   , return=  177431.33359946805\n",
      "probs of actions:  tensor([0.9949, 0.9953, 0.9956, 0.9958, 0.9960, 0.9962, 0.9963, 0.9964, 0.9964,\n",
      "        0.9965, 0.9965, 0.9965, 0.9964, 0.9964, 0.9963, 0.9962, 0.9962, 0.9961,\n",
      "        0.9960, 0.9959, 0.9958, 0.9956, 0.9955, 0.9954, 0.9953],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "196000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 26, 40, 40, 40, 40, 40,\n",
      "        40, 40, 40, 40, 40, 40, 40])\n",
      "loss=  tensor(1708.3685, grad_fn=<AddBackward0>)   , actor=  tensor(40.6316, grad_fn=<DivBackward0>)   , critic=  tensor(16677.3691, grad_fn=<SumBackward0>)   , return=  177042.01841294605\n",
      "probs of actions:  tensor([9.9534e-01, 9.9567e-01, 9.9597e-01, 9.9621e-01, 9.9640e-01, 9.9655e-01,\n",
      "        9.9666e-01, 9.9673e-01, 9.9678e-01, 9.9680e-01, 9.9681e-01, 9.9679e-01,\n",
      "        6.8827e-04, 9.9673e-01, 9.9664e-01, 9.9658e-01, 9.9651e-01, 9.9643e-01,\n",
      "        9.9635e-01, 9.9625e-01, 9.9614e-01, 9.9603e-01, 9.9592e-01, 9.9581e-01,\n",
      "        9.9569e-01], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "197000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40,\n",
      "        40, 40, 40, 40, 40, 40, 40])\n",
      "loss=  tensor(1677.5894, grad_fn=<AddBackward0>)   , actor=  tensor(0.4191, grad_fn=<DivBackward0>)   , critic=  tensor(16771.7031, grad_fn=<SumBackward0>)   , return=  177431.33359946805\n",
      "probs of actions:  tensor([0.9955, 0.9958, 0.9961, 0.9964, 0.9965, 0.9967, 0.9968, 0.9969, 0.9969,\n",
      "        0.9969, 0.9970, 0.9969, 0.9969, 0.9969, 0.9968, 0.9968, 0.9967, 0.9966,\n",
      "        0.9966, 0.9965, 0.9964, 0.9963, 0.9962, 0.9961, 0.9960],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "198000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40,\n",
      "        40, 40, 40, 40, 40, 40, 40])\n",
      "loss=  tensor(1677.3210, grad_fn=<AddBackward0>)   , actor=  tensor(0.1508, grad_fn=<DivBackward0>)   , critic=  tensor(16771.7031, grad_fn=<SumBackward0>)   , return=  177431.33359946805\n",
      "probs of actions:  tensor([0.9983, 0.9985, 0.9986, 0.9987, 0.9988, 0.9988, 0.9989, 0.9989, 0.9989,\n",
      "        0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9989, 0.9988, 0.9988, 0.9988,\n",
      "        0.9988, 0.9987, 0.9987, 0.9986, 0.9986, 0.9985, 0.9985],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "199000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40,\n",
      "        40, 40, 40, 40, 40, 40, 40])\n",
      "loss=  tensor(1677.3020, grad_fn=<AddBackward0>)   , actor=  tensor(0.1317, grad_fn=<DivBackward0>)   , critic=  tensor(16771.7031, grad_fn=<SumBackward0>)   , return=  177431.33359946805\n",
      "probs of actions:  tensor([0.9985, 0.9986, 0.9988, 0.9988, 0.9989, 0.9990, 0.9990, 0.9990, 0.9991,\n",
      "        0.9991, 0.9991, 0.9991, 0.9991, 0.9990, 0.9990, 0.9990, 0.9990, 0.9989,\n",
      "        0.9989, 0.9989, 0.9988, 0.9988, 0.9988, 0.9987, 0.9987],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "199675   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40,\n",
      "        40, 40, 40, 40, 40, 40, 40])\n",
      "loss=  tensor(1677.2588, grad_fn=<AddBackward0>)   , actor=  tensor(0.0885, grad_fn=<DivBackward0>)   , critic=  tensor(16771.7031, grad_fn=<SumBackward0>)   , return=  177431.33359946805\n",
      "probs of actions:  tensor([0.9990, 0.9991, 0.9992, 0.9992, 0.9993, 0.9993, 0.9993, 0.9994, 0.9994,\n",
      "        0.9994, 0.9994, 0.9994, 0.9994, 0.9994, 0.9993, 0.9993, 0.9993, 0.9993,\n",
      "        0.9993, 0.9992, 0.9992, 0.9992, 0.9992, 0.9991, 0.9991],\n",
      "       grad_fn=<ExpBackward0>)\n",
      "shouldBreak: True\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "algorithm.solver(print_step=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "advModeNames=\"\"\n",
    "for i in range(len(adversaryProbs)):\n",
    "    if adversaryProbs[i]!=0:\n",
    "        tmp=\"{:.1f}\".format(adversaryProbs[i])\n",
    "        advModeNames+=f\"{(AdversaryModes(i)).name}-{tmp}-\"\n",
    "    \n",
    "name=f\"ep {algorithm.numberEpisodes}, {advModeNames}, {game.advHistoryNum} hist, {neuralNet.lr} lr\"\n",
    "neuralNet.save(name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hi'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# neuralNet.load(name=name)\n",
    "\"hi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algorithm.bestAverageRetu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'mean'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m prices \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(game\u001b[38;5;241m.\u001b[39mprices)\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m      4\u001b[0m demandPotential \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(game\u001b[38;5;241m.\u001b[39mdemandPotential)\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m----> 5\u001b[0m learning \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43malgorithm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m(axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m),columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentry\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'mean'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "profits = pd.DataFrame(game.profit).T\n",
    "prices = pd.DataFrame(game.prices).T\n",
    "demandPotential = pd.DataFrame(game.demandPotential).T\n",
    "learning = pd.DataFrame(algorithm.returns.mean(axis = 0),columns=['entry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demandPotential.plot()\n",
    "demandPotential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profits.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profits.plot()\n",
    "profits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "prices.plot()\n",
    "prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pricelearning = pd.DataFrame(game.prices.mean(axis = 0))\n",
    "# pricelearning.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning = learning.to_numpy()\n",
    "learning_2 = [0]*len(learning)\n",
    "for i in range(len(learning)):\n",
    "    learning_2[i] = learning[i][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_learning = np.convolve(learning_2, np.ones(1000)/1000, mode = 'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(avg_learning)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
