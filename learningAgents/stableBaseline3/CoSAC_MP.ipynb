{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd17f737",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import SAC\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, SubprocVecEnv\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import globals as gl\n",
    "import classes as cl\n",
    "import time\n",
    "import os\n",
    "# from gymnasium_env import ContinousPricingGame\n",
    "from Environment import ConPricingGame\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e8dfa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gl.initialize()\n",
    "\n",
    "num_procs=6\n",
    "model = SAC\n",
    "model_name=\"CoSAC_MP\"\n",
    "timesteps= 1_000_000\n",
    "num_timesteps=10\n",
    "state_onehot=False\n",
    "costs=[gl.LOW_COST, gl.HIGH_COST]\n",
    "adv_mixed_strategy = cl.MixedStrategy(strategiesList=[cl.Strategy(\n",
    "        cl.StrategyType.static, NNorFunc=cl.myopic, name=\"myopic\")], probablitiesArray=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10a4ef16",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs=[0.00005,0.00008, 0.0003]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf1946fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_env(rank, seed=0):\n",
    "#     \"\"\"\n",
    "#     Utility function for multiprocessed env.\n",
    "#     :param seed: (int) the inital seed for RNG\n",
    "#     :param rank: (int) index of the subprocess\n",
    "#     \"\"\"\n",
    "\n",
    "#     def _init():\n",
    "#         env = ContinousPricingGame(tuple_costs=costs, adversary_mixed_strategy=adv_mixed_strategy, state_onehot=state_onehot)\n",
    "#         env.reset(seed=seed + rank)\n",
    "#         # use a seed for reproducibility\n",
    "#         # Important: use a different seed for each environment\n",
    "#         # otherwise they would generate the same experiences\n",
    "#         return env\n",
    "\n",
    "#     set_random_seed(seed)\n",
    "#     return _init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3a5dd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(lr=None):    \n",
    "    seed=int(time.time())\n",
    "\n",
    "    iter_name = f\"{model_name}-{str(seed)}\"\n",
    "    models_dir = os.path.join(\"models\", iter_name)\n",
    "    log_dir = os.path.join(\"logs\", iter_name)\n",
    "             \n",
    "    if not os.path.exists(models_dir):\n",
    "        os.makedirs(models_dir)\n",
    "\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "             \n",
    "    train_env = make_vec_env(ConPricingGame, n_envs=num_procs, seed=seed, vec_env_cls=SubprocVecEnv,env_kwargs=\\\n",
    "                           dict(tuple_costs = costs,adversary_mixed_strategy = adv_mixed_strategy))\n",
    "#     train_env = make_vec_env(ContinousPricingGame, n_envs=num_procs, seed=0, vec_env_cls=SubprocVecEnv,\\\n",
    "#                              env_kwargs=dict(tuple_cost=costs))\n",
    "\n",
    "    lr_=(gl.LR if (lr is None) else lr)\n",
    "#     train_env = ContinousPricingGame()\n",
    "#     train_env.reset()\n",
    "    \n",
    "#     train_env.reset()\n",
    "    model_ = model('MlpPolicy', train_env,learning_rate=lr_,verbose=0, tensorboard_log=log_dir, gamma=gl.GAMMA)\n",
    "    \n",
    "    start=time.time()\n",
    "    for i in range(num_timesteps):\n",
    "        model_.learn(total_timesteps=timesteps,\n",
    "                     reset_num_timesteps=False,tb_log_name=iter_name)\n",
    "    model_.save(os.path.join(models_dir, str(timesteps*i)))\n",
    "    running_time=time.time()- start\n",
    "\n",
    "    # test and write results\n",
    "    env = ConPricingGame(tuple_costs=costs, adversary_mixed_strategy=adv_mixed_strategy)\n",
    "    for iter in range(gl.NUM_STOCHASTIC_ITER):\n",
    "             \n",
    "        obs,_ = env.reset()\n",
    "        done = False\n",
    "\n",
    "        actions = []\n",
    "        while not done:\n",
    "            action, _states = model_.predict(obs)\n",
    "            obs, reward, done,trunc, info = env.step(action)\n",
    "\n",
    "            actions.append(int(action))\n",
    "        # name\tep\tcosts\tadversary\tagent_returnC:\\Users\\sjaha\\Desktop\\RL\\Gym\\stableBaseline3\\environment.py\tadv_return\tagent_rewards\tactions\tagent_prices\t\\\n",
    "        # adv_prices\tagent_demands\tadv_demands\tlr\thist\ttotal_stages\taction_step\tnum_actions\tgamma\t\\\n",
    "        # stae_onehot\tseed\tnum_procs\trunning_time\n",
    "        data=[iter_name, timesteps*num_timesteps,(\"L\" if (costs[0]<costs[1]) else \"H\"), env.adversary_strategy.name,\\\n",
    "              sum(env.profit[0]), sum(env.profit[1]),  str(env.profit[0]), str(actions), str(env.prices[0]),\\\n",
    "              str(env.prices[1]), str(env.demand_potential[0]),str(env.demand_potential[1]), lr_, gl.NUM_ADV_HISTORY,\\\n",
    "              gl.TOTAL_STAGES, gl.ACTION_STEP, gl.NUM_ACTIONS, gl.GAMMA, False, seed, num_procs, running_time]\n",
    "        cl.write_to_excel(data)\n",
    "    print(lr, \"=lr completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f024f5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5e-05 =lr completed\n",
      "5e-05 =lr completed\n",
      "8e-05 =lr completed\n",
      "8e-05 =lr completed\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    for lr in lrs:\n",
    "\n",
    "        for _ in range(2):\n",
    "            run(lr=lr)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035c2e33",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
