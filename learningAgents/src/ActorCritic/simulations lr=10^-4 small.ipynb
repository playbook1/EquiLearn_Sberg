{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from learningActorCritic import ReinforceAlgorithm\n",
    "from environmentModel import Model, AdversaryModes\n",
    "from neuralNetwork import NeuralNetwork\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions import Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adversaryProbs=torch.zeros(len(AdversaryModes))\n",
    "adversaryProbs[0]=1\n",
    "adversaryProbs[1]=0\n",
    "adversaryProbs[8]=0\n",
    "game = Model(totalDemand = 400, \n",
    "               tupleCosts = (57, 71),\n",
    "              totalStages = 3, adversaryProbs=adversaryProbs, advHistoryNum=0)\n",
    "adversaryProbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  0.0000, 200.0000, 128.5000]), 0, False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135.5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game.adversaryChoosePrice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuralNet=NeuralNetwork(num_input=3+game.advHistoryNum, lr=0.0001,num_actions=4)\n",
    "algorithm = ReinforceAlgorithm(game, neuralNet, numberIterations=1, numberEpisodes=1000_000, discountFactor =0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "0   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([2, 0, 2])\n",
      "loss=  tensor(4.9797, grad_fn=<AddBackward0>)   , actor=  tensor(3.9336, grad_fn=<DivBackward0>)   , critic=  tensor(10.4610, grad_fn=<SumBackward0>)   , return=  16074.953125\n",
      "probs of actions:  tensor([0.2934, 0.2473, 0.2804], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "1000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([2, 3, 0])\n",
      "loss=  tensor(5.2275, grad_fn=<AddBackward0>)   , actor=  tensor(4.1640, grad_fn=<DivBackward0>)   , critic=  tensor(10.6347, grad_fn=<SumBackward0>)   , return=  16182.078125\n",
      "probs of actions:  tensor([0.2676, 0.2565, 0.2366], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "2000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([2, 3, 2])\n",
      "loss=  tensor(5.5201, grad_fn=<AddBackward0>)   , actor=  tensor(4.4573, grad_fn=<DivBackward0>)   , critic=  tensor(10.6283, grad_fn=<SumBackward0>)   , return=  16178.078125\n",
      "probs of actions:  tensor([0.2233, 0.2595, 0.2189], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "3000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 0])\n",
      "loss=  tensor(5.4532, grad_fn=<AddBackward0>)   , actor=  tensor(4.3818, grad_fn=<DivBackward0>)   , critic=  tensor(10.7132, grad_fn=<SumBackward0>)   , return=  16232.8125\n",
      "probs of actions:  tensor([0.2424, 0.2464, 0.2302], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "4000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([2, 3, 2])\n",
      "loss=  tensor(5.4042, grad_fn=<AddBackward0>)   , actor=  tensor(4.3414, grad_fn=<DivBackward0>)   , critic=  tensor(10.6283, grad_fn=<SumBackward0>)   , return=  16178.078125\n",
      "probs of actions:  tensor([0.2512, 0.2344, 0.2399], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "5000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 1])\n",
      "loss=  tensor(5.3095, grad_fn=<AddBackward0>)   , actor=  tensor(4.2383, grad_fn=<DivBackward0>)   , critic=  tensor(10.7116, grad_fn=<SumBackward0>)   , return=  16231.8125\n",
      "probs of actions:  tensor([0.2398, 0.2442, 0.3100], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "6000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([0, 1, 1])\n",
      "loss=  tensor(5.1766, grad_fn=<AddBackward0>)   , actor=  tensor(4.1401, grad_fn=<DivBackward0>)   , critic=  tensor(10.3647, grad_fn=<SumBackward0>)   , return=  16007.453125\n",
      "probs of actions:  tensor([0.2112, 0.3035, 0.3006], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "7000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([0, 3, 0])\n",
      "loss=  tensor(5.4203, grad_fn=<AddBackward0>)   , actor=  tensor(4.3728, grad_fn=<DivBackward0>)   , critic=  tensor(10.4742, grad_fn=<SumBackward0>)   , return=  16075.078125\n",
      "probs of actions:  tensor([0.2213, 0.2679, 0.2317], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "8000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([1, 2, 2])\n",
      "loss=  tensor(5.0621, grad_fn=<AddBackward0>)   , actor=  tensor(4.0125, grad_fn=<DivBackward0>)   , critic=  tensor(10.4956, grad_fn=<SumBackward0>)   , return=  16093.0625\n",
      "probs of actions:  tensor([0.2850, 0.2543, 0.2535], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "9000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 1, 3])\n",
      "loss=  tensor(4.8157, grad_fn=<AddBackward0>)   , actor=  tensor(3.7568, grad_fn=<DivBackward0>)   , critic=  tensor(10.5889, grad_fn=<SumBackward0>)   , return=  16156.8125\n",
      "probs of actions:  tensor([0.3071, 0.2715, 0.3004], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "10000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([0, 3, 1])\n",
      "loss=  tensor(5.5414, grad_fn=<AddBackward0>)   , actor=  tensor(4.4942, grad_fn=<DivBackward0>)   , critic=  tensor(10.4726, grad_fn=<SumBackward0>)   , return=  16074.078125\n",
      "probs of actions:  tensor([0.1680, 0.3269, 0.2628], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "11000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([0, 0, 2])\n",
      "loss=  tensor(6.1389, grad_fn=<AddBackward0>)   , actor=  tensor(5.1086, grad_fn=<DivBackward0>)   , critic=  tensor(10.3023, grad_fn=<SumBackward0>)   , return=  15968.328125\n",
      "probs of actions:  tensor([0.1691, 0.1778, 0.2453], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "12000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([2, 1, 0])\n",
      "loss=  tensor(5.5878, grad_fn=<AddBackward0>)   , actor=  tensor(4.5352, grad_fn=<DivBackward0>)   , critic=  tensor(10.5256, grad_fn=<SumBackward0>)   , return=  16115.203125\n",
      "probs of actions:  tensor([0.2453, 0.2423, 0.1618], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "13000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([2, 2, 0])\n",
      "loss=  tensor(5.7609, grad_fn=<AddBackward0>)   , actor=  tensor(4.7028, grad_fn=<DivBackward0>)   , critic=  tensor(10.5814, grad_fn=<SumBackward0>)   , return=  16149.578125\n",
      "probs of actions:  tensor([0.2336, 0.2302, 0.1540], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "14000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([1, 3, 3])\n",
      "loss=  tensor(4.6650, grad_fn=<AddBackward0>)   , actor=  tensor(3.6109, grad_fn=<DivBackward0>)   , critic=  tensor(10.5406, grad_fn=<SumBackward0>)   , return=  16120.5\n",
      "probs of actions:  tensor([0.2538, 0.3657, 0.3627], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "15000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([2, 2, 3])\n",
      "loss=  tensor(5.2291, grad_fn=<AddBackward0>)   , actor=  tensor(4.1724, grad_fn=<DivBackward0>)   , critic=  tensor(10.5669, grad_fn=<SumBackward0>)   , return=  16140.578125\n",
      "probs of actions:  tensor([0.2375, 0.2340, 0.3665], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "16000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 0])\n",
      "loss=  tensor(4.5219, grad_fn=<AddBackward0>)   , actor=  tensor(3.4506, grad_fn=<DivBackward0>)   , critic=  tensor(10.7132, grad_fn=<SumBackward0>)   , return=  16232.8125\n",
      "probs of actions:  tensor([0.3925, 0.3882, 0.1472], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "17000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 0])\n",
      "loss=  tensor(4.8447, grad_fn=<AddBackward0>)   , actor=  tensor(3.7734, grad_fn=<DivBackward0>)   , critic=  tensor(10.7132, grad_fn=<SumBackward0>)   , return=  16232.8125\n",
      "probs of actions:  tensor([0.3544, 0.3517, 0.1303], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "18000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([1, 2, 0])\n",
      "loss=  tensor(5.4633, grad_fn=<AddBackward0>)   , actor=  tensor(4.4131, grad_fn=<DivBackward0>)   , critic=  tensor(10.5020, grad_fn=<SumBackward0>)   , return=  16097.0625\n",
      "probs of actions:  tensor([0.3058, 0.2382, 0.1168], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "19000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 1, 2])\n",
      "loss=  tensor(4.7379, grad_fn=<AddBackward0>)   , actor=  tensor(3.6782, grad_fn=<DivBackward0>)   , critic=  tensor(10.5970, grad_fn=<SumBackward0>)   , return=  16161.8125\n",
      "probs of actions:  tensor([0.3264, 0.3050, 0.2378], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "20000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([2, 3, 1])\n",
      "loss=  tensor(4.8365, grad_fn=<AddBackward0>)   , actor=  tensor(3.7732, grad_fn=<DivBackward0>)   , critic=  tensor(10.6331, grad_fn=<SumBackward0>)   , return=  16181.078125\n",
      "probs of actions:  tensor([0.2657, 0.3365, 0.2902], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "21000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([0, 3, 1])\n",
      "loss=  tensor(6.3878, grad_fn=<AddBackward0>)   , actor=  tensor(5.3405, grad_fn=<DivBackward0>)   , critic=  tensor(10.4726, grad_fn=<SumBackward0>)   , return=  16074.078125\n",
      "probs of actions:  tensor([0.0762, 0.3955, 0.3141], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "22000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(4.1148, grad_fn=<AddBackward0>)   , actor=  tensor(3.0703, grad_fn=<DivBackward0>)   , critic=  tensor(10.4449, grad_fn=<SumBackward0>)   , return=  16061.75\n",
      "probs of actions:  tensor([0.3705, 0.3609, 0.3552], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "23000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(3.8579, grad_fn=<AddBackward0>)   , actor=  tensor(2.8134, grad_fn=<DivBackward0>)   , critic=  tensor(10.4449, grad_fn=<SumBackward0>)   , return=  16061.75\n",
      "probs of actions:  tensor([0.4046, 0.3919, 0.3844], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "24000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 1, 3])\n",
      "loss=  tensor(4.3906, grad_fn=<AddBackward0>)   , actor=  tensor(3.3317, grad_fn=<DivBackward0>)   , critic=  tensor(10.5889, grad_fn=<SumBackward0>)   , return=  16156.8125\n",
      "probs of actions:  tensor([0.3059, 0.4007, 0.3127], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "25000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([1, 3, 1])\n",
      "loss=  tensor(4.2529, grad_fn=<AddBackward0>)   , actor=  tensor(3.1976, grad_fn=<DivBackward0>)   , critic=  tensor(10.5534, grad_fn=<SumBackward0>)   , return=  16128.5\n",
      "probs of actions:  tensor([0.3603, 0.3420, 0.3480], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "26000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([1, 2, 1])\n",
      "loss=  tensor(4.7713, grad_fn=<AddBackward0>)   , actor=  tensor(3.7212, grad_fn=<DivBackward0>)   , critic=  tensor(10.5004, grad_fn=<SumBackward0>)   , return=  16096.0625\n",
      "probs of actions:  tensor([0.3304, 0.2424, 0.3188], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "27000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 1])\n",
      "loss=  tensor(4.4134, grad_fn=<AddBackward0>)   , actor=  tensor(3.3422, grad_fn=<DivBackward0>)   , critic=  tensor(10.7116, grad_fn=<SumBackward0>)   , return=  16231.8125\n",
      "probs of actions:  tensor([0.3388, 0.3398, 0.3340], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "28000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([2, 3, 3])\n",
      "loss=  tensor(4.9025, grad_fn=<AddBackward0>)   , actor=  tensor(3.8405, grad_fn=<DivBackward0>)   , critic=  tensor(10.6202, grad_fn=<SumBackward0>)   , return=  16173.078125\n",
      "probs of actions:  tensor([0.2427, 0.3316, 0.3329], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "29000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([1, 1, 3])\n",
      "loss=  tensor(4.0224, grad_fn=<AddBackward0>)   , actor=  tensor(2.9792, grad_fn=<DivBackward0>)   , critic=  tensor(10.4321, grad_fn=<SumBackward0>)   , return=  16053.75\n",
      "probs of actions:  tensor([0.4008, 0.3902, 0.2935], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "30000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([2, 1, 3])\n",
      "loss=  tensor(4.6600, grad_fn=<AddBackward0>)   , actor=  tensor(3.6089, grad_fn=<DivBackward0>)   , critic=  tensor(10.5111, grad_fn=<SumBackward0>)   , return=  16106.203125\n",
      "probs of actions:  tensor([0.2664, 0.3544, 0.3356], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "31000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([1, 3, 3])\n",
      "loss=  tensor(4.3270, grad_fn=<AddBackward0>)   , actor=  tensor(3.2730, grad_fn=<DivBackward0>)   , critic=  tensor(10.5406, grad_fn=<SumBackward0>)   , return=  16120.5\n",
      "probs of actions:  tensor([0.3796, 0.3123, 0.3136], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "32000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([1, 1, 3])\n",
      "loss=  tensor(4.0273, grad_fn=<AddBackward0>)   , actor=  tensor(2.9841, grad_fn=<DivBackward0>)   , critic=  tensor(10.4321, grad_fn=<SumBackward0>)   , return=  16053.75\n",
      "probs of actions:  tensor([0.3960, 0.3869, 0.3050], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "33000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(3.7352, grad_fn=<AddBackward0>)   , actor=  tensor(2.6907, grad_fn=<DivBackward0>)   , critic=  tensor(10.4449, grad_fn=<SumBackward0>)   , return=  16061.75\n",
      "probs of actions:  tensor([0.4200, 0.4091, 0.4014], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "34000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(4.5755, grad_fn=<AddBackward0>)   , actor=  tensor(3.5056, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.3188, 0.3216, 0.3231], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "35000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 1, 2])\n",
      "loss=  tensor(4.5353, grad_fn=<AddBackward0>)   , actor=  tensor(3.4756, grad_fn=<DivBackward0>)   , critic=  tensor(10.5970, grad_fn=<SumBackward0>)   , return=  16161.8125\n",
      "probs of actions:  tensor([0.3134, 0.4002, 0.2280], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "36000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 1, 2])\n",
      "loss=  tensor(4.5500, grad_fn=<AddBackward0>)   , actor=  tensor(3.4903, grad_fn=<DivBackward0>)   , critic=  tensor(10.5970, grad_fn=<SumBackward0>)   , return=  16161.8125\n",
      "probs of actions:  tensor([0.3194, 0.3832, 0.2294], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "37000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([1, 1, 0])\n",
      "loss=  tensor(4.8269, grad_fn=<AddBackward0>)   , actor=  tensor(3.7823, grad_fn=<DivBackward0>)   , critic=  tensor(10.4465, grad_fn=<SumBackward0>)   , return=  16062.75\n",
      "probs of actions:  tensor([0.4075, 0.3954, 0.0648], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "38000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([1, 1, 2])\n",
      "loss=  tensor(3.9521, grad_fn=<AddBackward0>)   , actor=  tensor(2.9081, grad_fn=<DivBackward0>)   , critic=  tensor(10.4401, grad_fn=<SumBackward0>)   , return=  16058.75\n",
      "probs of actions:  tensor([0.4313, 0.4173, 0.2436], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "39000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([2, 1, 3])\n",
      "loss=  tensor(4.6413, grad_fn=<AddBackward0>)   , actor=  tensor(3.5902, grad_fn=<DivBackward0>)   , critic=  tensor(10.5111, grad_fn=<SumBackward0>)   , return=  16106.203125\n",
      "probs of actions:  tensor([0.2525, 0.4277, 0.2804], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "40000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 2, 3])\n",
      "loss=  tensor(5.0671, grad_fn=<AddBackward0>)   , actor=  tensor(4.0026, grad_fn=<DivBackward0>)   , critic=  tensor(10.6450, grad_fn=<SumBackward0>)   , return=  16191.25\n",
      "probs of actions:  tensor([0.2640, 0.2813, 0.2744], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "41000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([1, 2, 3])\n",
      "loss=  tensor(4.3581, grad_fn=<AddBackward0>)   , actor=  tensor(3.3093, grad_fn=<DivBackward0>)   , critic=  tensor(10.4876, grad_fn=<SumBackward0>)   , return=  16088.0625\n",
      "probs of actions:  tensor([0.3999, 0.3012, 0.2696], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "42000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([2, 1, 1])\n",
      "loss=  tensor(4.2029, grad_fn=<AddBackward0>)   , actor=  tensor(3.1505, grad_fn=<DivBackward0>)   , critic=  tensor(10.5240, grad_fn=<SumBackward0>)   , return=  16114.203125\n",
      "probs of actions:  tensor([0.3314, 0.3817, 0.3784], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "43000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([2, 1, 1])\n",
      "loss=  tensor(4.0830, grad_fn=<AddBackward0>)   , actor=  tensor(3.0306, grad_fn=<DivBackward0>)   , critic=  tensor(10.5240, grad_fn=<SumBackward0>)   , return=  16114.203125\n",
      "probs of actions:  tensor([0.3387, 0.4038, 0.3989], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "44000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([1, 1, 2])\n",
      "loss=  tensor(4.1149, grad_fn=<AddBackward0>)   , actor=  tensor(3.0708, grad_fn=<DivBackward0>)   , critic=  tensor(10.4401, grad_fn=<SumBackward0>)   , return=  16058.75\n",
      "probs of actions:  tensor([0.3675, 0.3649, 0.3546], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "45000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([1, 3, 1])\n",
      "loss=  tensor(4.4763, grad_fn=<AddBackward0>)   , actor=  tensor(3.4209, grad_fn=<DivBackward0>)   , critic=  tensor(10.5534, grad_fn=<SumBackward0>)   , return=  16128.5\n",
      "probs of actions:  tensor([0.3859, 0.2398, 0.3792], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "46000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 1])\n",
      "loss=  tensor(5.0607, grad_fn=<AddBackward0>)   , actor=  tensor(3.9896, grad_fn=<DivBackward0>)   , critic=  tensor(10.7116, grad_fn=<SumBackward0>)   , return=  16231.8125\n",
      "probs of actions:  tensor([0.2551, 0.2632, 0.3567], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "47000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([1, 2, 3])\n",
      "loss=  tensor(4.3433, grad_fn=<AddBackward0>)   , actor=  tensor(3.2946, grad_fn=<DivBackward0>)   , critic=  tensor(10.4876, grad_fn=<SumBackward0>)   , return=  16088.0625\n",
      "probs of actions:  tensor([0.3698, 0.3460, 0.2618], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "48000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([2, 3, 1])\n",
      "loss=  tensor(4.5006, grad_fn=<AddBackward0>)   , actor=  tensor(3.4373, grad_fn=<DivBackward0>)   , critic=  tensor(10.6331, grad_fn=<SumBackward0>)   , return=  16181.078125\n",
      "probs of actions:  tensor([0.3894, 0.2466, 0.3499], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "49000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(3.9104, grad_fn=<AddBackward0>)   , actor=  tensor(2.8659, grad_fn=<DivBackward0>)   , critic=  tensor(10.4449, grad_fn=<SumBackward0>)   , return=  16061.75\n",
      "probs of actions:  tensor([0.3908, 0.3895, 0.3872], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "50000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([1, 2, 3])\n",
      "loss=  tensor(4.3497, grad_fn=<AddBackward0>)   , actor=  tensor(3.3009, grad_fn=<DivBackward0>)   , critic=  tensor(10.4876, grad_fn=<SumBackward0>)   , return=  16088.0625\n",
      "probs of actions:  tensor([0.3504, 0.3886, 0.2398], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "51000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 2, 2])\n",
      "loss=  tensor(4.8515, grad_fn=<AddBackward0>)   , actor=  tensor(3.7862, grad_fn=<DivBackward0>)   , critic=  tensor(10.6531, grad_fn=<SumBackward0>)   , return=  16196.25\n",
      "probs of actions:  tensor([0.2179, 0.3823, 0.3748], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "52000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(3.6407, grad_fn=<AddBackward0>)   , actor=  tensor(2.5962, grad_fn=<DivBackward0>)   , critic=  tensor(10.4449, grad_fn=<SumBackward0>)   , return=  16061.75\n",
      "probs of actions:  tensor([0.4305, 0.4237, 0.4180], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "53000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([2, 2, 3])\n",
      "loss=  tensor(4.7517, grad_fn=<AddBackward0>)   , actor=  tensor(3.6950, grad_fn=<DivBackward0>)   , critic=  tensor(10.5669, grad_fn=<SumBackward0>)   , return=  16140.578125\n",
      "probs of actions:  tensor([0.3198, 0.3135, 0.2297], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "54000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([1, 3, 3])\n",
      "loss=  tensor(4.6382, grad_fn=<AddBackward0>)   , actor=  tensor(3.5842, grad_fn=<DivBackward0>)   , critic=  tensor(10.5406, grad_fn=<SumBackward0>)   , return=  16120.5\n",
      "probs of actions:  tensor([0.4054, 0.2408, 0.2466], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "55000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([1, 2, 1])\n",
      "loss=  tensor(4.2062, grad_fn=<AddBackward0>)   , actor=  tensor(3.1561, grad_fn=<DivBackward0>)   , critic=  tensor(10.5004, grad_fn=<SumBackward0>)   , return=  16096.0625\n",
      "probs of actions:  tensor([0.3595, 0.3483, 0.3583], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "56000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 2, 2])\n",
      "loss=  tensor(4.5654, grad_fn=<AddBackward0>)   , actor=  tensor(3.5001, grad_fn=<DivBackward0>)   , critic=  tensor(10.6531, grad_fn=<SumBackward0>)   , return=  16196.25\n",
      "probs of actions:  tensor([0.2196, 0.4544, 0.4422], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "57000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([1, 3, 2])\n",
      "loss=  tensor(5.0714, grad_fn=<AddBackward0>)   , actor=  tensor(4.0166, grad_fn=<DivBackward0>)   , critic=  tensor(10.5486, grad_fn=<SumBackward0>)   , return=  16125.5\n",
      "probs of actions:  tensor([0.2512, 0.2118, 0.5010], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "58000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 2, 2])\n",
      "loss=  tensor(4.5462, grad_fn=<AddBackward0>)   , actor=  tensor(3.4809, grad_fn=<DivBackward0>)   , critic=  tensor(10.6531, grad_fn=<SumBackward0>)   , return=  16196.25\n",
      "probs of actions:  tensor([0.1826, 0.5434, 0.5277], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "59000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 1])\n",
      "loss=  tensor(6.0326, grad_fn=<AddBackward0>)   , actor=  tensor(4.9615, grad_fn=<DivBackward0>)   , critic=  tensor(10.7116, grad_fn=<SumBackward0>)   , return=  16231.8125\n",
      "probs of actions:  tensor([0.1829, 0.1939, 0.2672], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "60000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([2, 2, 1])\n",
      "loss=  tensor(3.7214, grad_fn=<AddBackward0>)   , actor=  tensor(2.6634, grad_fn=<DivBackward0>)   , critic=  tensor(10.5798, grad_fn=<SumBackward0>)   , return=  16148.578125\n",
      "probs of actions:  tensor([0.4780, 0.4614, 0.2488], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "61000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([2, 2, 1])\n",
      "loss=  tensor(3.8367, grad_fn=<AddBackward0>)   , actor=  tensor(2.7787, grad_fn=<DivBackward0>)   , critic=  tensor(10.5798, grad_fn=<SumBackward0>)   , return=  16148.578125\n",
      "probs of actions:  tensor([0.4601, 0.4442, 0.2402], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "62000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(3.9422, grad_fn=<AddBackward0>)   , actor=  tensor(2.8847, grad_fn=<DivBackward0>)   , critic=  tensor(10.5749, grad_fn=<SumBackward0>)   , return=  16145.578125\n",
      "probs of actions:  tensor([0.3979, 0.3856, 0.3771], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "63000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([1, 2, 3])\n",
      "loss=  tensor(4.6071, grad_fn=<AddBackward0>)   , actor=  tensor(3.5584, grad_fn=<DivBackward0>)   , critic=  tensor(10.4876, grad_fn=<SumBackward0>)   , return=  16088.0625\n",
      "probs of actions:  tensor([0.2668, 0.3580, 0.3575], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "64000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 2, 2])\n",
      "loss=  tensor(4.2269, grad_fn=<AddBackward0>)   , actor=  tensor(3.1616, grad_fn=<DivBackward0>)   , critic=  tensor(10.6531, grad_fn=<SumBackward0>)   , return=  16196.25\n",
      "probs of actions:  tensor([0.3149, 0.4041, 0.3947], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "65000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([2, 3, 0])\n",
      "loss=  tensor(5.7966, grad_fn=<AddBackward0>)   , actor=  tensor(4.7331, grad_fn=<DivBackward0>)   , critic=  tensor(10.6347, grad_fn=<SumBackward0>)   , return=  16182.078125\n",
      "probs of actions:  tensor([0.4374, 0.2879, 0.0196], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "66000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 2, 3])\n",
      "loss=  tensor(4.5164, grad_fn=<AddBackward0>)   , actor=  tensor(3.4519, grad_fn=<DivBackward0>)   , critic=  tensor(10.6450, grad_fn=<SumBackward0>)   , return=  16191.25\n",
      "probs of actions:  tensor([0.2879, 0.4030, 0.2978], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "67000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 2, 2])\n",
      "loss=  tensor(4.2706, grad_fn=<AddBackward0>)   , actor=  tensor(3.2052, grad_fn=<DivBackward0>)   , critic=  tensor(10.6531, grad_fn=<SumBackward0>)   , return=  16196.25\n",
      "probs of actions:  tensor([0.3045, 0.4057, 0.3957], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "68000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([1, 1, 2])\n",
      "loss=  tensor(4.6365, grad_fn=<AddBackward0>)   , actor=  tensor(3.5925, grad_fn=<DivBackward0>)   , critic=  tensor(10.4401, grad_fn=<SumBackward0>)   , return=  16058.75\n",
      "probs of actions:  tensor([0.2909, 0.2968, 0.3749], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "69000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([1, 3, 3])\n",
      "loss=  tensor(4.6196, grad_fn=<AddBackward0>)   , actor=  tensor(3.5655, grad_fn=<DivBackward0>)   , critic=  tensor(10.5406, grad_fn=<SumBackward0>)   , return=  16120.5\n",
      "probs of actions:  tensor([0.3238, 0.2998, 0.3032], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "70000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(4.7775, grad_fn=<AddBackward0>)   , actor=  tensor(3.7077, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.2970, 0.3019, 0.3053], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "71000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([2, 1, 3])\n",
      "loss=  tensor(4.3538, grad_fn=<AddBackward0>)   , actor=  tensor(3.3027, grad_fn=<DivBackward0>)   , critic=  tensor(10.5111, grad_fn=<SumBackward0>)   , return=  16106.203125\n",
      "probs of actions:  tensor([0.3805, 0.3022, 0.3098], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "72000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([2, 3, 2])\n",
      "loss=  tensor(4.1258, grad_fn=<AddBackward0>)   , actor=  tensor(3.0630, grad_fn=<DivBackward0>)   , critic=  tensor(10.6283, grad_fn=<SumBackward0>)   , return=  16178.078125\n",
      "probs of actions:  tensor([0.4240, 0.2902, 0.4021], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "73000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 1])\n",
      "loss=  tensor(4.7027, grad_fn=<AddBackward0>)   , actor=  tensor(3.6316, grad_fn=<DivBackward0>)   , critic=  tensor(10.7116, grad_fn=<SumBackward0>)   , return=  16231.8125\n",
      "probs of actions:  tensor([0.3098, 0.3130, 0.2942], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "74000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([2, 3, 3])\n",
      "loss=  tensor(4.3988, grad_fn=<AddBackward0>)   , actor=  tensor(3.3367, grad_fn=<DivBackward0>)   , critic=  tensor(10.6202, grad_fn=<SumBackward0>)   , return=  16173.078125\n",
      "probs of actions:  tensor([0.3836, 0.2992, 0.3020], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "75000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([2, 1, 2])\n",
      "loss=  tensor(4.0946, grad_fn=<AddBackward0>)   , actor=  tensor(3.0426, grad_fn=<DivBackward0>)   , critic=  tensor(10.5192, grad_fn=<SumBackward0>)   , return=  16111.203125\n",
      "probs of actions:  tensor([0.4192, 0.2964, 0.3994], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "76000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([1, 2, 1])\n",
      "loss=  tensor(4.5562, grad_fn=<AddBackward0>)   , actor=  tensor(3.5061, grad_fn=<DivBackward0>)   , critic=  tensor(10.5004, grad_fn=<SumBackward0>)   , return=  16096.0625\n",
      "probs of actions:  tensor([0.2857, 0.3811, 0.2938], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "77000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([2, 1, 3])\n",
      "loss=  tensor(4.3697, grad_fn=<AddBackward0>)   , actor=  tensor(3.3186, grad_fn=<DivBackward0>)   , critic=  tensor(10.5111, grad_fn=<SumBackward0>)   , return=  16106.203125\n",
      "probs of actions:  tensor([0.3964, 0.2781, 0.3163], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "78000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([2, 2, 1])\n",
      "loss=  tensor(3.8965, grad_fn=<AddBackward0>)   , actor=  tensor(2.8386, grad_fn=<DivBackward0>)   , critic=  tensor(10.5798, grad_fn=<SumBackward0>)   , return=  16148.578125\n",
      "probs of actions:  tensor([0.4386, 0.4248, 0.2657], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "79000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 2, 2])\n",
      "loss=  tensor(4.3657, grad_fn=<AddBackward0>)   , actor=  tensor(3.3004, grad_fn=<DivBackward0>)   , critic=  tensor(10.6531, grad_fn=<SumBackward0>)   , return=  16196.25\n",
      "probs of actions:  tensor([0.3084, 0.3773, 0.3703], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "80000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([2, 3, 1])\n",
      "loss=  tensor(4.3244, grad_fn=<AddBackward0>)   , actor=  tensor(3.2611, grad_fn=<DivBackward0>)   , critic=  tensor(10.6331, grad_fn=<SumBackward0>)   , return=  16181.078125\n",
      "probs of actions:  tensor([0.3795, 0.3513, 0.2644], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "81000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([1, 1, 1])\n",
      "loss=  tensor(4.8643, grad_fn=<AddBackward0>)   , actor=  tensor(3.8198, grad_fn=<DivBackward0>)   , critic=  tensor(10.4449, grad_fn=<SumBackward0>)   , return=  16061.75\n",
      "probs of actions:  tensor([0.2822, 0.2864, 0.2885], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "82000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 2, 3])\n",
      "loss=  tensor(4.1545, grad_fn=<AddBackward0>)   , actor=  tensor(3.0900, grad_fn=<DivBackward0>)   , critic=  tensor(10.6450, grad_fn=<SumBackward0>)   , return=  16191.25\n",
      "probs of actions:  tensor([0.4014, 0.3062, 0.4007], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "83000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([1, 2, 1])\n",
      "loss=  tensor(5.0287, grad_fn=<AddBackward0>)   , actor=  tensor(3.9787, grad_fn=<DivBackward0>)   , critic=  tensor(10.5004, grad_fn=<SumBackward0>)   , return=  16096.0625\n",
      "probs of actions:  tensor([0.2345, 0.3501, 0.2466], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "84000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 2])\n",
      "loss=  tensor(3.5777, grad_fn=<AddBackward0>)   , actor=  tensor(2.5071, grad_fn=<DivBackward0>)   , critic=  tensor(10.7067, grad_fn=<SumBackward0>)   , return=  16228.8125\n",
      "probs of actions:  tensor([0.4863, 0.4797, 0.3016], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "85000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(4.1685, grad_fn=<AddBackward0>)   , actor=  tensor(3.1111, grad_fn=<DivBackward0>)   , critic=  tensor(10.5749, grad_fn=<SumBackward0>)   , return=  16145.578125\n",
      "probs of actions:  tensor([0.3670, 0.3595, 0.3540], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "86000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([2, 1, 1])\n",
      "loss=  tensor(5.4579, grad_fn=<AddBackward0>)   , actor=  tensor(4.4055, grad_fn=<DivBackward0>)   , critic=  tensor(10.5240, grad_fn=<SumBackward0>)   , return=  16114.203125\n",
      "probs of actions:  tensor([0.3286, 0.1733, 0.1786], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "87000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(4.2887, grad_fn=<AddBackward0>)   , actor=  tensor(3.2312, grad_fn=<DivBackward0>)   , critic=  tensor(10.5749, grad_fn=<SumBackward0>)   , return=  16145.578125\n",
      "probs of actions:  tensor([0.3537, 0.3452, 0.3391], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "88000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 0])\n",
      "loss=  tensor(5.5099, grad_fn=<AddBackward0>)   , actor=  tensor(4.4386, grad_fn=<DivBackward0>)   , critic=  tensor(10.7132, grad_fn=<SumBackward0>)   , return=  16232.8125\n",
      "probs of actions:  tensor([0.4930, 0.4905, 0.0092], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "89000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 2, 2])\n",
      "loss=  tensor(4.1462, grad_fn=<AddBackward0>)   , actor=  tensor(3.0809, grad_fn=<DivBackward0>)   , critic=  tensor(10.6531, grad_fn=<SumBackward0>)   , return=  16196.25\n",
      "probs of actions:  tensor([0.4781, 0.2906, 0.2861], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "90000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 1, 0])\n",
      "loss=  tensor(6.1150, grad_fn=<AddBackward0>)   , actor=  tensor(5.0547, grad_fn=<DivBackward0>)   , critic=  tensor(10.6034, grad_fn=<SumBackward0>)   , return=  16165.8125\n",
      "probs of actions:  tensor([0.4208, 0.2550, 0.0147], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "91000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([2, 2, 3])\n",
      "loss=  tensor(4.3492, grad_fn=<AddBackward0>)   , actor=  tensor(3.2925, grad_fn=<DivBackward0>)   , critic=  tensor(10.5669, grad_fn=<SumBackward0>)   , return=  16140.578125\n",
      "probs of actions:  tensor([0.3341, 0.3257, 0.3918], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "92000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([2, 2, 3])\n",
      "loss=  tensor(4.5170, grad_fn=<AddBackward0>)   , actor=  tensor(3.4603, grad_fn=<DivBackward0>)   , critic=  tensor(10.5669, grad_fn=<SumBackward0>)   , return=  16140.578125\n",
      "probs of actions:  tensor([0.3069, 0.2998, 0.4226], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "93000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(4.5964, grad_fn=<AddBackward0>)   , actor=  tensor(3.5389, grad_fn=<DivBackward0>)   , critic=  tensor(10.5749, grad_fn=<SumBackward0>)   , return=  16145.578125\n",
      "probs of actions:  tensor([0.3189, 0.3126, 0.3083], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "94000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(3.9227, grad_fn=<AddBackward0>)   , actor=  tensor(2.8529, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.3967, 0.3957, 0.3957], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "95000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(3.9115, grad_fn=<AddBackward0>)   , actor=  tensor(2.8540, grad_fn=<DivBackward0>)   , critic=  tensor(10.5749, grad_fn=<SumBackward0>)   , return=  16145.578125\n",
      "probs of actions:  tensor([0.3999, 0.3906, 0.3836], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "96000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([2, 1, 3])\n",
      "loss=  tensor(4.3043, grad_fn=<AddBackward0>)   , actor=  tensor(3.2532, grad_fn=<DivBackward0>)   , critic=  tensor(10.5111, grad_fn=<SumBackward0>)   , return=  16106.203125\n",
      "probs of actions:  tensor([0.4193, 0.2817, 0.2999], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "97000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(3.5843, grad_fn=<AddBackward0>)   , actor=  tensor(2.5268, grad_fn=<DivBackward0>)   , critic=  tensor(10.5749, grad_fn=<SumBackward0>)   , return=  16145.578125\n",
      "probs of actions:  tensor([0.4471, 0.4336, 0.4236], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "98000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([2, 1, 2])\n",
      "loss=  tensor(4.3736, grad_fn=<AddBackward0>)   , actor=  tensor(3.3217, grad_fn=<DivBackward0>)   , critic=  tensor(10.5192, grad_fn=<SumBackward0>)   , return=  16111.203125\n",
      "probs of actions:  tensor([0.4023, 0.2445, 0.3865], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "99000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([2, 1, 1])\n",
      "loss=  tensor(4.6651, grad_fn=<AddBackward0>)   , actor=  tensor(3.6127, grad_fn=<DivBackward0>)   , critic=  tensor(10.5240, grad_fn=<SumBackward0>)   , return=  16114.203125\n",
      "probs of actions:  tensor([0.3911, 0.2438, 0.2484], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "100000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([2, 3, 3])\n",
      "loss=  tensor(4.0569, grad_fn=<AddBackward0>)   , actor=  tensor(2.9949, grad_fn=<DivBackward0>)   , critic=  tensor(10.6202, grad_fn=<SumBackward0>)   , return=  16173.078125\n",
      "probs of actions:  tensor([0.3819, 0.3729, 0.3717], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "101000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([2, 1, 3])\n",
      "loss=  tensor(4.6044, grad_fn=<AddBackward0>)   , actor=  tensor(3.5533, grad_fn=<DivBackward0>)   , critic=  tensor(10.5111, grad_fn=<SumBackward0>)   , return=  16106.203125\n",
      "probs of actions:  tensor([0.3370, 0.2549, 0.3732], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "102000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([1, 3, 3])\n",
      "loss=  tensor(4.4273, grad_fn=<AddBackward0>)   , actor=  tensor(3.3733, grad_fn=<DivBackward0>)   , critic=  tensor(10.5406, grad_fn=<SumBackward0>)   , return=  16120.5\n",
      "probs of actions:  tensor([0.2624, 0.4117, 0.4074], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "103000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 1])\n",
      "loss=  tensor(4.1490, grad_fn=<AddBackward0>)   , actor=  tensor(3.0778, grad_fn=<DivBackward0>)   , critic=  tensor(10.7116, grad_fn=<SumBackward0>)   , return=  16231.8125\n",
      "probs of actions:  tensor([0.3919, 0.3851, 0.2898], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "104000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([2, 3, 2])\n",
      "loss=  tensor(4.1121, grad_fn=<AddBackward0>)   , actor=  tensor(3.0492, grad_fn=<DivBackward0>)   , critic=  tensor(10.6283, grad_fn=<SumBackward0>)   , return=  16178.078125\n",
      "probs of actions:  tensor([0.3754, 0.3677, 0.3632], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "105000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([1, 0, 1])\n",
      "loss=  tensor(7.6220, grad_fn=<AddBackward0>)   , actor=  tensor(6.5833, grad_fn=<DivBackward0>)   , critic=  tensor(10.3870, grad_fn=<SumBackward0>)   , return=  16025.5625\n",
      "probs of actions:  tensor([0.2476, 0.0249, 0.2607], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "106000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([1, 3, 3])\n",
      "loss=  tensor(4.7500, grad_fn=<AddBackward0>)   , actor=  tensor(3.6959, grad_fn=<DivBackward0>)   , critic=  tensor(10.5406, grad_fn=<SumBackward0>)   , return=  16120.5\n",
      "probs of actions:  tensor([0.2414, 0.3628, 0.3600], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "107000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 1, 2])\n",
      "loss=  tensor(4.5315, grad_fn=<AddBackward0>)   , actor=  tensor(3.4718, grad_fn=<DivBackward0>)   , critic=  tensor(10.5970, grad_fn=<SumBackward0>)   , return=  16161.8125\n",
      "probs of actions:  tensor([0.3603, 0.2676, 0.3402], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "108000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([1, 3, 2])\n",
      "loss=  tensor(4.8516, grad_fn=<AddBackward0>)   , actor=  tensor(3.7968, grad_fn=<DivBackward0>)   , critic=  tensor(10.5486, grad_fn=<SumBackward0>)   , return=  16125.5\n",
      "probs of actions:  tensor([0.2123, 0.4056, 0.3417], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "109000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([0, 3, 3])\n",
      "loss=  tensor(7.5620, grad_fn=<AddBackward0>)   , actor=  tensor(6.5160, grad_fn=<DivBackward0>)   , critic=  tensor(10.4598, grad_fn=<SumBackward0>)   , return=  16066.078125\n",
      "probs of actions:  tensor([0.0250, 0.4802, 0.4726], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "110000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 2, 3])\n",
      "loss=  tensor(3.7651, grad_fn=<AddBackward0>)   , actor=  tensor(2.7006, grad_fn=<DivBackward0>)   , critic=  tensor(10.6450, grad_fn=<SumBackward0>)   , return=  16191.25\n",
      "probs of actions:  tensor([0.5164, 0.2793, 0.4952], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "111000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([2, 3, 3])\n",
      "loss=  tensor(4.1043, grad_fn=<AddBackward0>)   , actor=  tensor(3.0423, grad_fn=<DivBackward0>)   , critic=  tensor(10.6202, grad_fn=<SumBackward0>)   , return=  16173.078125\n",
      "probs of actions:  tensor([0.2684, 0.5001, 0.4918], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "112000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 2])\n",
      "loss=  tensor(3.5390, grad_fn=<AddBackward0>)   , actor=  tensor(2.4683, grad_fn=<DivBackward0>)   , critic=  tensor(10.7067, grad_fn=<SumBackward0>)   , return=  16228.8125\n",
      "probs of actions:  tensor([0.5065, 0.4930, 0.2763], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "113000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 1, 3])\n",
      "loss=  tensor(4.0931, grad_fn=<AddBackward0>)   , actor=  tensor(3.0342, grad_fn=<DivBackward0>)   , critic=  tensor(10.5889, grad_fn=<SumBackward0>)   , return=  16156.8125\n",
      "probs of actions:  tensor([0.4887, 0.2239, 0.4694], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "114000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([1, 3, 3])\n",
      "loss=  tensor(4.2571, grad_fn=<AddBackward0>)   , actor=  tensor(3.2030, grad_fn=<DivBackward0>)   , critic=  tensor(10.5406, grad_fn=<SumBackward0>)   , return=  16120.5\n",
      "probs of actions:  tensor([0.2380, 0.5011, 0.4924], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "115000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([1, 3, 3])\n",
      "loss=  tensor(4.1000, grad_fn=<AddBackward0>)   , actor=  tensor(3.0460, grad_fn=<DivBackward0>)   , critic=  tensor(10.5406, grad_fn=<SumBackward0>)   , return=  16120.5\n",
      "probs of actions:  tensor([0.2778, 0.4805, 0.4725], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "116000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(2.7895, grad_fn=<AddBackward0>)   , actor=  tensor(1.7196, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.5829, 0.5664, 0.5564], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "117000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 1, 2])\n",
      "loss=  tensor(4.2533, grad_fn=<AddBackward0>)   , actor=  tensor(3.1936, grad_fn=<DivBackward0>)   , critic=  tensor(10.5970, grad_fn=<SumBackward0>)   , return=  16161.8125\n",
      "probs of actions:  tensor([0.5575, 0.2813, 0.1633], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "118000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 1, 2])\n",
      "loss=  tensor(4.2348, grad_fn=<AddBackward0>)   , actor=  tensor(3.1751, grad_fn=<DivBackward0>)   , critic=  tensor(10.5970, grad_fn=<SumBackward0>)   , return=  16161.8125\n",
      "probs of actions:  tensor([0.5338, 0.2841, 0.1857], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "119000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([2, 1, 1])\n",
      "loss=  tensor(5.5831, grad_fn=<AddBackward0>)   , actor=  tensor(4.5307, grad_fn=<DivBackward0>)   , critic=  tensor(10.5240, grad_fn=<SumBackward0>)   , return=  16114.203125\n",
      "probs of actions:  tensor([0.1633, 0.3038, 0.3080], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "120000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([0, 3, 2])\n",
      "loss=  tensor(8.8275, grad_fn=<AddBackward0>)   , actor=  tensor(7.7808, grad_fn=<DivBackward0>)   , critic=  tensor(10.4678, grad_fn=<SumBackward0>)   , return=  16071.078125\n",
      "probs of actions:  tensor([0.0148, 0.5427, 0.1549], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "121000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(2.8864, grad_fn=<AddBackward0>)   , actor=  tensor(1.8165, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.5662, 0.5481, 0.5373], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "122000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(2.6306, grad_fn=<AddBackward0>)   , actor=  tensor(1.5608, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.6146, 0.5960, 0.5844], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "123000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 1])\n",
      "loss=  tensor(2.9910, grad_fn=<AddBackward0>)   , actor=  tensor(1.9199, grad_fn=<DivBackward0>)   , critic=  tensor(10.7116, grad_fn=<SumBackward0>)   , return=  16231.8125\n",
      "probs of actions:  tensor([0.6889, 0.6672, 0.1874], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "124000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([1, 3, 1])\n",
      "loss=  tensor(4.9805, grad_fn=<AddBackward0>)   , actor=  tensor(3.9252, grad_fn=<DivBackward0>)   , critic=  tensor(10.5534, grad_fn=<SumBackward0>)   , return=  16128.5\n",
      "probs of actions:  tensor([0.1666, 0.6937, 0.1878], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "125000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 2, 3])\n",
      "loss=  tensor(4.1058, grad_fn=<AddBackward0>)   , actor=  tensor(3.0413, grad_fn=<DivBackward0>)   , critic=  tensor(10.6450, grad_fn=<SumBackward0>)   , return=  16191.25\n",
      "probs of actions:  tensor([0.6803, 0.1199, 0.6442], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "126000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([1, 2, 3])\n",
      "loss=  tensor(5.6580, grad_fn=<AddBackward0>)   , actor=  tensor(4.6092, grad_fn=<DivBackward0>)   , critic=  tensor(10.4876, grad_fn=<SumBackward0>)   , return=  16088.0625\n",
      "probs of actions:  tensor([0.2315, 0.1199, 0.6064], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "127000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(2.3525, grad_fn=<AddBackward0>)   , actor=  tensor(1.2826, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.6732, 0.6524, 0.6382], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "128000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(2.1599, grad_fn=<AddBackward0>)   , actor=  tensor(1.0900, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.7138, 0.6961, 0.6832], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "129000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.9157, grad_fn=<AddBackward0>)   , actor=  tensor(0.8458, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.7714, 0.7543, 0.7413], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "130000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.9023, grad_fn=<AddBackward0>)   , actor=  tensor(0.8325, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.7750, 0.7575, 0.7441], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "131000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(2.1230, grad_fn=<AddBackward0>)   , actor=  tensor(1.0531, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.7226, 0.7043, 0.6913], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "132000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 2])\n",
      "loss=  tensor(3.2246, grad_fn=<AddBackward0>)   , actor=  tensor(2.1539, grad_fn=<DivBackward0>)   , critic=  tensor(10.7067, grad_fn=<SumBackward0>)   , return=  16228.8125\n",
      "probs of actions:  tensor([0.7480, 0.7267, 0.0853], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "133000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(2.2385, grad_fn=<AddBackward0>)   , actor=  tensor(1.1687, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.7011, 0.6757, 0.6584], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "134000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 1, 0])\n",
      "loss=  tensor(5.3047, grad_fn=<AddBackward0>)   , actor=  tensor(4.2444, grad_fn=<DivBackward0>)   , critic=  tensor(10.6034, grad_fn=<SumBackward0>)   , return=  16165.8125\n",
      "probs of actions:  tensor([0.6764, 0.2435, 0.0198], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "135000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([2, 3, 3])\n",
      "loss=  tensor(5.2203, grad_fn=<AddBackward0>)   , actor=  tensor(4.1583, grad_fn=<DivBackward0>)   , critic=  tensor(10.6202, grad_fn=<SumBackward0>)   , return=  16173.078125\n",
      "probs of actions:  tensor([0.0996, 0.6146, 0.5996], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "136000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 2, 3])\n",
      "loss=  tensor(4.3626, grad_fn=<AddBackward0>)   , actor=  tensor(3.2981, grad_fn=<DivBackward0>)   , critic=  tensor(10.6450, grad_fn=<SumBackward0>)   , return=  16191.25\n",
      "probs of actions:  tensor([0.7025, 0.0883, 0.6649], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "137000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.9271, grad_fn=<AddBackward0>)   , actor=  tensor(0.8573, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.7721, 0.7498, 0.7329], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "138000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(2.0575, grad_fn=<AddBackward0>)   , actor=  tensor(0.9877, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.7399, 0.7186, 0.7033], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "139000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 2, 3])\n",
      "loss=  tensor(4.2820, grad_fn=<AddBackward0>)   , actor=  tensor(3.2175, grad_fn=<DivBackward0>)   , critic=  tensor(10.6450, grad_fn=<SumBackward0>)   , return=  16191.25\n",
      "probs of actions:  tensor([0.7200, 0.0906, 0.6872], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "140000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 2, 3])\n",
      "loss=  tensor(4.2760, grad_fn=<AddBackward0>)   , actor=  tensor(3.2115, grad_fn=<DivBackward0>)   , critic=  tensor(10.6450, grad_fn=<SumBackward0>)   , return=  16191.25\n",
      "probs of actions:  tensor([0.7450, 0.0852, 0.7132], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "141000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([2, 1, 3])\n",
      "loss=  tensor(7.5781, grad_fn=<AddBackward0>)   , actor=  tensor(6.5270, grad_fn=<DivBackward0>)   , critic=  tensor(10.5111, grad_fn=<SumBackward0>)   , return=  16106.203125\n",
      "probs of actions:  tensor([0.0553, 0.1217, 0.7948], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "142000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 2])\n",
      "loss=  tensor(3.0990, grad_fn=<AddBackward0>)   , actor=  tensor(2.0283, grad_fn=<DivBackward0>)   , critic=  tensor(10.7067, grad_fn=<SumBackward0>)   , return=  16228.8125\n",
      "probs of actions:  tensor([0.8333, 0.8171, 0.0648], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "143000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.6593, grad_fn=<AddBackward0>)   , actor=  tensor(0.5895, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.8373, 0.8206, 0.8066], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "144000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.6672, grad_fn=<AddBackward0>)   , actor=  tensor(0.5974, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.8353, 0.8184, 0.8043], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "145000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 2, 3])\n",
      "loss=  tensor(4.2835, grad_fn=<AddBackward0>)   , actor=  tensor(3.2190, grad_fn=<DivBackward0>)   , critic=  tensor(10.6450, grad_fn=<SumBackward0>)   , return=  16191.25\n",
      "probs of actions:  tensor([0.8182, 0.0706, 0.7851], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "146000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.7237, grad_fn=<AddBackward0>)   , actor=  tensor(0.6538, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.8210, 0.8031, 0.7887], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "147000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.5935, grad_fn=<AddBackward0>)   , actor=  tensor(0.5236, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.8552, 0.8384, 0.8243], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "148000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 1])\n",
      "loss=  tensor(2.7966, grad_fn=<AddBackward0>)   , actor=  tensor(1.7254, grad_fn=<DivBackward0>)   , critic=  tensor(10.7116, grad_fn=<SumBackward0>)   , return=  16231.8125\n",
      "probs of actions:  tensor([0.9187, 0.9063, 0.0710], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "149000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.3488, grad_fn=<AddBackward0>)   , actor=  tensor(0.2789, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9211, 0.9102, 0.9000], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "150000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.2870, grad_fn=<AddBackward0>)   , actor=  tensor(0.2171, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9386, 0.9292, 0.9201], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "151000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.2422, grad_fn=<AddBackward0>)   , actor=  tensor(0.1723, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9514, 0.9433, 0.9353], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "152000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 1])\n",
      "loss=  tensor(2.9289, grad_fn=<AddBackward0>)   , actor=  tensor(1.8577, grad_fn=<DivBackward0>)   , critic=  tensor(10.7116, grad_fn=<SumBackward0>)   , return=  16231.8125\n",
      "probs of actions:  tensor([0.9498, 0.9427, 0.0479], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "153000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.2002, grad_fn=<AddBackward0>)   , actor=  tensor(0.1303, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9633, 0.9567, 0.9501], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "154000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.2227, grad_fn=<AddBackward0>)   , actor=  tensor(0.1529, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9567, 0.9495, 0.9423], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "155000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.1972, grad_fn=<AddBackward0>)   , actor=  tensor(0.1274, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9640, 0.9577, 0.9513], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "156000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.2019, grad_fn=<AddBackward0>)   , actor=  tensor(0.1320, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9626, 0.9562, 0.9498], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "157000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.2086, grad_fn=<AddBackward0>)   , actor=  tensor(0.1387, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9605, 0.9542, 0.9476], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "158000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([2, 1, 3])\n",
      "loss=  tensor(10.7576, grad_fn=<AddBackward0>)   , actor=  tensor(9.7065, grad_fn=<DivBackward0>)   , critic=  tensor(10.5111, grad_fn=<SumBackward0>)   , return=  16106.203125\n",
      "probs of actions:  tensor([0.0112, 0.0488, 0.9295], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "159000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.3577, grad_fn=<AddBackward0>)   , actor=  tensor(0.2878, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9159, 0.9089, 0.9013], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "160000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.4131, grad_fn=<AddBackward0>)   , actor=  tensor(0.3432, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9010, 0.8920, 0.8830], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "161000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([1, 3, 3])\n",
      "loss=  tensor(4.7231, grad_fn=<AddBackward0>)   , actor=  tensor(3.6690, grad_fn=<DivBackward0>)   , critic=  tensor(10.5406, grad_fn=<SumBackward0>)   , return=  16120.5\n",
      "probs of actions:  tensor([0.0919, 0.8832, 0.8745], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "162000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.3713, grad_fn=<AddBackward0>)   , actor=  tensor(0.3015, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9127, 0.9045, 0.8961], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "163000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.2779, grad_fn=<AddBackward0>)   , actor=  tensor(0.2081, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9392, 0.9330, 0.9263], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "164000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.2150, grad_fn=<AddBackward0>)   , actor=  tensor(0.1451, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9573, 0.9528, 0.9477], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "165000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([1, 3, 3])\n",
      "loss=  tensor(5.6652, grad_fn=<AddBackward0>)   , actor=  tensor(4.6111, grad_fn=<DivBackward0>)   , critic=  tensor(10.5406, grad_fn=<SumBackward0>)   , return=  16120.5\n",
      "probs of actions:  tensor([0.0446, 0.9431, 0.9372], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "166000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 1, 3])\n",
      "loss=  tensor(4.2920, grad_fn=<AddBackward0>)   , actor=  tensor(3.2331, grad_fn=<DivBackward0>)   , critic=  tensor(10.5889, grad_fn=<SumBackward0>)   , return=  16156.8125\n",
      "probs of actions:  tensor([0.9428, 0.0518, 0.9315], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "167000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.3152, grad_fn=<AddBackward0>)   , actor=  tensor(0.2454, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9274, 0.9221, 0.9158], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "168000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.3223, grad_fn=<AddBackward0>)   , actor=  tensor(0.2524, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9250, 0.9202, 0.9142], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "169000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.3883, grad_fn=<AddBackward0>)   , actor=  tensor(0.3185, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9067, 0.9000, 0.8926], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "170000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.5187, grad_fn=<AddBackward0>)   , actor=  tensor(0.4488, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.8708, 0.8619, 0.8529], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "171000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.3813, grad_fn=<AddBackward0>)   , actor=  tensor(0.3114, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9097, 0.9016, 0.8932], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "172000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.3709, grad_fn=<AddBackward0>)   , actor=  tensor(0.3011, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9131, 0.9044, 0.8957], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "173000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([0, 3, 3])\n",
      "loss=  tensor(8.4639, grad_fn=<AddBackward0>)   , actor=  tensor(7.4179, grad_fn=<DivBackward0>)   , critic=  tensor(10.4598, grad_fn=<SumBackward0>)   , return=  16066.078125\n",
      "probs of actions:  tensor([0.0068, 0.8850, 0.8750], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "174000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.7393, grad_fn=<AddBackward0>)   , actor=  tensor(0.6695, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.8108, 0.8023, 0.7937], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "175000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.6230, grad_fn=<AddBackward0>)   , actor=  tensor(0.5531, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.8421, 0.8331, 0.8241], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "176000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.5020, grad_fn=<AddBackward0>)   , actor=  tensor(0.4322, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.8753, 0.8667, 0.8579], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "177000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 2])\n",
      "loss=  tensor(3.1461, grad_fn=<AddBackward0>)   , actor=  tensor(2.0754, grad_fn=<DivBackward0>)   , critic=  tensor(10.7067, grad_fn=<SumBackward0>)   , return=  16228.8125\n",
      "probs of actions:  tensor([0.8854, 0.8778, 0.0446], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "178000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.7033, grad_fn=<AddBackward0>)   , actor=  tensor(0.6334, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.8224, 0.8106, 0.7999], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "179000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.7967, grad_fn=<AddBackward0>)   , actor=  tensor(0.7269, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.7986, 0.7860, 0.7747], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "180000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.8868, grad_fn=<AddBackward0>)   , actor=  tensor(0.8169, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.7780, 0.7619, 0.7489], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "181000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 2])\n",
      "loss=  tensor(3.1086, grad_fn=<AddBackward0>)   , actor=  tensor(2.0379, grad_fn=<DivBackward0>)   , critic=  tensor(10.7067, grad_fn=<SumBackward0>)   , return=  16228.8125\n",
      "probs of actions:  tensor([0.7345, 0.7207, 0.1115], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "182000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(2.2745, grad_fn=<AddBackward0>)   , actor=  tensor(1.2047, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.6858, 0.6718, 0.6611], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "183000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 0, 1])\n",
      "loss=  tensor(5.8304, grad_fn=<AddBackward0>)   , actor=  tensor(4.7761, grad_fn=<DivBackward0>)   , critic=  tensor(10.5433, grad_fn=<SumBackward0>)   , return=  16128.5\n",
      "probs of actions:  tensor([0.6056, 0.0512, 0.1852], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "184000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([0, 3, 1])\n",
      "loss=  tensor(7.2354, grad_fn=<AddBackward0>)   , actor=  tensor(6.1882, grad_fn=<DivBackward0>)   , critic=  tensor(10.4726, grad_fn=<SumBackward0>)   , return=  16074.078125\n",
      "probs of actions:  tensor([0.0389, 0.6346, 0.1637], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "185000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(2.2191, grad_fn=<AddBackward0>)   , actor=  tensor(1.1493, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.6985, 0.6838, 0.6728], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "186000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.9961, grad_fn=<AddBackward0>)   , actor=  tensor(0.9262, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.7507, 0.7356, 0.7231], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "187000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.7673, grad_fn=<AddBackward0>)   , actor=  tensor(0.6974, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.8080, 0.7927, 0.7794], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "188000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.7799, grad_fn=<AddBackward0>)   , actor=  tensor(0.7100, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.8052, 0.7893, 0.7754], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "189000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.7943, grad_fn=<AddBackward0>)   , actor=  tensor(0.7244, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.8019, 0.7853, 0.7711], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "190000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 1])\n",
      "loss=  tensor(2.9647, grad_fn=<AddBackward0>)   , actor=  tensor(1.8936, grad_fn=<DivBackward0>)   , critic=  tensor(10.7116, grad_fn=<SumBackward0>)   , return=  16231.8125\n",
      "probs of actions:  tensor([0.8129, 0.7945, 0.0925], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "191000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([2, 3, 3])\n",
      "loss=  tensor(4.8813, grad_fn=<AddBackward0>)   , actor=  tensor(3.8193, grad_fn=<DivBackward0>)   , critic=  tensor(10.6202, grad_fn=<SumBackward0>)   , return=  16173.078125\n",
      "probs of actions:  tensor([0.0923, 0.8104, 0.7955], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "192000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 2])\n",
      "loss=  tensor(2.8905, grad_fn=<AddBackward0>)   , actor=  tensor(1.8198, grad_fn=<DivBackward0>)   , critic=  tensor(10.7067, grad_fn=<SumBackward0>)   , return=  16228.8125\n",
      "probs of actions:  tensor([0.7850, 0.7656, 0.1234], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "193000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([1, 3, 3])\n",
      "loss=  tensor(5.2078, grad_fn=<AddBackward0>)   , actor=  tensor(4.1538, grad_fn=<DivBackward0>)   , critic=  tensor(10.5406, grad_fn=<SumBackward0>)   , return=  16120.5\n",
      "probs of actions:  tensor([0.0737, 0.8007, 0.7851], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "194000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([2, 3, 3])\n",
      "loss=  tensor(5.2927, grad_fn=<AddBackward0>)   , actor=  tensor(4.2307, grad_fn=<DivBackward0>)   , critic=  tensor(10.6202, grad_fn=<SumBackward0>)   , return=  16173.078125\n",
      "probs of actions:  tensor([0.0638, 0.8743, 0.8619], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "195000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 1])\n",
      "loss=  tensor(3.2196, grad_fn=<AddBackward0>)   , actor=  tensor(2.1485, grad_fn=<DivBackward0>)   , critic=  tensor(10.7116, grad_fn=<SumBackward0>)   , return=  16231.8125\n",
      "probs of actions:  tensor([0.9132, 0.9021, 0.0344], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "196000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.3270, grad_fn=<AddBackward0>)   , actor=  tensor(0.2572, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9273, 0.9168, 0.9068], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "197000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.2367, grad_fn=<AddBackward0>)   , actor=  tensor(0.1669, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9528, 0.9451, 0.9373], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "198000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.2761, grad_fn=<AddBackward0>)   , actor=  tensor(0.2063, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9420, 0.9324, 0.9233], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "199000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.2741, grad_fn=<AddBackward0>)   , actor=  tensor(0.2042, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9431, 0.9328, 0.9230], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "200000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.2457, grad_fn=<AddBackward0>)   , actor=  tensor(0.1759, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9516, 0.9416, 0.9319], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "201000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([1, 2, 1])\n",
      "loss=  tensor(9.4285, grad_fn=<AddBackward0>)   , actor=  tensor(8.3785, grad_fn=<DivBackward0>)   , critic=  tensor(10.5004, grad_fn=<SumBackward0>)   , return=  16096.0625\n",
      "probs of actions:  tensor([0.0423, 0.1229, 0.0564], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "202000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 2, 3])\n",
      "loss=  tensor(3.6532, grad_fn=<AddBackward0>)   , actor=  tensor(2.5887, grad_fn=<DivBackward0>)   , critic=  tensor(10.6450, grad_fn=<SumBackward0>)   , return=  16191.25\n",
      "probs of actions:  tensor([0.8330, 0.1244, 0.7953], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "203000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 2, 3])\n",
      "loss=  tensor(3.7101, grad_fn=<AddBackward0>)   , actor=  tensor(2.6456, grad_fn=<DivBackward0>)   , critic=  tensor(10.6450, grad_fn=<SumBackward0>)   , return=  16191.25\n",
      "probs of actions:  tensor([0.8592, 0.1108, 0.8237], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "204000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.5300, grad_fn=<AddBackward0>)   , actor=  tensor(0.4601, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.8751, 0.8551, 0.8379], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "205000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.6005, grad_fn=<AddBackward0>)   , actor=  tensor(0.5307, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.8563, 0.8352, 0.8173], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "206000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 2])\n",
      "loss=  tensor(2.6653, grad_fn=<AddBackward0>)   , actor=  tensor(1.5946, grad_fn=<DivBackward0>)   , critic=  tensor(10.7067, grad_fn=<SumBackward0>)   , return=  16228.8125\n",
      "probs of actions:  tensor([0.8139, 0.7911, 0.1574], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "207000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([2, 3, 3])\n",
      "loss=  tensor(4.1340, grad_fn=<AddBackward0>)   , actor=  tensor(3.0720, grad_fn=<DivBackward0>)   , critic=  tensor(10.6202, grad_fn=<SumBackward0>)   , return=  16173.078125\n",
      "probs of actions:  tensor([0.1698, 0.7451, 0.7252], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "208000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.8933, grad_fn=<AddBackward0>)   , actor=  tensor(0.8234, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.7819, 0.7577, 0.7387], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "209000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 1])\n",
      "loss=  tensor(3.2967, grad_fn=<AddBackward0>)   , actor=  tensor(2.2255, grad_fn=<DivBackward0>)   , critic=  tensor(10.7116, grad_fn=<SumBackward0>)   , return=  16231.8125\n",
      "probs of actions:  tensor([0.7870, 0.7637, 0.0602], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "210000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([2, 3, 2])\n",
      "loss=  tensor(4.9102, grad_fn=<AddBackward0>)   , actor=  tensor(3.8474, grad_fn=<DivBackward0>)   , critic=  tensor(10.6283, grad_fn=<SumBackward0>)   , return=  16178.078125\n",
      "probs of actions:  tensor([0.1670, 0.7523, 0.1883], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "211000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([2, 3, 3])\n",
      "loss=  tensor(4.1766, grad_fn=<AddBackward0>)   , actor=  tensor(3.1146, grad_fn=<DivBackward0>)   , critic=  tensor(10.6202, grad_fn=<SumBackward0>)   , return=  16173.078125\n",
      "probs of actions:  tensor([0.1623, 0.7544, 0.7373], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "212000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 0])\n",
      "loss=  tensor(4.5420, grad_fn=<AddBackward0>)   , actor=  tensor(3.4706, grad_fn=<DivBackward0>)   , critic=  tensor(10.7132, grad_fn=<SumBackward0>)   , return=  16232.8125\n",
      "probs of actions:  tensor([0.7082, 0.6890, 0.0106], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "213000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(2.0016, grad_fn=<AddBackward0>)   , actor=  tensor(0.9317, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.7531, 0.7319, 0.7168], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "214000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.9472, grad_fn=<AddBackward0>)   , actor=  tensor(0.8773, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.7661, 0.7452, 0.7300], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "215000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([2, 2, 3])\n",
      "loss=  tensor(5.6584, grad_fn=<AddBackward0>)   , actor=  tensor(4.6017, grad_fn=<DivBackward0>)   , critic=  tensor(10.5669, grad_fn=<SumBackward0>)   , return=  16140.578125\n",
      "probs of actions:  tensor([0.1646, 0.1761, 0.7505], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "216000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 2])\n",
      "loss=  tensor(2.6553, grad_fn=<AddBackward0>)   , actor=  tensor(1.5846, grad_fn=<DivBackward0>)   , critic=  tensor(10.7067, grad_fn=<SumBackward0>)   , return=  16228.8125\n",
      "probs of actions:  tensor([0.7744, 0.7526, 0.1999], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "217000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([2, 3, 3])\n",
      "loss=  tensor(3.9847, grad_fn=<AddBackward0>)   , actor=  tensor(2.9227, grad_fn=<DivBackward0>)   , critic=  tensor(10.6202, grad_fn=<SumBackward0>)   , return=  16173.078125\n",
      "probs of actions:  tensor([0.1946, 0.7216, 0.7048], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "218000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(2.2177, grad_fn=<AddBackward0>)   , actor=  tensor(1.1479, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.7043, 0.6809, 0.6654], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "219000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(2.3094, grad_fn=<AddBackward0>)   , actor=  tensor(1.2395, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.6838, 0.6608, 0.6459], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "220000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(2.1503, grad_fn=<AddBackward0>)   , actor=  tensor(1.0804, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.7195, 0.6962, 0.6806], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "221000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(2.2213, grad_fn=<AddBackward0>)   , actor=  tensor(1.1515, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.7043, 0.6796, 0.6635], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "222000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(2.1106, grad_fn=<AddBackward0>)   , actor=  tensor(1.0407, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.7296, 0.7049, 0.6880], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "223000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.9683, grad_fn=<AddBackward0>)   , actor=  tensor(0.8984, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.7619, 0.7397, 0.7234], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "224000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 0, 2])\n",
      "loss=  tensor(7.4641, grad_fn=<AddBackward0>)   , actor=  tensor(6.4103, grad_fn=<DivBackward0>)   , critic=  tensor(10.5385, grad_fn=<SumBackward0>)   , return=  16125.5\n",
      "probs of actions:  tensor([0.7595, 0.0076, 0.1962], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "225000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([2, 3, 3])\n",
      "loss=  tensor(4.0545, grad_fn=<AddBackward0>)   , actor=  tensor(2.9925, grad_fn=<DivBackward0>)   , critic=  tensor(10.6202, grad_fn=<SumBackward0>)   , return=  16173.078125\n",
      "probs of actions:  tensor([0.1805, 0.7389, 0.7240], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "226000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([2, 3, 3])\n",
      "loss=  tensor(4.2628, grad_fn=<AddBackward0>)   , actor=  tensor(3.2008, grad_fn=<DivBackward0>)   , critic=  tensor(10.6202, grad_fn=<SumBackward0>)   , return=  16173.078125\n",
      "probs of actions:  tensor([0.1455, 0.7887, 0.7735], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "227000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 2, 3])\n",
      "loss=  tensor(3.4660, grad_fn=<AddBackward0>)   , actor=  tensor(2.4015, grad_fn=<DivBackward0>)   , critic=  tensor(10.6450, grad_fn=<SumBackward0>)   , return=  16191.25\n",
      "probs of actions:  tensor([0.7961, 0.1619, 0.7626], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "228000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 1])\n",
      "loss=  tensor(3.1800, grad_fn=<AddBackward0>)   , actor=  tensor(2.1089, grad_fn=<DivBackward0>)   , critic=  tensor(10.7116, grad_fn=<SumBackward0>)   , return=  16231.8125\n",
      "probs of actions:  tensor([0.8023, 0.7850, 0.0669], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "229000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.8675, grad_fn=<AddBackward0>)   , actor=  tensor(0.7976, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.7844, 0.7659, 0.7515], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "230000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([2, 3, 3])\n",
      "loss=  tensor(4.2257, grad_fn=<AddBackward0>)   , actor=  tensor(3.1636, grad_fn=<DivBackward0>)   , critic=  tensor(10.6202, grad_fn=<SumBackward0>)   , return=  16173.078125\n",
      "probs of actions:  tensor([0.1542, 0.7668, 0.7493], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "231000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 2, 3])\n",
      "loss=  tensor(3.5965, grad_fn=<AddBackward0>)   , actor=  tensor(2.5320, grad_fn=<DivBackward0>)   , critic=  tensor(10.6450, grad_fn=<SumBackward0>)   , return=  16191.25\n",
      "probs of actions:  tensor([0.8296, 0.1324, 0.7919], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "232000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 2])\n",
      "loss=  tensor(2.6577, grad_fn=<AddBackward0>)   , actor=  tensor(1.5870, grad_fn=<DivBackward0>)   , critic=  tensor(10.7067, grad_fn=<SumBackward0>)   , return=  16228.8125\n",
      "probs of actions:  tensor([0.8367, 0.8157, 0.1403], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "233000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([2, 3, 3])\n",
      "loss=  tensor(4.5625, grad_fn=<AddBackward0>)   , actor=  tensor(3.5005, grad_fn=<DivBackward0>)   , critic=  tensor(10.6202, grad_fn=<SumBackward0>)   , return=  16173.078125\n",
      "probs of actions:  tensor([0.1134, 0.8205, 0.8036], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "234000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.6196, grad_fn=<AddBackward0>)   , actor=  tensor(0.5497, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.8505, 0.8301, 0.8135], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "235000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 2, 3])\n",
      "loss=  tensor(3.6203, grad_fn=<AddBackward0>)   , actor=  tensor(2.5558, grad_fn=<DivBackward0>)   , critic=  tensor(10.6450, grad_fn=<SumBackward0>)   , return=  16191.25\n",
      "probs of actions:  tensor([0.8451, 0.1248, 0.8084], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "236000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([2, 3, 3])\n",
      "loss=  tensor(4.5930, grad_fn=<AddBackward0>)   , actor=  tensor(3.5310, grad_fn=<DivBackward0>)   , critic=  tensor(10.6202, grad_fn=<SumBackward0>)   , return=  16173.078125\n",
      "probs of actions:  tensor([0.1104, 0.8247, 0.8083], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "237000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.4142, grad_fn=<AddBackward0>)   , actor=  tensor(0.3443, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9050, 0.8893, 0.8763], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "238000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.3228, grad_fn=<AddBackward0>)   , actor=  tensor(0.2529, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9307, 0.9169, 0.9050], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "239000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 2])\n",
      "loss=  tensor(2.7431, grad_fn=<AddBackward0>)   , actor=  tensor(1.6724, grad_fn=<DivBackward0>)   , critic=  tensor(10.7067, grad_fn=<SumBackward0>)   , return=  16228.8125\n",
      "probs of actions:  tensor([0.9212, 0.9065, 0.0773], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "240000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.3007, grad_fn=<AddBackward0>)   , actor=  tensor(0.2309, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9369, 0.9238, 0.9120], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "241000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.2161, grad_fn=<AddBackward0>)   , actor=  tensor(0.1462, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9608, 0.9506, 0.9411], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "242000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.2318, grad_fn=<AddBackward0>)   , actor=  tensor(0.1619, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9559, 0.9458, 0.9363], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "243000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.1840, grad_fn=<AddBackward0>)   , actor=  tensor(0.1141, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9692, 0.9613, 0.9537], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "244000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.1382, grad_fn=<AddBackward0>)   , actor=  tensor(0.0683, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9819, 0.9765, 0.9711], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "245000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.1444, grad_fn=<AddBackward0>)   , actor=  tensor(0.0745, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9802, 0.9744, 0.9687], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "246000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.1258, grad_fn=<AddBackward0>)   , actor=  tensor(0.0560, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9854, 0.9807, 0.9759], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "247000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.1562, grad_fn=<AddBackward0>)   , actor=  tensor(0.0863, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9770, 0.9705, 0.9640], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "248000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.2454, grad_fn=<AddBackward0>)   , actor=  tensor(0.1755, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9520, 0.9415, 0.9316], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "249000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.2118, grad_fn=<AddBackward0>)   , actor=  tensor(0.1419, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9612, 0.9524, 0.9440], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "250000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.3342, grad_fn=<AddBackward0>)   , actor=  tensor(0.2644, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9264, 0.9140, 0.9028], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "251000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.3920, grad_fn=<AddBackward0>)   , actor=  tensor(0.3222, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9108, 0.8962, 0.8833], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "252000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.2845, grad_fn=<AddBackward0>)   , actor=  tensor(0.2146, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9411, 0.9291, 0.9181], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "253000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.3911, grad_fn=<AddBackward0>)   , actor=  tensor(0.3213, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9119, 0.8960, 0.8823], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "254000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([2, 3, 3])\n",
      "loss=  tensor(5.1156, grad_fn=<AddBackward0>)   , actor=  tensor(4.0536, grad_fn=<DivBackward0>)   , critic=  tensor(10.6202, grad_fn=<SumBackward0>)   , return=  16173.078125\n",
      "probs of actions:  tensor([0.0714, 0.8823, 0.8675], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "255000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.3539, grad_fn=<AddBackward0>)   , actor=  tensor(0.2840, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9221, 0.9074, 0.8947], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "256000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.2114, grad_fn=<AddBackward0>)   , actor=  tensor(0.1416, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9615, 0.9524, 0.9438], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "257000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.1953, grad_fn=<AddBackward0>)   , actor=  tensor(0.1254, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9660, 0.9577, 0.9497], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "258000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.2321, grad_fn=<AddBackward0>)   , actor=  tensor(0.1623, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9559, 0.9456, 0.9360], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "259000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.2652, grad_fn=<AddBackward0>)   , actor=  tensor(0.1954, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9469, 0.9349, 0.9242], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "260000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.2025, grad_fn=<AddBackward0>)   , actor=  tensor(0.1326, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9643, 0.9551, 0.9465], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "261000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.2095, grad_fn=<AddBackward0>)   , actor=  tensor(0.1397, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9614, 0.9533, 0.9455], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "262000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.1894, grad_fn=<AddBackward0>)   , actor=  tensor(0.1195, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9669, 0.9599, 0.9530], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "263000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.1779, grad_fn=<AddBackward0>)   , actor=  tensor(0.1080, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9698, 0.9638, 0.9578], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "264000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.1898, grad_fn=<AddBackward0>)   , actor=  tensor(0.1199, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9666, 0.9599, 0.9531], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "265000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.1519, grad_fn=<AddBackward0>)   , actor=  tensor(0.0820, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9776, 0.9722, 0.9666], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "266000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.1800, grad_fn=<AddBackward0>)   , actor=  tensor(0.1101, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9697, 0.9629, 0.9562], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "267000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.1636, grad_fn=<AddBackward0>)   , actor=  tensor(0.0937, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9746, 0.9682, 0.9619], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "268000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.1553, grad_fn=<AddBackward0>)   , actor=  tensor(0.0855, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9770, 0.9709, 0.9648], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "269000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.1384, grad_fn=<AddBackward0>)   , actor=  tensor(0.0685, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9818, 0.9765, 0.9711], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "270000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.1606, grad_fn=<AddBackward0>)   , actor=  tensor(0.0908, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9757, 0.9690, 0.9624], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "271000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.1597, grad_fn=<AddBackward0>)   , actor=  tensor(0.0899, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9759, 0.9693, 0.9629], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "272000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.1394, grad_fn=<AddBackward0>)   , actor=  tensor(0.0696, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9815, 0.9761, 0.9708], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "273000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.1217, grad_fn=<AddBackward0>)   , actor=  tensor(0.0518, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9863, 0.9821, 0.9778], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "274000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.1219, grad_fn=<AddBackward0>)   , actor=  tensor(0.0520, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9864, 0.9820, 0.9776], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "275000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.1106, grad_fn=<AddBackward0>)   , actor=  tensor(0.0407, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9893, 0.9859, 0.9823], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "276000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.0841, grad_fn=<AddBackward0>)   , actor=  tensor(0.0142, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9964, 0.9950, 0.9935], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "277000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.1123, grad_fn=<AddBackward0>)   , actor=  tensor(0.0424, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9889, 0.9853, 0.9816], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "278000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.1096, grad_fn=<AddBackward0>)   , actor=  tensor(0.0398, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9896, 0.9862, 0.9827], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "279000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.0989, grad_fn=<AddBackward0>)   , actor=  tensor(0.0290, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9925, 0.9899, 0.9871], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "280000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.0810, grad_fn=<AddBackward0>)   , actor=  tensor(0.0112, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9972, 0.9961, 0.9947], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "281000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.0787, grad_fn=<AddBackward0>)   , actor=  tensor(0.0088, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9979, 0.9969, 0.9958], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "282000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.0749, grad_fn=<AddBackward0>)   , actor=  tensor(0.0051, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9988, 0.9982, 0.9975], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "283000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.0730, grad_fn=<AddBackward0>)   , actor=  tensor(0.0032, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9993, 0.9989, 0.9984], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "284000   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.0723, grad_fn=<AddBackward0>)   , actor=  tensor(0.0025, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9994, 0.9991, 0.9987], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: False\n",
      "--------------------------------------------------\n",
      "284724   adversary:  AdversaryModes.myopic\n",
      "  actions:  tensor([3, 3, 3])\n",
      "loss=  tensor(1.0718, grad_fn=<AddBackward0>)   , actor=  tensor(0.0019, grad_fn=<DivBackward0>)   , critic=  tensor(10.6986, grad_fn=<SumBackward0>)   , return=  16223.8125\n",
      "probs of actions:  tensor([0.9996, 0.9993, 0.9990], grad_fn=<ExpBackward0>)\n",
      "shouldBreak: True\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "algorithm.solver(print_step=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "advModeNames=\"\"\n",
    "for i in range(len(adversaryProbs)):\n",
    "    if adversaryProbs[i]!=0:\n",
    "        tmp=\"{:.1f}\".format(adversaryProbs[i])\n",
    "        advModeNames+=f\"{(AdversaryModes(i)).name}-{tmp}-\"\n",
    "    \n",
    "name=f\"ep {algorithm.numberEpisodes}, {advModeNames}, {game.advHistoryNum} hist, {neuralNet.lr} lr\"\n",
    "neuralNet.save(name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "profits = pd.DataFrame(game.profit).T\n",
    "prices = pd.DataFrame(game.prices).T\n",
    "demandPotential = pd.DataFrame(game.demandPotential).T\n",
    "learning = pd.DataFrame(algorithm.returns[0],columns=['entry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAsnklEQVR4nO3dd3wUdfoH8M9DR0GpNlCD/YCTABFRLCBSRM7KKZye3KmHnuXOO3968UTFzlnvrIiKiAWwHBwKKEWKdBJIIDQhkEBoCQklJCSkPL8/dpNsNrN9Zmd38nm/XnllMzM780w2efa73yqqCiIicq4GdgdARETWYqInInI4JnoiIodjoicicjgmeiIih2tkdwBG2rVrpwkJCXaHQUQUN1JTUw+oanujfTGZ6BMSEpCSkmJ3GEREcUNEsn3tY9UNEZHDMdETETkcEz0RkcPFZB29kbKyMuTk5KCkpMTuUKKmWbNm6NixIxo3bmx3KEQUx+Im0efk5KBly5ZISEiAiNgdjuVUFfn5+cjJyUGnTp3sDoeI4ljcVN2UlJSgbdu29SLJA4CIoG3btvXqEwwRWSNuEj2AepPkq9S3+yUia8RVoiciioa0XYeQsfuw3WGYhoneItOnT8fGjRvtDoOIwnDTu0sx9O0ldodhGiZ6i/hL9OXl5VGOhojqMyb6EHz++efo1asXEhMTcd9996GiogItWrTAk08+iW7duqF3797Yv38/li1bhhkzZuCxxx5DYmIiMjMz0bdvX/zzn//E1VdfjRdffBGdOnVCWVkZAODIkSNISEio/pmIyExx073S07PfbcDGPUdMPWfnM07CM7/p4nP/pk2bMHXqVCxduhSNGzfGAw88gC+++AJFRUXo3bs3XnzxRTz++OP48MMPMXr0aNxwww0YOnQohg0bVn2OQ4cOYdGiRQCArKwszJw5EzfddBOmTJmCW2+9lf3liWLQseMVWLPzIPqc187uUMLGEn2Q5s+fj9TUVFxyySVITEzE/PnzsX37djRp0gRDhw4FAPTs2RNZWVk+z3H77bdXP7733nvxySefAAA++eQT/PGPf7Q0fiIKzz+nrccdH63EjgNFdocStrgs0fsreVtFVTFy5Ei8/PLLtba/9tpr1d0gGzZs6Lf+/cQTT6x+3KdPH2RlZWHRokWoqKhA165drQmciCLyy/5CAEBRafy2rbFEH6T+/fvjm2++QW5uLgCgoKAA2dk+ZwVFy5YtUVhY6Pecd911F0aMGMHSPBFZiok+SJ07d8YLL7yAgQMH4uKLL8aAAQOwd+9en8cPHz4cr776Krp3747MzEzDY+644w4cPHgQI0aMsCpsIqL4rLqxy+23316rnh0Ajh49Wv142LBh1Y2vffr0qdW9cuHChXXOt2TJEgwbNgytWrWyJF4iIiCIRC8iEwAMBZCrql3d26YCuNB9SCsAh1Q10eC5WQAKAVQAKFfVJFOidoCHH34Ys2fPxqxZs+wOhYgcLpgS/UQA7wCYVLVBVauLtSLyOgB/Y4X7qeqBcAN0qrffftvuEIiongiY6FV1sYgkGO0TV3eT2wBcY3JcvmKpVxN9qardIRCRA0TaGHslgP2qutXHfgUwR0RSRWSUvxOJyCgRSRGRlLy8vDr7mzVrhvz8/HqT/Krmo2/WrJndoRBRnIu0MXYEgMl+9vdR1T0icgqAuSKyWVUXGx2oquMBjAeApKSkOtm8Y8eOyMnJgdGbgFNVrTBFRPZxQtky7EQvIo0A3AKgp69jVHWP+3uuiEwD0AuAYaIPpHHjxlxpiYgoDJFU3VwLYLOq5hjtFJETRaRl1WMAAwFkRHA9IiIKQ8BELyKTASwHcKGI5IjIPe5dw+FVbSMiZ4hIVX/BUwEsEZF0AKsAzFTVH8wLnYiIghFMrxvDYZuq+geDbXsADHE/3g6gW4TxERFRhDgFAhGRwzHRExE5HBM9EZHDMdETEfnhgG70TPRERMGI59lXmOiJiByOiZ6IyOGY6ImI/HDCRIpM9EREQRDEbyU9Ez0RkcMx0RMRORwTPRGRwzHRExE5HBM9EVEQOGCKiIhiFhM9EZHDMdETETkcEz0ROZKq4rMV2ThcXGZ3KLZjoiciR0rbdQhPTc/AP75dZ3cotgtmcfAJIpIrIhke28aIyG4RSXN/DfHx3MEiskVEtolIspmBExH5U1peCQAoKD5ucyT2C6ZEPxHAYIPtb6pqovtrlvdOEWkI4F0A1wHoDGCEiHSOJFgiIgpdwESvqosBFIRx7l4AtqnqdlU9DmAKgBvDOA8RkW0cMHllRHX0D4nIOnfVTmuD/R0A7PL4Oce9zZCIjBKRFBFJycvLiyAsIoon2flFSEieiXkb99sdil/1ccDU+wDOBZAIYC+A1w2OMfq1+HxvVNXxqpqkqknt27cPMywiijdpuw4BAP6Xvifk5+444HqT2JZ71OSonCWsRK+q+1W1QlUrAXwIVzWNtxwAZ3r83BFA6K8kEZEP37nfHP6XtrvOPidUuZglrEQvIqd7/HgzgAyDw1YDOF9EOolIEwDDAcwI53pEROGK4xoX0zQKdICITAbQF0A7EckB8AyAviKSCFdVTBaA+9zHngHgI1UdoqrlIvIQgB8BNAQwQVU3WHETRETkW8BEr6ojDDZ/7OPYPQCGePw8C0CdrpdERBQ9HBlLRKZa9EseCks47UAsYaInItPsO1yCkRNW4a9T0qJ6XSsbXtV3Z8G4wURPRKY5VlYBANieF53ujv4aWs1K0FVvIhLHzbpM9EQxZt/hEhQfL7c7DMcwa6BTfRwwRUQW6f3yfNz2wXK7w4i6OM6jMY+JnigGZew+YncI5CBM9EQEAPgmNQc5B4vtDoMswERPRCirqMT/fZ2O346LzyojJ/SMsRITPRFV9yw5cLQ0qtctq6hEeYXr4uGkar8NpMz91QKOjCUiClWwOfZXT/2A8kprM3I8d4s0C0v0RGSaUFOq1UneDLEfYWBM9EQUE75L34OHJ6+ts33jniNYu/OgDRHVFs+fC5joiahapFMJRFr6/c5g8ZEhb/2Mm99bFuGZ6zcmeiIKOOpz96Fj2JkffNdLf6fLOlCEldvzgz4XRY6NsUQUUJ+xPwEAssZeH/G5+r620LRzVTH6JOKEunWzsERPZIOSsgocKj5udxh1mJ0cyyoqUVZRafJZa0gQE9DE0hw1M9ftrV4jN5pYoieywU3vLsXmfYWmlmojYVUu7PbsHDRu2ADpzww09bxrdh7E0q0H0KBBDGXxIDz45RoA5n6aCQZL9ORI6bsO4dvUHLvDMJSafRCb9xXaHYYhNXli9+LjFTh8zPxFSG55bxlen/uL6ed1KiZ6cqQb312KR79OtzuMOrblFuLW92OvB0kwVSChsKJ+/Ghp+FM37z18DDe9uxT5UR75GysCJnoRmSAiuSKS4bHtVRHZLCLrRGSaiLTy8dwsEVkvImkikmJi3ES2yNh9GEu3HQj7+QVFzl5iz8qKlEiS9Ec/70DarkOYtnZ3yM81+1OOHYIp0U8EMNhr21wAXVX1YgC/AHjCz/P7qWqiqiaFFyJR7Bj69hLc8dHKWttKyirw3sJtOFh0vN6WGO0WjVQcS426oQqY6FV1MYACr21zVLXqc9QKAB0tiI0cZtWOAkxZtdPuMEz33sJMvPLDFnR/fi56vjDP7nBiVkWl4v+iWJ3mgIK4acyoo78bwGwf+xTAHBFJFZFRJlyL4thtHyxH8n/XR/WaT/8vA+UWdu8DgKII6o7tsO9wCbIOFBnuizQ3+nv+5n1H8E0QDeSl5RXYfehYhJHUiLQk7oT3i4gSvYg8CaAcwBc+Dumjqj0AXAfgQRG5ys+5RolIioik5OXlRRIWUbVJy7OxNJOjMD31fnl+9aClKlW50KxScCS59ZEpaegz9ifL36BDtWXfUQx8cxGOlMRfO0vYiV5ERgIYCuAO9dFaoap73N9zAUwD0MvX+VR1vKomqWpS+/btww2LyNH2HylBSVmF6eeNpfrn+ZtyAQAVIbzrvL8wE/sOl1gVEgDg9blb8Mv+o1gehwWHsBK9iAwG8A8AN6iq4QQYInKiiLSsegxgIIAMo2OJKDiXvjQfd01YZXcYMenKV34y5TxO6GXjLZjulZMBLAdwoYjkiMg9AN4B0BLAXHfXyXHuY88QkVnup54KYImIpANYBWCmqv5gyV0Q1SOrdtTqG4GJS3cg94i1pdlQGaVKq/NnWYWasubtbR/E53KK/gTT62aEqp6uqo1VtaOqfqyq56nqme5uk4mqer/72D2qOsT9eLuqdnN/dVHVF62+Gaq/8gpL8Zu3l2DvYfMa8YIVbAI7UlKGCpMX2sjOL8KY7zZi1Geppp43XNGuAfKucjpyrKZhPNA6sl+szDYcvLY6y/65783GkbHkCN+k5mD97sOYuCwr5OfmHy1FbqE1JeJ1OYfw1PQMlJRV4OIxczBmxgZTz1+1QtMRC6YZsIvZC337WkrwyWkZSM0OIqn7CCf3SAm25R6NILLoYaKPUwVFx7EijDm9v0vfg4TkmVFfBDqW9XxhHnq9ON+Sc48YvwKfrchGQZFrpsot+4Of4yYz7yj6vbYwpgZhvbtgG6aHMbo0nJ4q3gna7rVfva/e66X5uPaNRaacOyF5JsbO3mzKuYww0cewikrFnR+tNGzlHz5+OYaPXxHyOauWavOu56XwmVUCLS2vwFPTa/orjFuYiR0Hiqp7ocSCV3/cgkempgV17Bsek45dPGYO5mzcH9G1zS7p22nDnsN1to1blGnZ9ZjoY1heYSmWbDuAR6bWXUfzl/3x8ZEx2j5YtB3Fx2sPYAq2F0VJWQUe/ybdtk87F47+AZ+tyDbcV1pegUFvLo5yRL55TjC2PDMfOwwGYL01f6vfn+2SklVgSUHnN28vwZtBzqh5/VtLTL++P0z0Mazq475dyioqkfztOlNHKUbDnkPh1bfPXLcXX6Xk4KWZm+rsGzNjA37eGvpAvqLj/vu8v/PTVnR/bk7A82TnF4dU7WO1rs/8WF11OOLDFej32kJk5xeFVZ1opkCl/q9TcjBs3HLDnjVHSsqwOiv8N4D1uw/jPzHyZuaNiT6GDXnrZ1uvvywzH1NW70Lyt+tsjcPTJ0t3YMnW0GePTMkqQFlFJQqKjiMheSa+Wr0rpOdPXJaF338cfv91X+nntTm/4GCx/Q2p4UxTvGZn7YbMq19dWD3FxbEAb3D++PoAZjQgyrve3vO6nuepeuzvzfK+San47Tjzu1b+uGEfFmy2t/qNib6eKq/UkIaYd39uDga+aU7DUySe/W4j7vx4ZeADPWzaW4hh45Zj7OzNyMp3VTF8GeHkap7dJH0lJrPqXB+PoTfaYEUyd3yVZZm139BvD6JNati45XUWHg/2PSzDoN7cU7gtBPd9loo/Tlwd5rPNwURfT/1l8lpc/epCv8cs2lJTVXGwuMywXeCTpTuQkDwTh4+VITu/CE9NzzC9r3ikqnqtbAlyVSfv6I+X131D9E5CRiLtReHvt5hXGDs9cazyh0/CS44pwXSZNFBYEtybk68J4QIxqordnncUvx1n/UI0TPT1WKC69wlLdwQ8x+fuxsO8whI8PHktPluRjfW765aMwqluCYUZc7X4Osek5Vl1tkXjveygnzaaS16ch0qPIApLy1FaHlp1SWl5BXYV1B1J+tPm/bZ2vy23oaBg1Auminc0L4f5Bj7VoLrw1R+3RGWAFhN9HFAF3p6/Fdn54ZUkos0oX87bFFnXOjMo1O8o1vRdh1zHqWJdziFMXLoDeYWllk+W5UugN2LPW8krLMWw90OrX07+dj2ufGVBnV5Kd09MCao94pUftmBnfuRTDsSCYBrwY2jet5A1sjsACiy3sBSvz/0F367JwcLH+tkdTtzxLKlXzfxoVHr/dLnr00l6zmHc8M5SAMCY7zaGdU3v3ieRTpQVzNONPkn5s3CLq4GwpKwSJzSpvc+zUFHmpy1nSQTLKobLcwAZB/4FhyX6OFJSFv783Dvzi2Nu4qto8UyS3ssAGjHqE173nP4zb4ZX0o10Qi9fXW2DPe/R0nI8PHltrSQZbG+fj34OXIXnrTiCXjeeNu87Umeb5ypeHy/xHVtstRTZiyX6euKqVxfYHUItBUXHcbSkHGe1PcH0c3uX1r9ftxcAsHRb9Pp4hzoHSpq72siXER+GPgra09cpu/Bd+h60PbFJ4IO9HCz23VYwOYLeS8F8yhn8b3u7GJvJzpG9LNHHkVgfAh5KqfWKf/0UtTeffQafZNbuPGTa+dcaJOnDIU4y9olBw/fmAL2EolFnfLS0HOMXb/e5P9TqIk+TlhuPAraDrzedr1MCj7eYs2Ff2NeN1oIvTPQmUlUs23YgovrY/KOlSM02Hp0X6mmPHa8wvbHsh4x9hl0LPWML5o/XrI/2sSA9QGk8mg4Xl+GW95Ya9qbxxd/fq5XdOIOpIrPbY98EHsOwYnvszxvFRG+i6Wm78buPVuLrlMALIPty83vLcGuIvSd8GfVZiuml5vs/T8XvPqyp5w52RKXVq/aIj8dWCXQ3di3NNyN9N9bsPIQPFls3QVasE3E1uo8MciWueyauRlmF71c03L/dikqt1QXWTkz0JtqZ7+oOF+wqN2UVlXj++40oKDpe3Qd6ZwglsUB+trjvOlDzTzB5VWhTClS599PVEY2iLC2vMBzQFC2xNjjswFH/8yMZJa01BtVYAmD+pv34Koiqi3BZ+bsL5ZPI/M25ho2+VbLcn4pDnSbi3H/Owq0eg6HsXKGQid5GM9ftxcdLdqDH83Nx4ejAqyxa+Xeyq6AYCckz/f7B+zNh6Y7qbnih/EHP25SLrs/8GNY1AdeMj1f8y5y1QsPx3oJttl0bqPvJIdcrwU1fuxvPf78RRX7eTP80KaXOaE8RwT2fpuD9hdZ9MvA1U2ekXvlhC658JTY6H/hrC/ohY2/UCilM9DaKhdLg5yuyoar40d2g9NXqutVO/j4Z5B6pSSz+Gg8979TfIhTlFZX4/ccrfbZTeKoalZtbWBrWxGCp2QeR5NFVLxRVk6Jt3Gv8xhiNRTJmrt+LZ/7nf8WqR6am4eMlO/DaHP/T50bSqBrrwpmwLRru/3wN5kVprQF2r4wjVSXlv0yuOz99uEZPz8CFp7UM67kHi46j0KCkGOj/yl+Jf9fBY/h56wHsKigOODhstMciHdvzarozBvuPPXFZVtgDbmZnBOhpEWJuCbWXDlCziIwZXvnRutWN4kEk1Sqx3hsOCKJELyITRCRXRDI8trURkbkistX9vbWP5w4WkS0isk1Eks0MvH5y/UHNSN9Ta2tJWQVenr2pzlD2YJWGMRBLVfHgl2t87n9qegaecE9ZW/fJIV+ujj1+pgfwN5LT03dev8dQLc/MD/pTWaBEsnBL6HPdG4mkX7snM2afjCWBkvE7NlfBWS2YEv1EAO8AmOSxLRnAfFUd607gyQD+4fkkEWkI4F0AAwDkAFgtIjNUNbwx5XHkSEk5yisq0aih//fRR79ON+V6ny3PxgeLtqNpo4b4+4ALTDlnIJ2emOU/Jne1iqriwX7n1dpnRgnIX2l2nIX1yp4iHcRkJV9VR7Ff9vTP6t5b/sTLQuBGAiZ6VV0sIglem28E0Nf9+FMAC+GV6AH0ArBNVbcDgIhMcT/P8Yl+4rIsHDtegX8Nuzgq1/vAPaAlJasAlZWKBg3Cr5M0+2PolNW7sLOgGOe2bxFiHP55l9o9a2tWxsB6uN6vgB0f70NZ/MPuhbeDVTXKORRrsw8iNYKVo8JRGMZi6FYKtzH2VFXdCwDu76cYHNMBgGffrBz3NkMiMkpEUkQkJS/PnI+x0ZKdX4S0XYewYEtNw8q0tN1Rufa4RZnV9czLMvPxfpiLXUSzwcpfoawqiuz8YuwPYW6eHzfUzI4Zb0sfWmXq6uCrcWK0vbKOcNolCkvLAy7paLZfjwm8PGQ0WdkYa/Sn4/NfXFXHAxgPAElJSXH1CTPQAh5mMUqQ3otbpES55GLEu3ToHXewL+7fv0rDF/f2NieoKFqWeSBme3r4ku2Q6YZjwaJfjAuqdlY7hVui3y8ipwOA+7tRH6EcAGd6/NwRQGStX3HkeHklPlm6w+eLG2yDoadg/kwWGDTq5RYGLhlXxakKfL9uT0jLDHr7fl3dl7m8MvTz+RutGMteN+jKGO3/cV/vM3YO2nEq79/pqzHYgyncEv0MACMBjHV//5/BMasBnC8inQDsBjAcwO/CvF5ceva7jbi0U1t0PuOkOvs+XZYV8vkKio7j3/P894cGgKQX5tXqNnije271YHy/bg8mhhGbpw8MJsHyHDnrr2QTZwXhmLX/SAk6tGpudxj1Usbu8AYdWimY7pWTASwHcKGI5IjIPXAl+AEishWuXjVj3ceeISKzAEBVywE8BOBHAJsAfKWq/kd3ONDT/8swTGzhdl/797ytAY/x7hu+N4gVkqpCDDSEPhzLvRfhMDgmlEm4AON1XGNFavbBOo1xP0d5gY4fN+wPe8k7skagQWtWCqbXzQgfu/obHLsHwBCPn2cB8N8Pz+FSsg/ijo9W4ss/xW5d866DxXhx1qaoXc+oQH/lKwuw/aUhPhdoXrL1AD5bkVX9c6ApfO3m3S/ec0CXnayadoBiG6dACMPHS3bghneWBH38skxXiTYheSZufs9VjRJMyTxaft4aG72c/v5VGoa+Xff3WlJWgTs/XlmrZ028+WRplt0hUD3GKRDC8Pz34Q8FMHPBC7PMWh/+wgnh8NWnfHpa7Ubc8opKHC+vxEVPBZ7wjchO09aGPzV5NDDRU9QF2wFnzc5DuGD0bGuDIYpQdn5RxB0YrMaqmyjxN02sEStX9rFbShAzUxLFC6MuzbGGiT4CZRWVQc8k6Znot+4P3JC4YHN0pi+1w0NfmjfrIpEd4m3SN1bdBOl4eSV+2rwfg7ueXr2t6zM/ojTIbn6e0/kOeHOx4TEJyTMjC5KIoiKSxXLswBJ9kF6fs8W1UMDGmp4fwSZ5AOj/+qKQrnegyLlVN0QUXUz0QarqInnvpJSoXO8NGwdXEJGzMNEHKdpLrZXHwDKDROQMTPRERA7HRE9E5HBM9EREDsdET0TkcEz0REQOx0RPRORwTPRERA7HRB+EHQeK7A6BiChsTPRB6PfaQrtDICIKGxO9gQNHS5GQPBNTV++0OxQiooiFnehF5EIRSfP4OiIij3gd01dEDnsc83TEEUfBtlzX+p7/+Ha9zZEQEUUu7GmKVXULgEQAEJGGAHYDmGZw6M+qOjTc69hB7A6AiMhEZlXd9AeQqapxvcS8qmK5e5bKKr1fmm9TNERE5jAr0Q8HMNnHvstEJF1EZotIF18nEJFRIpIiIil5efYszTU9bTdGfLgC366pWeh335ESW2IhIjJLxIleRJoAuAHA1wa71wA4W1W7AXgbwHRf51HV8aqapKpJ7du3jzSssMzZ4FpUJOfgMVuuT0RkBTNK9NcBWKOq+713qOoRVT3qfjwLQGMRaWfCNU13tLQcszP2AahZZISIyAnMSPQj4KPaRkROExFxP+7lvl5MZtGRE1bZHQIRkSUiWhxcRE4AMADAfR7b7gcAVR0HYBiAP4tIOYBjAIarakwunZSafdDuEIiILBFRolfVYgBtvbaN83j8DoB3IrlGNJSWV9gdAhGRZTgyFsBfJq+1OwQiIstEVKJ3ghHjV2D59phsNiAiMkW9LtGrKpM8ETlePU/0dkdARGS9elt1s+9wCbbmFtodBhGR5eptou/9MuewIaL6oV5W3Twyhb1siKj+qJeJfnraHrtDICKKmnqX6Ccs2WF3CEREUVWvEn36rkN47vuNdodBRBRVjk/0qopdBcUoKatAQfFxu8MhIoo6x/e6ef77TZiw1FVd8/TQzjZHQ0QUfY4q0ZdXVOJ4eSUSkmdizIwNUNXqJA+A1TZEVC85qkR/1SsLsOewa+m/icuyMHFZlr0BERHFAEeV6KuSPBER1XBUoiciorqY6ImIHI6JnojI4ZjoiYgcLqJELyJZIrJeRNJEJMVgv4jIWyKyTUTWiUiPSK5HREShM6N7ZT9VPeBj33UAznd/XQrgffd3IiKKEqurbm4EMEldVgBoJSKnW3xNIqK4dLi4zJLzRproFcAcEUkVkVEG+zsA2OXxc457Wx0iMkpEUkQkJS8vL8KwiIjiT7fn5lhy3kgTfR9V7QFXFc2DInKV134xeI7hSq2qOl5Vk1Q1qX379hGGRUREVSJK9Kq6x/09F8A0AL28DskBcKbHzx0BcNUPIqIoCjvRi8iJItKy6jGAgQAyvA6bAeAud++b3gAOq+resKON0KMDLrDr0kREtomkRH8qgCUikg5gFYCZqvqDiNwvIve7j5kFYDuAbQA+BPBARNEG8OwNXXBmm+Y+9z90zXl447ZuVoZARBRzwu5eqarbAdTJmqo6zuOxAngw3GuEauTlCRh5eQISkmfW2df9rFYQEdzSoyP+/lV6tEIiIrKdI0fGpoy+FmlPD8Anf7iketu0B/pUP/5z33PtCIuIyBaOmo++SrsWTQEA/S46Baue7I8WTWvf5uODLsT7CzPtCI2IKOocWaL3dErLZjihSe1ELyLY8OyggM/94Pc9rQqLiChqHJ/ofTmxaeAPM4O6nIZxdzLZE1F8q7eJHgAeH3yhz33dz2oFAOhxdqvoBENEZJF6negf6HsePr3be4yXy9f3XQbAVfXjy7d/vsySuIiIzFSvEz0AXH1Be2SNvR5ZY6+vtb1Rw8C/mp5nt8GtPTpaFVrM8P7dWKk+/D6Joq3eJ3oj68YMrPXzX/qfj5Oa1a7TP+NkV0n/dRMHYG18bhC2vDDY8sSa8eygoK9R9Ynnq/us/fTy+T2XImvs9Xj9tm74z/BES69FVN8w0XtIf2YgMp4dhJOaNa61/e8DLsC6MbV76Yy66hzDcyx/4pqwr39Ck0Zo2qghAOCW7oaTfAbtyvPbYVhP49Jx44ZGc80Z63NuWwBAr05tsPixfhHF5M8V57erfnxDtzMsuw5RfcRE7+Hk5o3r9Ln39OW9NWum/KFPpzr7H77mPJx+cnO0ObFJnX1/urLu8f68cXsissZej+TrLsIT110U0nMB4NGBF+K13xp/2qh6M9n64nWua93WDR/dlWR4rGcV1lltTwg5jk7tTjTcvvapAViW7HpTPKVl01r7RIJ/IyKiwJjoQ3D5ee1wd59OmDqqd63tVXX8jw509eJJHX0tunY4CdMf7IMmDRtgzG86V+/zxdccPfdffS7uuzr0kbwXdzi5zrYLT21Zq1qqccMGyBp7PW7p0bG6lxHg+rRyzUWnoGWz8MbTfeHxhvjdw1fU+fSTNfZ6tD6xCc5o1RxZY6/HqievrXOOv13LCeiIzCKu6WhiS1JSkqak1FmC1hFW7SjAbR8sBwB8++fLcev7ywAAD/Q9F48P9l1yP1R8HInPzQXgSoJvzvvF73Wq6uALS8rw6zFzam3zZcKSHTj95GYY1OU0NGhgXKo2mkfI00s3/xq/u/SsWtu27i/EgDcXAwC2vDC4+hOFP+UVlTjvydkBjyNymnDb6EQkVVUNP5o7cgqEWNarU5vqxz3OaoXMl4Zg7sb9GNTlVL/P80yOf732fHQ54yTcOynwm2HLZo2D/sO5+4rQqpeM9DmvbZ1t55/asvpxMEkeCK7XExEFh4neBtMeuBzb84ogImgowOCupwV8TvMmDTH+9z3R/azWAIBrO/t/Y7DLWW1Cr8cnImux2GSD7me1xq0+esT4M7DLaWjv1XBppPc5bQIeE6737+jhd7+vhtSmjfinRmQX/vfFsdYnNDbcbuX8PNf9+nRkjb0e/33g8pCet+WF60Kue3xskP8GbCIKDhN9HJvx0BV1tj1/U1e0OqFu906z9TirNcbd2QNf/qmmh83wS87084zQPdjvvDrbNj8/GOe0N+6ySUTGmOjj2JkG9eFmJ1t/Bnc9HZefWzPQKZhqpVCljL62VnfWpo0a4KdH+5p+HSInY6J3mMY29FaZ5J4m4eFrzjf93O1aNMWl57TFWyO647Jz2la3AXzoNcDLR29QIgITfdzznEFz+0tDbInhKvfEcE0sbHC9odsZmOxRsveeeyjzpSEYff2vLLs+UTwL+z9TRM4UkQUisklENojIXw2O6Ssih0Ukzf31dGThkreeZ7epHpnra5CTE12S4OpZdHP3Dsgaez1EBPdeeQ5mPNQnwDOJ6p9I+tGXA3hUVdeISEsAqSIyV1U3eh33s6oOjeA6RHU0aCCGvXgu8BicRUQuYZfoVXWvqq5xPy4EsAlAZFMuEkWoWePgRt4S1SemVKqKSAKA7gBWGuy+TETSRWS2iHTxc45RIpIiIil5eXlmhEX11N0GM4sS1WcRJ3oRaQHgWwCPqOoRr91rAJytqt0AvA1guq/zqOp4VU1S1aT27dtHGhbVY0//prPdIRDFlIgSvYg0hivJf6Gq//Xer6pHVPWo+/EsAI1FpJ33cURkDSvGNlD8iaTXjQD4GMAmVX3DxzGnuY+DiPRyXy8/3GsSBevGxNqrVAUz/cI7v+tuVTi2WJp8Dd79nf+5iah+iKRE3wfA7wFc49F9coiI3C8i97uPGQYgQ0TSAbwFYLjG4gT45Dh/7V8zeGvyn3r7OdJl5l+uwNCLnbWEYYdWzWtNi031V9jdK1V1CQC/HbdV9R0A74R7DaJwndO+BZ67sQv6/+pUdGjlWr1rx8tD0OmJWYbHdznDtSLX1Re0x6Jf4r8zwE+PXm13CD6tHzOwejEcig6OjCXHuuuyhOokDwS3Fq3n1ApVa9rGm58evRrntG9R/XO4KxZFYtFjfX0u8t6yWWPc714e047Y6iMmeqpXUkbXXp923t+vqjV1hOc0DlVr2sYbzyRvl7Pbnoi3RtRu8xh3Z8/q32fydRdVP048sxUA+FygniLHFaaoXmnXoqYXSsroa2v9XCUek3uVV4ZdbLh98WP9cNWrC6ISw46Xa944r/3VKZi3Kdfv73T6g5y2wmpM9FTvhJrI054eUL0we6zrd+EphtvPalszpfWD/c7Fuwsy0bF1c+QcPBbR9dKfHoiT3QvgjF+cidsvOatWFdlHIy8J6XwbnxuEfq8txEWnnYRFv+ShXYumOHC0NKIYiYmeKKBWJzRBAwEqvfqLzfnbVRj45mJ7gjIw46E+fvvNe77BPTboourHI8avwPLt4fV6PtljlbNRV50b1jk8ndCkEVb+s3b1WkLyTACuCeymrd0d8TXqI4nF3o5JSUmakpJidxhEtZSUVdSZS+dvU9NsST5Lk69Bn7E/Vf+8/aUhYc9eqqo+eyN5+s/wRHyVsgtLt7neFLa8MBhNG0V/bqHVWQWYvykXD11zHro+82PUr2+1cKsORSRVVQ0bOliiJwqS0YRpb96eGPVE/8MjV6JDq+b49O5eGDlhFVY/eW1EU1QH0xsJAAZ1OQ03JnZAzsFinHFyc9umxb4koU31NNUUHPa6IYrQTYmhD7Q6pWVTDOvZMeTnjbuzBy467SQArj7/WWOvN2Wagw3PDgp4TNUbXcfWJ8TM2gfx3HAeTay6ITJJVV1yIE8O+RX+dNU5AZ/36IAL8HB/85dn9KewpMxwMNMfLk/AmBt8Tj5rq6Ol5RjwxiJ8fu+l6P/6oqCft+KJ/th/pARfrtyJf7l7KwX7GlrJiqobJnoik5VXVOK8J2fX2f7Szb/Gb5M6Gq7ru6ugGC2bNUKrE5pgx4EinNm6ORrZsP4vAKzPOYzZGXvx+OCLAh8cg8YvzsS57Vvgnk+Nc8hn9/TCyc0b4+KOrersO1xchktfnoeSskoM+fVpeOO2RHy5ciee+957PSXrMNETEYXgwNFSFJWW42BxGbp1PDno9ohIqCrKKhT5RaVYu/MQHvhiTdDPPbl5Y6Q/MzCs6zLRExE5nL9Ez8ZYIiKHY6InInI4JnoiIodjoicicjgmeiIih2OiJyJyOCZ6IiKHY6InInK4mBwwJSJ5ALLDfHo7AAdMDCcWOPGeAGfelxPvCXDmfTntns5W1fZGO2Iy0UdCRFJ8jQ6LV068J8CZ9+XEewKceV9OvCdfWHVDRORwTPRERA7nxEQ/3u4ALODEewKceV9OvCfAmfflxHsy5Lg6eiIiqs2JJXoiIvLARE9E5HCOSfQiMlhEtojINhFJtjseIyKSJSLrRSRNRFLc29qIyFwR2er+3trj+Cfc97NFRAZ5bO/pPs82EXlL3MvmiEhTEZnq3r5SRBIsuo8JIpIrIhke26JyHyIy0n2NrSIy0uJ7GiMiu92vV5qIDImzezpTRBaIyCYR2SAif3Vvj/fXytd9xfXrZSlVjfsvAA0BZAI4B0ATAOkAOtsdl0GcWQDaeW17BUCy+3EygH+5H3d230dTAJ3c99fQvW8VgMsACIDZAK5zb38AwDj34+EAplp0H1cB6AEgI5r3AaANgO3u763dj1tbeE9jAPyfwbHxck+nA+jhftwSwC/u2OP9tfJ1X3H9eln55ZQSfS8A21R1u6oeBzAFwI02xxSsGwF86n78KYCbPLZPUdVSVd0BYBuAXiJyOoCTVHW5uv7yJnk9p+pc3wDoX1VCMZOqLgZQYMN9DAIwV1ULVPUggLkABlt4T77Eyz3tVdU17seFADYB6ID4f6183ZcvcXFfVnJKou8AYJfHzznw/8LbRQHMEZFUERnl3naqqu4FXH/AAE5xb/d1Tx3cj72313qOqpYDOAygrQX3YSQa92HH6/yQiKxzV+1UVXHE3T25qx66A1gJB71WXvcFOOT1MptTEr1RqTUW+432UdUeAK4D8KCIXOXnWF/35O9eY/H3YOZ9RPv+3gdwLoBEAHsBvO7eHlf3JCItAHwL4BFVPeLvUB+xxMt9OeL1soJTEn0OgDM9fu4IYI9Nsfikqnvc33MBTIOrymm/+yMk3N9z3Yf7uqcc92Pv7bWeIyKNAJyM4KsjIhWN+4jq66yq+1W1QlUrAXwI1+tVKz6vOGLunkSkMVzJ8AtV/a97c9y/Vkb35YTXyzJ2NxKY8QWgEVyNIp1Q0xjbxe64vGI8EUBLj8fL4KrbexW1G8ZecT/ugtoNSNtR04C0GkBv1DQgDXFvfxC1G5C+svB+ElC74dLy+4CrAWwHXI1grd2P21h4T6d7PP4bXPW8cXNP7hgmAfi31/a4fq383Fdcv15WftkegGk3AgyBq/U9E8CTdsdjEN857j+2dAAbqmKEq95vPoCt7u9tPJ7zpPt+tsDdG8C9PQlAhnvfO6gZ4dwMwNdwNTatAnCORfcyGa6PxmVwlXDuidZ9ALjbvX0bgD9afE+fAVgPYB2AGV6JJB7u6Qq4qhXWAUhzfw1xwGvl677i+vWy8otTIBAROZxT6uiJiMgHJnoiIodjoicicjgmeiIih2OiJyJyOCZ6IiKHY6InInK4/wfyXNDuCZaV/QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = pd.DataFrame(algorithm.loss[0],columns=['entry'])\n",
    "loss.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>205.0</td>\n",
       "      <td>195.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>207.5</td>\n",
       "      <td>192.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1\n",
       "0  200.0  200.0\n",
       "1  205.0  195.0\n",
       "2  207.5  192.5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "demandPotential.plot()\n",
    "demandPotential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    16223.8125\n",
       "1    11694.8125\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profits.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5103.2500</td>\n",
       "      <td>4160.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5467.0000</td>\n",
       "      <td>3844.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5653.5625</td>\n",
       "      <td>3690.5625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1\n",
       "0  5103.2500  4160.2500\n",
       "1  5467.0000  3844.0000\n",
       "2  5653.5625  3690.5625"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD8CAYAAACb4nSYAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAmE0lEQVR4nO3dfXRc9X3n8fdXD5ZkW7IkW7YljWXJYEhsAsaWBSmBQJIGl/DUbpuY09RJoXVhydZ7utsU2p62oafntNvNJifJlsTN5iQ05Wm7JWQ5NoUmTWg2+EGyCTYBgo0FjCX8IMm2jGXZkr77x70jjeSRNJKlGY3u53XOPTPzu7975zfy9ffe+7u/B3N3REQkGvKyXQAREckcBX0RkQhR0BcRiRAFfRGRCFHQFxGJEAV9EZEIKUgnk5m1At1AP9Dn7o1m9gRweZilHDjh7mvMrB54FXg9XLfD3e8N97MO+DZQAmwDtrjajIqIZExaQT90k7sfT3xw908l3pvZF4GTSXkPuvuaFPt4GNgM7CAI+huA7RMpsIiITN5FV++YmQGfBB4bJ181UObuL4ZX948Ad17s94uISPrSvdJ34Dkzc+Ab7r41ad31wBF3fyMprcHM9gKngD91938HaoF4Up54mDamRYsWeX19fZrFFBERgJaWluPuXjUyPd2gf527t5nZYuB5M3vN3V8I193F8Kv8dqDO3TvCOvzvmdlqwFLsN2V9vpltJqgGoq6ujubm5jSLKSIiAGb2Vqr0tKp33L0tfD0KPAU0hTstAH4NeCIpb6+7d4TvW4CDwGUEV/axpN3GgLZRvm+ruze6e2NV1QUnKhERmaRxg76ZzTOz0sR74OPA/nD1x4DX3D2elL/KzPLD9yuAlcCb7t4OdJvZteFzgE3A01P6a0REZEzpVO8sAZ4K4jQFwKPu/my4biMXPsC9AXjIzPoImnje6+6d4br7GGqyuR213BERySib6c3kGxsbfWSd/vnz54nH45w9ezZLpRpfcXExsViMwsLCbBdFRCLIzFrcvXFk+kTa6c8Y8Xic0tJS6uvrCe9AZhR3p6Ojg3g8TkNDQ7aLIyIyKCeHYTh79iwLFy6ckQEfwMxYuHDhjL4TEZFoysmgD8zYgJ8w08snItGUk9U7IiKzzenePg539RDvOsPhEz28e/Isf3jz5VN+AamgP0nPPvssW7Zsob+/n9/5nd/hgQceyHaRRGQGO9lzfjCox7t6OHxiKMDHu3o4ceb8sPxzCvK498ZLKCue2sYgCvqT0N/fz/3338/zzz9PLBZj/fr13H777axatSrbRRORLHB3Tpw5HwbzIKgPLUFg7z7bN2ybksJ8YhUl1FaUsGZZObXlc4lVlAymLZpXRF7e1FcTK+hPwq5du7j00ktZsWIFABs3buTpp59W0BeZpdydjvfOBUE91dV6Vw/vnesfts38ooIggJeXcE1DJbGKudQmgnp5CZXz5mTl2V/OB/0v/N9X+HnbqSnd56qaMv78ttWjrj98+DDLli0b/ByLxdi5c+eUlkFEMmdgwDl+upd3uoZXuSTXsZ89PzBsm7LiAmIVc6lfOI/rLl0UBPXyIKgvq5hLWUnBjGzQkfNBPxtSdWibif+4IhLoH3COdp8dqm5Jqn45fCII7uf6hwf1irmFxCrmctmSUm66fHFY9RJcrddWlEx5XXum5HzQH+uKfLrEYjHeeeedwc/xeJyampqMl0NEAn39A7SfPHvBFXoiqLed6KFvYPjF2qL5RdRWlLCqpoyPr1oyPKiXlzCvKOfDY0qz81dNs/Xr1/PGG29w6NAhamtrefzxx3n00UezXSyRWetc3wDtJ3uSrtDPEE8K8O+eOkv/iKC+pKyI2vLgIemtV1aH9elBFUxteQklc/Kz9GuyS0F/EgoKCvja177GzTffTH9/P3fffTerV2f+jkNktjh7vp+2Ez0XPBxNVMEc6T5Lcq1qnsHSsmJiFXNpaqgcfDgaqwhawFSXF1NUEM2gPh4F/Um65ZZbuOWWW7JdDJGc0HOun8MnzvBO1/Cr9UR1zLHu3mH58/OM6gXFxCpKwoekJYMtX5ZVzGXpgmIK83N2QIGsUtAXkYuW3Js01dV6x3vnhuUvzDdqwpYuN11eNXiFXlteQqxyLktKiyhQUJ8WCvoiMq7RepMm3qfqTRorD67OP16zYKjTUVgFs7h0ejoeyfgU9EUi7mJ7k15dl7nepHLx0gr6ZtYKdBPMhNXn7o1m9hfA7wLHwmx/7O7bwvwPAveE+X/f3f8lTF/H0MxZ24AtPtNncRHJcbOpN6lcvIlc6d/k7sdHpH3J3f97coKZrSKYRnE1UAP8q5ld5u79wMPAZmAHQdDfgKZMFLkoF9ObdHmO9SaVizcd1Tt3AI+7ey9wyMwOAE3h3UKZu78IYGaPAHeioC8ypv4B58ipsymbMk6kN2lt4mFpDvcmlYuXbtB34Dkzc+Ab7r41TP+cmW0CmoH/4u5dQC3BlXxCPEw7H74fmZ6T7r77bp555hkWL17M/v37s10cyWEje5MmB3b1JpWplu6RcZ27t5nZYuB5M3uNoKrmLwlOCH8JfBG4G0h1T+hjpF/AzDYTVANRV1eXZhEz67Of/Syf+9zn2LRpU7aLIjNcojfpsDp19SaVLEkr6Lt7W/h61MyeAprc/YXEejP7e+CZ8GMcWJa0eQxoC9NjKdJTfd9WYCtAY2PjjHzQe8MNN9Da2prtYsgMMNnepLUVJepNKhk3btA3s3lAnrt3h+8/DjxkZtXu3h5m+1UgUcfxfeBRM/sfBA9yVwK73L3fzLrN7FpgJ7AJ+OpF/4LtD8C7+y56N8Ms/QD8yl9P7T5lVjh8ooddhzrYdaiL1949pd6kknPSudJfAjwVPskvAB5192fN7B/MbA1BFU0r8HsA7v6KmT0J/BzoA+4PW+4A3MdQk83t6CGuzGDuzsFj77HrUCe7WzvZdaiTwyd6ACgtLuCKmgXqTSo5Z9yg7+5vAlelSP+tMbb5K+CvUqQ3A1dMsIxj0xW5TJH+AefV9lPsOtQ5GOgTwwcsml9EU0MFv3t9A00NC7l8aSn56nwkOUiP+CWyevv62Rc/yc4wwLe0dtHdG/Q8jVWU8OHLq2iqr6SpoZKGRfPUbl1mBQX9Sbrrrrv40Y9+xPHjx4nFYnzhC1/gnnvuyXaxZAzv9fax5+0udh/qZOehTl565wS9fUH79pWL53PbmhquaahkfX0lNeUlWS6tyPRQ0J+kxx57LNtFkHGcOHOO3a1dwYPX1i72Hz5J/4CTZ7C6ZgGfvnY5TWGQr5w3J9vFFckIBX2ZNY6cOhtU1YR18q8f6QZgTn4ea5aVc++HV9DUsJC1deWUqkeqRJSCvuQkd+etjjPsah166PpWxxkA5s3JZ119JbddVU1Tw0KujC2guFDt3kUgh4O+u8/oB2saPHRqDQw4vzjaPdiyZtehTo6G7eMr5hayvr6S3wqra1ZVl6nJpMgocjLoFxcX09HRwcKFC2dk4Hd3Ojo6KC4uznZRctb5/gH2Hz452D5+d2sXJ3uCiTqWlhXzwUsWsr6+kmsaKrmkar7GbhdJU04G/VgsRjwe59ixY+NnzpLi4mJisdj4GQUIhjLY+/aJwaqalre66Dkf9OlbsWgeG1YvpamhcnDYgpl4shfJBTkZ9AsLC2loaMh2MeQinDp7npbWrsE6+ZfjJzjf75jB+5aW8an1y1hfX8n6hgoWl+qOSWSq5GTQl9xz/HTvYPv43a2dvNp+igGHgjzjytgC7v5QA9c0VLJueSULStSyRmS6KOjLtIh3nRmsqtl5qJM3j70HQHFhHmvrKvj9j66kqb6Sq+sqNEywSAYp6MtFCwYmO82uQ0FHqN2tXcMGJmuqr+STjctoaqjkipoFzClQyxqRbFHQlwlLDEyW6AiVPDBZVWkRTfWVbL5hBevrKzUwmcgMo6Av4+rt6+fl+MnB9vF73hoamGxZZQk3Xr6YpoYKmhoWUr9wrlrWiMxgCvpygcTAZIkgv/edE5wLBya7bMl8bl9TM9h8snqBBiYTySUK+kLXe+fY3To0Ucj+tlP0Dzj5ecbqmjI2Xbuc9RqYTGRWUNCPoHdPng3bx3ew+1DX0MBkBcHAZPd9+BKaGipZu7yC+UU6RERmk7T+R5tZK9AN9AN97t5oZn8L3AacAw4Cv+3uJ8ysHngVeD3cfIe73xvuZx1D0yVuA7a4BqmZVoMDkx3qHOwI9XZnMDDZ/KIC1i6v4PY1Nayvr9TAZCIRMJHLuJvc/XjS5+eBB929z8z+BngQ+KNw3UF3X5NiHw8Dm4EdBEF/A5ond0oNDDivH+kebB+/O2lgssp5c1hfX8GmDy7nmoaFvL+6VAOTiUTMpO/d3f25pI87gF8fK7+ZVQNl7v5i+PkR4E4U9C9KYmCyxEPX5reGBiarXhAMTNbUMDQwmVrWiERbukHfgefMzIFvuPvWEevvBp5I+txgZnuBU8Cfuvu/A7VAPClPPEy7gJltJrgjoK6uLs0iRkPPuX72vtPF7kNd7GrtYM9bJ4YNTPYrVyxlfb0GJhOR1NIN+te5e5uZLQaeN7PX3P0FADP7E6AP+McwbztQ5+4dYR3+98xsNZAq+qSszw9PKlsBGhsbI13nnxiYbOeh4MHrvsMnBwcme384MFliyr+q0qJsF1dEZri0gr67t4WvR83sKaAJeMHMPgPcCnw08UDW3XuB3vB9i5kdBC4juLJPHms4BrRN1Q+ZLY519w42ndx1qJNX3z2FOxTmGx+oXcA9H1rBNWHLGg1MJiITNW7QN7N5QJ67d4fvPw48ZGYbCB7cftjdzyTlrwI63b3fzFYAK4E33b3TzLrN7FpgJ7AJ+Oo0/Kac4e7Eu3qGBfk3jwcDk5UU5rN2eTlbPrqSpoZKrl6mgclE5OKlc6W/BHgqrBsuAB5192fN7ABQRFDdA0NNM28gOCn0ETTxvNfdO8N93cdQk83tROwhbmJgsp1hgN99qJO2k2cBKCsuoKmhcrC65oraBRSqZY2ITDGb6c3kGxsbvbm5OdvFmJS+/gFebe8e6gjV2kVn8sBkYaua9fWVXL6kVFP+iciUMbMWd28cma7ullMoeWCyneHAZKfDgcnqKufykfctpilsWbNcA5OJSBYo6F+E07197Hmra7C360tJA5NdvqSUO6+uoalhIU31lSxdoCn/RCT7FPQnIDEwWSLIv5I0MNkVNWV85oPLg3ld6yup0MBkIjIDKeiPof1kz2Crmt2tnfziyGkgGJjs6mXl/Mcbw4HJ6iqYp4HJRCQHKFKF3J3WjjODk3fvau3gnc5gyr/5RQWsW17BHWtqaWoIBiYrKlDzSRHJPZEN+omByRJX8rtaOzmWNDBZU30ln/2lBq5pqOR9SzUwmYjMDpEJ+uf7B9gXDkyWmNf11NmgZU3NgmKuu2Rh8NC1oUIDk4nIrDVrg35iYLLBKf/eThqYrGoen7iyOmlgsrlZLq2ISGbM2qD/y1/6MfGuHsxgVXUwMNk1DZU0amAyEYmwWRv0//DmyykrLtTAZCIiSWZt0L9jTcqh+kVEIk1NUkREIkRBX0QkQhT0RUQiREFfRCRCFPRFRCIkraBvZq1mts/MXjKz5jCt0syeN7M3wteKpPwPmtkBM3vdzG5OSl8X7ueAmX3F1O1VRCSjJnKlf5O7r0maieUB4AfuvhL4QfgZM1sFbARWAxuAvzOzxOhkDwObCebNXRmuFxGRDLmY6p07gO+E778D3JmU/ri797r7IeAA0GRm1UCZu7/owRyNjyRtIyIiGZBu0HfgOTNrMbPNYdoSd28HCF8Xh+m1wDtJ28bDtNrw/cj0C5jZZjNrNrPmY8eOpVlEEREZT7o9cq9z9zYzWww8b2avjZE3VT29j5F+YaL7VmArBBOjp1lGEREZR1pX+u7eFr4eBZ4CmoAjYZUN4evRMHscWJa0eQxoC9NjKdJFRCRDxg36ZjbPzEoT74GPA/uB7wOfCbN9Bng6fP99YKOZFZlZA8ED211hFVC3mV0bttrZlLSNiIhkQDrVO0uAp8LWlQXAo+7+rJntBp40s3uAt4HfAHD3V8zsSeDnQB9wv7v3h/u6D/g2UAJsDxcREckQCxrSzFyNjY3e3Nyc7WKIiOQUM2tJamI/SD1yRUQiREFfRCRCFPRFRCJEQV9EJEIU9EVEIkRBX0QkQhT0RUQiREFfRCRCFPRFRCJEQV9EJEIU9EVEIkRBX0QkQhT0RUQiREFfRCRCFPRFRCJEQV9EJELSDvpmlm9me83smfDzE2b2Uri0mtlLYXq9mfUkrft60j7Wmdk+MztgZl8Jp00UEZEMSWe6xIQtwKtAGYC7fyqxwsy+CJxMynvQ3dek2MfDwGZgB7AN2ICmTBQRyZi0rvTNLAZ8AvhminUGfBJ4bJx9VANl7v6iB3M0PgLcOdECi4jI5KVbvfNl4PPAQIp11wNH3P2NpLSGsCrox2Z2fZhWC8ST8sTDtAuY2WYzazaz5mPHjqVZRBERGc+4Qd/MbgWOunvLKFnuYvhVfjtQ5+5XA38APGpmZUCq+vuUs7K7+1Z3b3T3xqqqqvGKKCIiaUqnTv864HYzuwUoBsrM7Lvu/mkzKwB+DViXyOzuvUBv+L7FzA4ClxFc2ceS9hsD2qbmZ4iISDrGvdJ39wfdPebu9cBG4Ifu/ulw9ceA19x9sNrGzKrMLD98vwJYCbzp7u1At5ldGz4H2AQ8PbU/R0RExjKR1jupbOTCB7g3AA+ZWR/QD9zr7p3huvuAbwMlBK121HJHRCSDLGhIM3M1NjZ6c3NztoshIpJTzKzF3RtHpqtHrohIhCjoi4hEiIK+iEiEKOiLiESIgr6ISIQo6IuIRIiCvohIhCjoi4hEiIK+iEiEKOiLiESIgr6ISIQo6IuIRIiCvohIhCjoi4hEiIK+iEiEKOiLiERI2kHfzPLNbK+ZPRN+/gszO2xmL4XLLUl5HzSzA2b2upndnJS+zsz2heu+Ek6bKCIiGTKRK/0twKsj0r7k7mvCZRuAma0imEZxNbAB+LvEnLnAw8BmgnlzV4brRUQkQ9IK+mYWAz4BfDON7HcAj7t7r7sfAg4ATWZWDZS5+4sezNH4CHDn5IotIiKTke6V/peBzwMDI9I/Z2Yvm9m3zKwiTKsF3knKEw/TasP3I9MvYGabzazZzJqPHTuWZhFFRGQ84wZ9M7sVOOruLSNWPQxcAqwB2oEvJjZJsRsfI/3CRPet7t7o7o1VVVXjFVFERNJUkEae64Dbwwe1xUCZmX3X3T+dyGBmfw88E36MA8uSto8BbWF6LEW6iIhkyLhX+u7+oLvH3L2e4AHtD93902EdfcKvAvvD998HNppZkZk1EDyw3eXu7UC3mV0bttrZBDw9lT9GRETGls6V/mj+m5mtIaiiaQV+D8DdXzGzJ4GfA33A/e7eH25zH/BtoATYHi4iIpIhFjSkmbkaGxu9ubk528UQEckpZtbi7o0j09UjV0QkQhT0RUQiREFfRCRCFPRFRCJEQV9EJEIU9EVEIkRBX0QkQhT0RUQiREFfRCRCFPRFRCJEQV9EJEIU9EVEIkRBX0QkQhT0RUQiREFfRCRCFPRFRCIk7aBvZvlmttfMngk//62ZvWZmL5vZU2ZWHqbXm1mPmb0ULl9P2sc6M9tnZgfM7CvhtIkiIpIhE7nS3wK8mvT5eeAKd78S+AXwYNK6g+6+JlzuTUp/GNhMMG/uSmDD5IotIiKTkVbQN7MY8Angm4k0d3/O3fvCjzuA2Dj7qAbK3P1FD+ZofAS4czKFFhGRyUn3Sv/LwOeBgVHW383wSc4bwqqgH5vZ9WFaLRBPyhMP00REJEPGDfpmditw1N1bRln/J0Af8I9hUjtQ5+5XA38APGpmZUCq+vuUs7Kb2WYzazaz5mPHjqXxM0REJB3pXOlfB9xuZq3A48BHzOy7AGb2GeBW4DfDKhvcvdfdO8L3LcBB4DKCK/vkKqAY0JbqC919q7s3untjVVXVpH6YiIhcaNyg7+4PunvM3euBjcAP3f3TZrYB+CPgdnc/k8hvZlVmlh++X0HwwPZNd28Hus3s2rDVzibg6an/SSIiMpqCi9j2a0AR8HzY8nJH2FLnBuAhM+sD+oF73b0z3OY+4NtACcEzgO0jdyoiItPHwlqZGauxsdGbm5uzXQwRkZxiZi3u3jgyXT1yRUQiREFfRCRCZm/Q7zgI597LdilERGaUi3mQO7M9/ptw/HWoej/Urg2XdbB4FeQXZrt0IiJZMXuD/i8/BIeb4XALvPYM7P2HIL2gGJZeGZwAEieCyhWgsd9EJAKi0XrHHbpagxNA297w9SXo6wnWFy+AmrXDTwSlSy+26CIiWTNa653Ze6WfzAwqG4LlA78epPX3wbHXwhPAnuD1J18C7w/Wl9YMrxaquTo4OYiI5LBoBP1U8gtg6RXBsu4zQdq5M/DuvqGTQKJqKGHhyuF3A0uugMLi7JRfRGQSohv0U5kzF+quCZaEM51BlVDbHji8B978N3j58WBdXiEsWT38RLDoMsjLz075RUTGoaA/nrmVcOlHgwWC5wOn2oZXC+3739D8v4L1c+ZD9RqovTo8GayDBcv0oFhEZgQF/YkygwW1wbLq9iBtYAA6DgyvFtr5Deg/F6yfu2j43UDNWpi3MHu/QUQiS0F/KuTlQdVlwXLVxiCt7xwc2T9ULXS4Bd54jsEpBMqXDz8RVF8Fc+Zl7SeISDQo6E+XgjlDrX/Wh2m93UFT0cQdQbwZXvnnYJ3lhR3JkqqF1JFMRKaYgn4mFZVCw/XBknD62IjWQttg73eDdYMdyZKqhSpXBHcWIiKTEI3OWbkk0ZEsuVqo/WdwPpynZrAjWdKJoKw6q0UWkZkn2p2zcklyR7Ir/kOQluhINnhHsAd+8mV1JBORCUs76IdTIDYDh939VjOrBJ4A6oFW4JPu3hXmfRC4h2DmrN93938J09cxNHPWNmCLz/RbjZkguSPZ2k1B2vmeoCNZolro8J4UHcmS7gaWfkAdyURkQlf6W4BXgbLw8wPAD9z9r83sgfDzH5nZKoK5dFcDNcC/mtll7t4PPAxsBnYQBP0NaMrEySksgWVNwZLQ0zU0ttDhPfDmj+DlJ4J1eQVBD+LkE0HV5epIJhIxaQV9M4sBnwD+CviDMPkO4Mbw/XeAHxFMlH4H8Li79wKHzOwA0GRmrUCZu78Y7vMR4E4U9KdOSQVc8pFggaGOZMkPivf9EzR/K1hfOA9q1gw/EZTXqSOZyCyW7pX+l4HPA6VJaUvcvR3A3dvNbHGYXktwJZ8QD9POh+9Hpst0Se5I9v7bgrQLOpLtSdGRLOkkULsW5i3K3m8QkSk1btA3s1uBo+7eYmY3prHPVJeJPkZ6qu/cTFANRF1dXRpfKWkbrSPZ0VeGTgKH98AbzzO8I1nSiaD6Kiian7WfICKTl86V/nXA7WZ2C1AMlJnZd4EjZlYdXuVXA0fD/HFgWdL2MaAtTI+lSL+Au28FtkLQZHMCv0cmo2BO0OKn5urhHcnafzZULRRvgVeeCtaN7EhWszYYeE4dyURmvAm10w+v9P9r2Hrnb4GOpAe5le7+eTNbDTwKNBE8yP0BsNLd+81sN/CfgJ0ED3K/6u7bxvrOyLXTn8mGdSQLX3s6g3UFxUELoURvYnUkE8mq6Win/9fAk2Z2D/A28BsA7v6KmT0J/BzoA+4PW+4A3MdQk83t6CFubplfBZfdHCwQPCg+8dbwaqE9j8DOrwfrixcEdw+DzwfWqSOZSJapR65Mrf6+YEL65P4DR15J3ZGsZm1wUigpz2qRRWYj9ciVzMgvCOr3l6wepSPZnhQzkl06vFpIHclEpo2Cvky/cTuS7YU3fzyiI9nq4dVC6kgmMiUU9CU7RnYkg6EZyRJ3BKN1JEucCNSRTGTCFPRl5iirCZbkjmSdB4dXC+3cCv29wfq5C4dXC6kjmci4FPRl5srLg0UrgyVlR7KwemhYR7K64dVC6kgmMoyCvuSWcTuS7UnRkex9w6uF1JFMIkxBX3JfUSnUfyhYEgY7koXVQq9vH5qRLL8Iqq8cfkegjmQSEWqnL9GQqiNZ+0tDM5IVLQiGlUicBNSRTHKc2ulLtJlBRX2wJM9INtiRLLwj+OlXYKAvWF9aPTQTWeJVHckkxynoS3SN2ZEsebL6ER3JBp8NrAp6GJcu1cNiyRkK+iLJxuxIFlYLHXoB9j05fLs5pUHwL10a3CGkfF0a7F8kixT0RcYzWkey47+A7iPQ3Q7d7w69vrMzeE30J0hWXD7GSSF8nb8kaKUkMg0U9EUmI9GRbDTuwR1C8slg5OvxN+D0u0PPEJLNXTT8DiHVCWJeVVBFJTIBOmJEpoMZzK0MliWrRs83MABnOkY/MXS3B88Y3jsKPjDiO/Jg3uJxqpSqg57Lao4qIQV9kWzKywvmKZhfFfQdGE1/H7x3bPSTw8k4xHfDmeMpvqMA5i8d+66hdGlQjaWxjGY9BX2RXJBfEPQbGK/vQN85OH1k9LuGjoPQ+hM4eyLFdxSN/gA6+XNRmU4OOUxBX2Q2KZgD5cuCZSzne8ITwSgnhyOvwMEfQu+pC7ctnDt+lVLpUpgzb3p+o1yUcYO+mRUDLwBFYf5/cvc/N7MngMvDbOXACXdfY2b1wKvA6+G6He5+b7ivdQxNl7gN2OIzvUuwyGxUWAKVDcEylt7T4Z3DKNVKbXvh1Dbo67lw26Ky8auU5i/VhDkZls6Vfi/wEXc/bWaFwE/MbLu7fyqRwcy+CJxM2uagu69Jsa+Hgc3ADoKgvwHNkysycxXND5aFl4yexz24IxirpdLbL4bNWM9duH1JRXrNWDVI3pQYN+iHV+Knw4+F4TJ4dW5mBnwS+MiFWw8xs2qgzN1fDD8/AtyJgr5IbjOD4gXBUnX56PkGm7G2pzg5hO+PvR68T8ypPPQlwVwJ41UrzavSDGvjSKtO38zygRbgUuB/uvvOpNXXA0fc/Y2ktAYz2wucAv7U3f8dqAXiSXniYVqq79tMcEdAXV1dmj9FRGa0Yc1YV4+eb6B//Gas7T+D00dJuv4MvyMvuCsY7+RQUhnZZqxpBX137wfWmFk58JSZXeHu+8PVdwGPJWVvB+rcvSOsw/+ema0GUj3uT1mf7+5bga0QjLKZ1i8RkdkhLx/mLw6W6qtGz9ffF/RfGO3kcOLtoHf0mY4U31GYumXSyNfi8lnXUmlCrXfc/YSZ/YigLn6/mRUAvwasS8rTS/AcAHdvMbODwGUEV/axpN3FgLaLKr2IRFd+wfg9owH6esduxnr8jWA8pbMnL9y2oDi9lkpFpdPzG6dBOq13qoDzYcAvAT4G/E24+mPAa+4eH5G/0937zWwFsBJ40907zazbzK4FdgKbgK9O8e8RERmuoCiYRrN8nKric2eCYTFSnhzeDXpG/+I5OP/ehdvOmZ+ib0OKlkpz5k7Pb5yAdK70q4HvhPX6ecCT7p4Ya3Yjw6t2AG4AHjKzPqAfuNfdO8N19zHUZHM7eogrIjPFnLnBDGqVK8bO19s9dkul+O7gte/shdsWL0hzwL2i6fmNaOYsEZGp5x70eh7r5JBYBs5fuP3chcFJ4O5nJ111pJmzREQyxSzof1BSAYvfP3q+gQHo6Ux9Yjh9NKg2mmIK+iIi2ZKXF/Q/mLcIln4gM1+ZkW8REZEZQUFfRCRCFPRFRCJEQV9EJEIU9EVEIkRBX0QkQhT0RUQiREFfRCRCZvwwDGZ2DHhrkpsvAo5PYXGmiso1MSrXxKhcEzNby7Xc3atGJs74oH8xzKw51dgT2aZyTYzKNTEq18RErVyq3hERiRAFfRGRCJntQX9rtgswCpVrYlSuiVG5JiZS5ZrVdfoiIjLcbL/SFxGRJDkZ9M1sg5m9bmYHzOyBFOvNzL4Srn/ZzNamu+00l+s3w/K8bGY/NbOrkta1mtk+M3vJzKZ0qrA0ynWjmZ0Mv/slM/uzdLed5nL9YVKZ9ptZv5lVhuum8+/1LTM7amb7R1mfreNrvHJl6/gar1zZOr7GK1e2jq9lZvZvZvaqmb1iZltS5Jm+Y8zdc2oB8oGDwApgDvAzYNWIPLcQzL9rwLXAznS3neZy/RJQEb7/lUS5ws+twKIs/b1uBJ6ZzLbTWa4R+W8Dfjjdf69w3zcAa4H9o6zP+PGVZrkyfnylWa6MH1/plCuLx1c1sDZ8Xwr8IpMxLBev9JuAA+7+prufAx4H7hiR5w7gEQ/sAMrNrDrNbaetXO7+U3fvCj/uAGJT9N0XVa5p2naq930X8NgUffeY3P0FoHOMLNk4vsYtV5aOr3T+XqPJ6t9rhEweX+3uvid83w28CtSOyDZtx1guBv1a4J2kz3Eu/IONliedbaezXMnuITiTJzjwnJm1mNnmKSrTRMr1QTP7mZltN7PVE9x2OsuFmc0FNgD/Jyl5uv5e6cjG8TVRmTq+0pXp4ytt2Ty+zKweuBrYOWLVtB1juThHrqVIG9kEabQ86Ww7WWnv28xuIvhP+aGk5Ovcvc3MFgPPm9lr4ZVKJsq1h6DL9mkzuwX4HrAyzW2ns1wJtwH/z92Tr9qm6++VjmwcX2nL8PGVjmwcXxORlePLzOYTnGj+s7ufGrk6xSZTcozl4pV+HFiW9DkGtKWZJ51tp7NcmNmVwDeBO9y9I5Hu7m3h61HgKYLbuIyUy91Pufvp8P02oNDMFqWz7XSWK8lGRtx6T+PfKx3ZOL7SkoXja1xZOr4mIuPHl5kVEgT8f3T3f06RZfqOsel4UDGdC8HdyZtAA0MPMlaPyPMJhj8E2ZXuttNcrjrgAPBLI9LnAaVJ738KbMhguZYy1GejCXg7/Ntl9e8V5ltAUC87LxN/r6TvqGf0B5MZP77SLFfGj680y5Xx4yudcmXr+Ap/+yPAl8fIM23HWM5V77h7n5l9DvgXgifZ33L3V8zs3nD914FtBE+/DwBngN8ea9sMluvPgIXA35kZQJ8HAyotAZ4K0wqAR9392QyW69eB+8ysD+gBNnpwhGX77wXwq8Bz7v5e0ubT9vcCMLPHCFqcLDKzOPDnQGFSuTJ+fKVZrowfX2mWK+PHV5rlgiwcX8B1wG8B+8zspTDtjwlO2tN+jKlHrohIhORinb6IiEySgr6ISIQo6IuIRIiCvohIhCjoi4hEiIK+iEiEKOiLiESIgr6ISIT8f4Fyai7v8djrAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "profits.plot()\n",
    "profits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>125.50</td>\n",
       "      <td>135.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128.00</td>\n",
       "      <td>133.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>129.25</td>\n",
       "      <td>131.75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0       1\n",
       "0  125.50  135.50\n",
       "1  128.00  133.00\n",
       "2  129.25  131.75"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "prices.plot()\n",
    "prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learning.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pricelearning = pd.DataFrame(game.prices.mean(axis = 0))\n",
    "# pricelearning.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning = learning.to_numpy()\n",
    "learning_2 = [0]*len(learning)\n",
    "for i in range(len(learning)):\n",
    "    learning_2[i] = learning[i][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_learning = np.convolve(learning_2, np.ones(1000)/1000, mode = 'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(avg_learning)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
