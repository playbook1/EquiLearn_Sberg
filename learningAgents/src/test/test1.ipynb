{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from learningAgents import ReinforceAlgorithm\n",
    "from environmentModel import Model, AdversaryModes\n",
    "from NeuralNetwork import NeuralNetwork\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions import Categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adversaryProbs=torch.zeros(len(AdversaryModes))\n",
    "adversaryProbs[0]=1\n",
    "adversaryProbs[1]=0\n",
    "adversaryProbs[8]=0\n",
    "game = Model(totalDemand = 400, \n",
    "               tupleCosts = (57, 71),\n",
    "              totalStages = 3, adversaryProbs=adversaryProbs, advHistoryNum=0)\n",
    "adversaryProbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuralNet=NeuralNetwork(num_input=3+game.advHistoryNum, lr=0.0009,num_actions=4)\n",
    "algorithm = ReinforceAlgorithm(game, neuralNet, numberIterations=1, numberEpisodes=500_000, discountFactor =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([0.2517, 0.2253, 0.2504, 0.2726], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.2546, 0.2273, 0.2506, 0.2675], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.2576, 0.2272, 0.2508, 0.2644], grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "0   actions:  tensor([1, 1, 3])\n",
      "loss=  tensor(7.4485, grad_fn=<DivBackward0>)   , return=  16053.75\n",
      "discReturns/1000= tensor([5.1112, 5.4012, 5.5413])\n",
      "actionProbs tensor([[0.3344, 0.3364, 0.3381, 0.3438],\n",
      "        [0.3340, 0.3350, 0.3339, 0.3330],\n",
      "        [0.3316, 0.3286, 0.3280, 0.3231]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.2066, 0.2897, 0.2791, 0.2246], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.3016, 0.2461, 0.2508, 0.2015], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.4139, 0.1901, 0.2186, 0.1775], grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "1000   actions:  tensor([1, 2, 2])\n",
      "loss=  tensor(7.8283, grad_fn=<DivBackward0>)   , return=  16093.0625\n",
      "discReturns/1000= tensor([5.1112, 5.3983, 5.5836])\n",
      "actionProbs tensor([[0.5801, 0.7376, 0.7206, 0.7203],\n",
      "        [0.2703, 0.2000, 0.2067, 0.2064],\n",
      "        [0.1497, 0.0624, 0.0727, 0.0733]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.2566, 0.3441, 0.0719, 0.3274], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.0015, 0.0032, 0.9942, 0.0010], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.7919e-06, 2.3492e-05, 9.9997e-01, 2.4626e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "2000   actions:  tensor([1, 2, 2])\n",
      "loss=  tensor(1.9615, grad_fn=<DivBackward0>)   , return=  16093.0625\n",
      "discReturns/1000= tensor([5.1112, 5.3983, 5.5836])\n",
      "actionProbs tensor([[9.9885e-01, 9.9819e-01, 1.2432e-01, 9.9940e-01],\n",
      "        [1.1399e-03, 1.7843e-03, 3.2640e-01, 6.0125e-04],\n",
      "        [7.1627e-06, 2.1652e-05, 5.4927e-01, 2.3884e-06]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.0666, 0.6586, 0.0580, 0.2168], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.1821, 0.4569, 0.0832, 0.2777], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.4229, 0.2139, 0.0949, 0.2683], grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "3000   actions:  tensor([1, 3, 3])\n",
      "loss=  tensor(6.2044, grad_fn=<DivBackward0>)   , return=  16120.5\n",
      "discReturns/1000= tensor([5.1112, 5.3932, 5.6160])\n",
      "actionProbs tensor([[0.0555, 0.3910, 0.1591, 0.1907],\n",
      "        [0.1886, 0.3370, 0.2834, 0.3035],\n",
      "        [0.7559, 0.2721, 0.5575, 0.5058]], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.3309, 0.1202, 0.2879, 0.2610], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.0116, 0.0011, 0.9823, 0.0050], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.2098e-04, 1.0863e-05, 9.9971e-01, 5.8602e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "4000   actions:  tensor([1, 2, 2])\n",
      "loss=  tensor(2.3558, grad_fn=<DivBackward0>)   , return=  16093.0625\n",
      "discReturns/1000= tensor([5.1112, 5.3983, 5.5836])\n",
      "actionProbs tensor([[9.9900e-01, 9.9974e-01, 9.0028e-01, 9.9945e-01],\n",
      "        [9.9806e-04, 2.5625e-04, 8.7372e-02, 5.4454e-04],\n",
      "        [2.6363e-06, 3.5706e-07, 1.2353e-02, 8.8661e-07]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.3274, 0.1297, 0.2681, 0.2749], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.6369e-04, 2.2761e-04, 9.9807e-01, 7.3993e-04],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.2424e-06, 9.1688e-07, 9.9999e-01, 2.4338e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "5000   actions:  tensor([0, 2, 2])\n",
      "loss=  tensor(2.3442, grad_fn=<DivBackward0>)   , return=  16038.703125\n",
      "discReturns/1000= tensor([5.1122, 5.3616, 5.5649])\n",
      "actionProbs tensor([[9.9996e-01, 9.9998e-01, 9.4882e-01, 9.9996e-01],\n",
      "        [3.9420e-05, 2.3510e-05, 4.7311e-02, 3.6048e-05],\n",
      "        [1.0830e-08, 7.7328e-09, 3.8705e-03, 9.6817e-09]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.3404, 0.1237, 0.2535, 0.2824], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.5818e-04, 1.9098e-03, 9.9710e-01, 4.3342e-04],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0468e-06, 2.7399e-05, 9.9997e-01, 7.8372e-07],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "6000   actions:  tensor([3, 2, 2])\n",
      "loss=  tensor(2.3552, grad_fn=<DivBackward0>)   , return=  16196.25\n",
      "discReturns/1000= tensor([5.1033, 5.4720, 5.6210])\n",
      "actionProbs tensor([[9.9999e-01, 9.9989e-01, 9.7212e-01, 9.9999e-01],\n",
      "        [1.1348e-05, 1.0687e-04, 2.6466e-02, 1.0623e-05],\n",
      "        [1.1297e-09, 8.1385e-08, 1.4089e-03, 1.0195e-09]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.3540, 0.1409, 0.2271, 0.2780], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.8088e-05, 1.6462e-04, 9.9968e-01, 6.2318e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.4666e-08, 4.3412e-07, 1.0000e+00, 3.0337e-08],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "7000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.4783, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 9.9998e-01, 9.1337e-01, 1.0000e+00],\n",
      "        [4.7954e-06, 2.2509e-05, 7.7462e-02, 4.3203e-06],\n",
      "        [2.8784e-10, 7.0264e-09, 9.1726e-03, 2.4896e-10]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.2166, 0.0756, 0.5555, 0.1523], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4924e-04, 9.6556e-05, 9.9973e-01, 2.8974e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.3893e-07, 4.2463e-07, 1.0000e+00, 2.5663e-08],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "8000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3846, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[9.9999e-01, 9.9999e-01, 9.8302e-01, 1.0000e+00],\n",
      "        [6.3384e-06, 1.1741e-05, 1.6272e-02, 1.7502e-06],\n",
      "        [6.2697e-10, 2.2489e-09, 7.0890e-04, 6.7517e-11]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.1486, 0.0569, 0.6958, 0.0987], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.1616e-06, 6.2061e-06, 9.9999e-01, 1.5134e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.3530e-10, 6.1918e-09, 1.0000e+00, 3.4760e-10],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "9000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3615, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 9.9936e-01, 1.0000e+00],\n",
      "        [9.4745e-09, 4.8542e-08, 6.3945e-04, 6.8281e-09],\n",
      "        [1.4858e-14, 2.5673e-13, 3.3898e-06, 8.3135e-15]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.1466, 0.0607, 0.6953, 0.0973], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.7432e-07, 8.1090e-07, 1.0000e+00, 1.7785e-07],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.4042e-11, 1.7816e-10, 1.0000e+00, 8.7827e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "10000   actions:  tensor([0, 2, 2])\n",
      "loss=  tensor(2.3624, grad_fn=<DivBackward0>)   , return=  16038.703125\n",
      "discReturns/1000= tensor([5.1122, 5.3616, 5.5649])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 9.9992e-01, 1.0000e+00],\n",
      "        [1.3436e-10, 7.0314e-10, 7.5693e-05, 9.6165e-11],\n",
      "        [9.8701e-18, 1.7669e-16, 8.6573e-08, 5.4313e-18]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([0.1581, 0.0657, 0.6691, 0.1071], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3316e-07, 2.9685e-07, 1.0000e+00, 6.2842e-08],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.0536e-12, 3.0874e-11, 1.0000e+00, 1.4386e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "11000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3606, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 9.9998e-01, 1.0000e+00],\n",
      "        [1.3137e-11, 7.0466e-11, 2.3306e-05, 9.1460e-12],\n",
      "        [2.0957e-19, 3.8405e-18, 1.2213e-08, 1.0972e-19]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.1681, 0.0684, 0.6454, 0.1181], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.2782e-08, 1.3838e-07, 1.0000e+00, 3.0170e-08],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0571e-12, 7.9859e-12, 1.0000e+00, 3.7686e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "12000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 9.9999e-01, 1.0000e+00],\n",
      "        [2.4288e-12, 1.3159e-11, 1.0075e-05, 1.6608e-12],\n",
      "        [1.1936e-20, 2.2163e-19, 2.9404e-09, 6.0547e-21]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.1718, 0.0704, 0.6405, 0.1173], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.0639e-08, 6.8458e-08, 1.0000e+00, 1.4113e-08],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.0629e-13, 2.3498e-12, 1.0000e+00, 1.0362e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "13000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 9.9999e-01, 1.0000e+00],\n",
      "        [6.0139e-13, 3.2798e-12, 5.2655e-06, 4.0574e-13],\n",
      "        [1.1166e-21, 2.0910e-20, 9.7801e-10, 5.5328e-22]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.1716, 0.0706, 0.6238, 0.1340], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.7012e-08, 3.8190e-08, 1.0000e+00, 8.8983e-09],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0725e-13, 8.3017e-13, 1.0000e+00, 4.0982e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "14000   actions:  tensor([1, 2, 2])\n",
      "loss=  tensor(2.3619, grad_fn=<DivBackward0>)   , return=  16093.0625\n",
      "discReturns/1000= tensor([5.1112, 5.3983, 5.5836])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.6714e-13, 9.1206e-13, 2.7034e-06, 1.1197e-13],\n",
      "        [1.1942e-22, 2.2470e-21, 3.0639e-10, 5.8447e-23]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.1926, 0.0661, 0.6286, 0.1128], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.8489e-09, 1.8578e-08, 1.0000e+00, 3.8365e-09],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.0791e-14, 2.6431e-13, 1.0000e+00, 1.1542e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "15000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.6673e-14, 2.5657e-13, 1.4518e-06, 3.1046e-14],\n",
      "        [1.4640e-23, 2.7645e-22, 1.0996e-10, 7.0741e-24]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.1679, 0.0771, 0.6403, 0.1148], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.9604e-09, 1.2453e-08, 1.0000e+00, 2.2465e-09],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3180e-14, 1.1448e-13, 1.0000e+00, 4.3225e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "16000   actions:  tensor([0, 2, 2])\n",
      "loss=  tensor(2.3624, grad_fn=<DivBackward0>)   , return=  16038.703125\n",
      "discReturns/1000= tensor([5.1122, 5.3616, 5.5649])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.4810e-14, 8.0997e-14, 7.8284e-07, 9.8121e-15],\n",
      "        [1.8155e-24, 3.4350e-23, 3.6114e-11, 8.7095e-25]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.1576, 0.0747, 0.6257, 0.1419], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.1439e-09, 8.2531e-09, 1.0000e+00, 1.8745e-09],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.9960e-15, 6.2716e-14, 1.0000e+00, 3.0158e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "17000   actions:  tensor([3, 2, 2])\n",
      "loss=  tensor(2.3582, grad_fn=<DivBackward0>)   , return=  16196.25\n",
      "discReturns/1000= tensor([5.1033, 5.4720, 5.6210])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [5.1569e-15, 2.8552e-14, 4.1327e-07, 3.4155e-15],\n",
      "        [3.7300e-25, 7.0525e-24, 1.3433e-11, 1.7862e-25]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.1370, 0.0590, 0.7097, 0.0943], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5428e-09, 3.6720e-09, 1.0000e+00, 6.9892e-10],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.4389e-15, 1.9886e-14, 1.0000e+00, 7.9603e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "18000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [2.1153e-15, 1.1679e-14, 2.6464e-07, 1.3923e-15],\n",
      "        [7.7445e-26, 1.4649e-24, 6.1292e-12, 3.6726e-26]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.1059, 0.0473, 0.7800, 0.0667], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.4829e-10, 2.3462e-09, 1.0000e+00, 3.9378e-10],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3728e-15, 1.1578e-14, 1.0000e+00, 4.1096e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "19000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [9.8999e-16, 5.4851e-15, 1.4179e-07, 6.5243e-16],\n",
      "        [2.1519e-26, 4.0641e-25, 2.1289e-12, 1.0224e-26]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.1064, 0.0491, 0.7800, 0.0645], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.2757e-10, 2.3738e-09, 1.0000e+00, 3.7109e-10],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3322e-15, 1.1587e-14, 1.0000e+00, 3.8425e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "20000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9952e-16, 2.7708e-15, 7.3446e-08, 3.2963e-16],\n",
      "        [6.8274e-27, 1.2871e-25, 6.9892e-13, 3.2480e-27]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.0876, 0.0414, 0.8179, 0.0532], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.2597e-10, 1.9138e-09, 1.0000e+00, 2.8897e-10],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0574e-15, 9.3453e-15, 1.0000e+00, 3.0135e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "21000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [2.6919e-16, 1.5031e-15, 3.9712e-08, 1.7655e-16],\n",
      "        [2.4591e-27, 4.6032e-26, 2.4906e-13, 1.1547e-27]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([0.0558, 0.0268, 0.8827, 0.0348], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.8375e-10, 1.2962e-09, 1.0000e+00, 1.9345e-10],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.7555e-16, 6.7857e-15, 1.0000e+00, 2.1763e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "22000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.5231e-16, 8.5067e-16, 1.9893e-08, 9.7618e-17],\n",
      "        [9.4926e-28, 1.7311e-26, 7.7333e-14, 4.2692e-28]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.0321, 0.0156, 0.9318, 0.0205], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.8370e-10, 7.6398e-10, 1.0000e+00, 1.1210e-10],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.8245e-16, 4.1159e-15, 1.0000e+00, 1.2980e-16],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "23000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [8.1980e-17, 4.5457e-16, 9.9548e-09, 5.0598e-17],\n",
      "        [3.3382e-28, 5.8640e-27, 2.3837e-14, 1.4028e-28]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.0178, 0.0090, 0.9614, 0.0119], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.7714e-10, 5.1473e-10, 1.0000e+00, 7.4302e-11],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.3722e-16, 3.1083e-15, 1.0000e+00, 9.6835e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "24000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.8320e-17, 2.7762e-16, 5.0364e-09, 3.0184e-17],\n",
      "        [1.3579e-28, 2.4749e-27, 7.4350e-15, 5.8072e-29]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.0098, 0.0050, 0.9785, 0.0066], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.0698e-11, 2.6234e-10, 1.0000e+00, 3.6452e-11],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.6705e-16, 1.4858e-15, 1.0000e+00, 4.4341e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "25000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [2.5531e-17, 1.4474e-16, 2.8303e-09, 1.5225e-17],\n",
      "        [4.6409e-29, 8.0901e-28, 2.7933e-15, 1.8278e-29]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.0053, 0.0027, 0.9885, 0.0035], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.4076e-11, 1.2021e-10, 1.0000e+00, 1.6718e-11],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.7022e-17, 6.1196e-16, 1.0000e+00, 1.8540e-17],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "26000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.4273e-17, 7.7174e-17, 1.7285e-09, 8.0805e-18],\n",
      "        [1.7456e-29, 2.7495e-28, 1.2097e-15, 6.2712e-30]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.0033, 0.0017, 0.9928, 0.0022], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.5362e-11, 6.5483e-11, 1.0000e+00, 9.0383e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.1974e-17, 3.0078e-16, 1.0000e+00, 9.1540e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "27000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [8.0693e-18, 4.1670e-17, 1.0733e-09, 4.3567e-18],\n",
      "        [6.7224e-30, 9.6348e-29, 5.4029e-16, 2.2212e-30]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([0.0025, 0.0012, 0.9948, 0.0016], grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.9658e-11, 4.1728e-11, 1.0000e+00, 6.1987e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.4548e-17, 1.8233e-16, 1.0000e+00, 6.2719e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "28000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [5.1081e-18, 2.3093e-17, 6.4368e-10, 2.5401e-18],\n",
      "        [3.1998e-30, 3.5967e-29, 2.2943e-16, 9.1611e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.8909e-03, 9.1155e-04, 9.9596e-01, 1.2372e-03],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.0612e-11, 4.6392e-11, 1.0000e+00, 7.0609e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.6574e-17, 2.6211e-16, 1.0000e+00, 9.5080e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "29000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.7234e-18, 1.7384e-17, 3.4296e-10, 1.9493e-18],\n",
      "        [1.9632e-30, 2.2919e-29, 8.0029e-17, 6.1252e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.4735e-04, 3.8817e-04, 9.9820e-01, 5.6062e-04],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.7854e-12, 1.0993e-11, 1.0000e+00, 2.0552e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.5527e-18, 4.0936e-17, 1.0000e+00, 2.0528e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "30000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [2.3785e-18, 9.8656e-18, 3.4898e-10, 1.2770e-18],\n",
      "        [9.5052e-31, 8.8916e-30, 8.4464e-17, 3.0872e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.1134e-04, 3.3153e-04, 9.9849e-01, 4.7082e-04],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.7705e-12, 1.5144e-11, 1.0000e+00, 2.7758e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.8748e-17, 8.1395e-17, 1.0000e+00, 4.0563e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "31000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.9992e-18, 8.3596e-18, 1.8329e-10, 1.0790e-18],\n",
      "        [7.7411e-31, 7.2110e-30, 2.9415e-17, 2.5304e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.5433e-04, 1.8571e-04, 9.9908e-01, 2.8463e-04],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.6705e-12, 5.0391e-12, 1.0000e+00, 1.1506e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.5435e-18, 1.9513e-17, 1.0000e+00, 1.3579e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "32000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.2672e-18, 4.2560e-18, 1.5699e-10, 6.3402e-19],\n",
      "        [4.0089e-31, 2.5369e-30, 2.4167e-17, 1.1519e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([3.7942e-04, 1.5789e-04, 9.9923e-01, 2.3546e-04],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.6566e-12, 6.5606e-12, 1.0000e+00, 1.4493e-12],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3746e-17, 3.6115e-17, 1.0000e+00, 2.4605e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "33000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.1173e-18, 3.7830e-18, 9.1113e-11, 5.6039e-19],\n",
      "        [3.7479e-31, 2.3663e-30, 1.0353e-17, 1.0810e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.4482e-04, 9.7343e-05, 9.9951e-01, 1.4992e-04],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.4851e-12, 3.0464e-12, 1.0000e+00, 7.5844e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.8071e-18, 1.4457e-17, 1.0000e+00, 1.1954e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "34000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [7.7841e-19, 2.3999e-18, 7.6722e-11, 3.8796e-19],\n",
      "        [2.3178e-31, 1.2380e-30, 8.3401e-18, 6.6471e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.9945e-04, 8.0773e-05, 9.9960e-01, 1.2029e-04],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.8828e-12, 3.6256e-12, 1.0000e+00, 8.6552e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0972e-17, 2.3750e-17, 1.0000e+00, 1.9063e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "35000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [7.0622e-19, 2.1931e-18, 4.8879e-11, 3.5157e-19],\n",
      "        [2.3676e-31, 1.2655e-30, 4.3056e-18, 6.8208e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.6094e-05, 2.2092e-05, 9.9988e-01, 3.7903e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.9188e-13, 6.3726e-13, 1.0000e+00, 2.3850e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.9066e-18, 3.2138e-18, 1.0000e+00, 5.1068e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "36000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [7.2520e-19, 1.9825e-18, 6.8738e-11, 4.3247e-19],\n",
      "        [2.7693e-31, 1.1852e-30, 8.1485e-18, 1.0978e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.4476e-05, 1.3948e-05, 9.9993e-01, 2.2885e-05],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.7600e-13, 5.3281e-13, 1.0000e+00, 1.8803e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.1131e-18, 3.6674e-18, 1.0000e+00, 5.5916e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "37000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [6.3052e-19, 1.7445e-18, 4.5672e-11, 3.7523e-19],\n",
      "        [3.0026e-31, 1.2881e-30, 4.8993e-18, 1.1970e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.3358e-06, 2.9791e-06, 9.9998e-01, 5.4342e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.5138e-14, 7.5277e-14, 1.0000e+00, 3.8380e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.8782e-19, 4.1228e-19, 1.0000e+00, 1.1049e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "38000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [7.8100e-19, 1.9267e-18, 7.6252e-11, 5.3853e-19],\n",
      "        [4.7827e-31, 1.6870e-30, 1.2190e-17, 2.4786e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.8235e-06, 1.6078e-06, 9.9999e-01, 2.7841e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.7305e-14, 6.0488e-14, 1.0000e+00, 2.8687e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.4657e-19, 5.1629e-19, 1.0000e+00, 1.3164e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "39000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [6.3705e-19, 1.5991e-18, 4.2505e-11, 4.3795e-19],\n",
      "        [5.4348e-31, 1.9254e-30, 5.9958e-18, 2.8350e-31]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.2323e-06, 7.9875e-07, 1.0000e+00, 1.8333e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1852e-14, 8.8939e-15, 1.0000e+00, 7.4957e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.5272e-20, 4.2060e-20, 1.0000e+00, 2.3695e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "40000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8427e-19, 3.8646e-19, 3.4708e-11, 1.4191e-19],\n",
      "        [1.1457e-31, 2.9746e-31, 5.6490e-18, 7.3013e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.7772e-06, 6.4446e-07, 1.0000e+00, 1.4516e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3453e-14, 1.0322e-14, 1.0000e+00, 8.4492e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.1637e-20, 6.7684e-20, 1.0000e+00, 3.7414e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "41000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.6288e-19, 3.4464e-19, 2.1518e-11, 1.2525e-19],\n",
      "        [1.1809e-31, 3.0768e-31, 2.9296e-18, 7.5512e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.7060e-06, 6.2389e-07, 1.0000e+00, 1.3882e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.8297e-14, 1.4242e-14, 1.0000e+00, 1.1438e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2899e-19, 1.2327e-19, 1.0000e+00, 6.7262e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "42000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.4987e-19, 3.1899e-19, 1.3974e-11, 1.1514e-19],\n",
      "        [1.1715e-31, 3.0613e-31, 1.5493e-18, 7.5068e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([1.5452e-06, 4.5520e-07, 1.0000e+00, 1.4649e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.9570e-15, 1.3712e-15, 1.0000e+00, 2.5420e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.6799e-21, 2.7451e-21, 1.0000e+00, 4.5273e-21],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "43000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [5.9129e-20, 9.3077e-20, 3.0899e-11, 5.3616e-20],\n",
      "        [1.5776e-32, 2.5883e-32, 4.2920e-18, 1.3264e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2961e-06, 3.8515e-07, 1.0000e+00, 1.2282e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.6824e-15, 1.7367e-15, 1.0000e+00, 3.1617e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0950e-20, 5.3364e-21, 1.0000e+00, 8.7508e-21],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "44000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [5.1335e-20, 8.1473e-20, 1.8069e-11, 4.6513e-20],\n",
      "        [1.8694e-32, 3.0658e-32, 2.2128e-18, 1.5766e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2659e-06, 3.7803e-07, 1.0000e+00, 1.1994e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.1405e-15, 2.4489e-15, 1.0000e+00, 4.4109e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.1145e-20, 1.0360e-20, 1.0000e+00, 1.6925e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "45000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.7107e-20, 7.5151e-20, 1.1601e-11, 4.2661e-20],\n",
      "        [2.0156e-32, 3.3070e-32, 1.2068e-18, 1.7028e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3274e-06, 3.9765e-07, 1.0000e+00, 1.2576e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.4471e-15, 3.5717e-15, 1.0000e+00, 6.3870e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.0120e-20, 1.9725e-20, 1.0000e+00, 3.2147e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "46000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.4463e-20, 7.1189e-20, 7.9255e-12, 4.0253e-20],\n",
      "        [2.1240e-32, 3.4859e-32, 7.0274e-19, 1.7964e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4754e-06, 4.4253e-07, 1.0000e+00, 1.3976e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1098e-14, 5.3412e-15, 1.0000e+00, 9.5150e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.3680e-20, 3.6315e-20, 1.0000e+00, 5.9082e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "47000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.2853e-20, 6.8760e-20, 5.6971e-12, 3.8785e-20],\n",
      "        [2.1058e-32, 3.4602e-32, 4.2166e-19, 1.7825e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.6687e-06, 5.0084e-07, 1.0000e+00, 1.5806e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.6317e-14, 7.8703e-15, 1.0000e+00, 1.3986e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2949e-19, 6.3937e-20, 1.0000e+00, 1.0389e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "48000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.1714e-20, 6.7037e-20, 4.2661e-12, 3.7750e-20],\n",
      "        [2.0692e-32, 3.4038e-32, 2.6664e-19, 1.7527e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.8879e-06, 5.6690e-07, 1.0000e+00, 1.7881e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.3291e-14, 1.1253e-14, 1.0000e+00, 1.9961e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.1626e-19, 1.0693e-19, 1.0000e+00, 1.7359e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "49000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.0857e-20, 6.5740e-20, 3.3118e-12, 3.6969e-20],\n",
      "        [2.0419e-32, 3.3622e-32, 1.7825e-19, 1.7305e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.1228e-06, 6.3767e-07, 1.0000e+00, 2.0104e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.2131e-14, 1.5546e-14, 1.0000e+00, 2.7533e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.4231e-19, 1.6943e-19, 1.0000e+00, 2.7485e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "50000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.0180e-20, 6.4713e-20, 2.6545e-12, 3.6354e-20],\n",
      "        [2.0200e-32, 3.3284e-32, 1.2527e-19, 1.7126e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.3652e-06, 7.1073e-07, 9.9999e-01, 2.2400e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.2837e-14, 2.0748e-14, 1.0000e+00, 3.6702e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.1467e-19, 2.5497e-19, 1.0000e+00, 4.1336e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "51000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.9634e-20, 6.3884e-20, 2.1884e-12, 3.5856e-20],\n",
      "        [2.0025e-32, 3.3015e-32, 9.2029e-20, 1.6983e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.6089e-06, 7.8416e-07, 9.9999e-01, 2.4706e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.5319e-14, 2.6819e-14, 1.0000e+00, 4.7391e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.3853e-19, 3.6617e-19, 1.0000e+00, 5.9331e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "52000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.9188e-20, 6.3208e-20, 1.8481e-12, 3.5451e-20],\n",
      "        [1.9885e-32, 3.2802e-32, 7.0245e-20, 1.6869e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([2.8500e-06, 8.5682e-07, 9.9999e-01, 2.6989e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.9445e-14, 3.3696e-14, 1.0000e+00, 5.9489e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0173e-18, 5.0474e-19, 1.0000e+00, 8.1746e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "53000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.8806e-20, 6.2629e-20, 1.5926e-12, 3.5103e-20],\n",
      "        [1.9763e-32, 3.2615e-32, 5.5365e-20, 1.6769e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.0859e-06, 9.2791e-07, 9.9999e-01, 2.9222e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.5075e-14, 4.1308e-14, 1.0000e+00, 7.2872e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3534e-18, 6.7182e-19, 1.0000e+00, 1.0877e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "54000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.8472e-20, 6.2124e-20, 1.3955e-12, 3.4800e-20],\n",
      "        [1.9657e-32, 3.2451e-32, 4.4821e-20, 1.6683e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.3154e-06, 9.9709e-07, 9.9999e-01, 3.1395e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0207e-13, 4.9590e-14, 1.0000e+00, 8.7425e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.7478e-18, 8.6803e-19, 1.0000e+00, 1.4049e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "55000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [3.8174e-20, 6.1671e-20, 1.2400e-12, 3.4529e-20],\n",
      "        [1.9561e-32, 3.2303e-32, 3.7106e-20, 1.6604e-32]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.1540e-06, 5.3059e-07, 1.0000e+00, 2.2038e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.8992e-15, 1.4322e-15, 1.0000e+00, 4.9399e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.9516e-21, 2.0604e-21, 1.0000e+00, 7.9208e-21],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "56000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [8.9095e-21, 1.0574e-20, 3.9171e-12, 8.7803e-21],\n",
      "        [3.2668e-34, 3.4364e-34, 8.8493e-20, 3.1806e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.1154e-06, 5.2108e-07, 1.0000e+00, 2.1649e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.2607e-15, 1.5399e-15, 1.0000e+00, 5.3053e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.3560e-21, 2.4250e-21, 1.0000e+00, 9.3274e-21],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "57000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [8.6996e-21, 1.0338e-20, 3.4982e-12, 8.5725e-21],\n",
      "        [3.3789e-34, 3.5553e-34, 7.6395e-20, 3.2914e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.1129e-06, 5.2047e-07, 1.0000e+00, 2.1630e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.8475e-15, 1.7139e-15, 1.0000e+00, 5.8981e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1533e-20, 2.9897e-21, 1.0000e+00, 1.1506e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "58000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [8.5088e-21, 1.0124e-20, 3.0744e-12, 8.3835e-21],\n",
      "        [3.5079e-34, 3.6917e-34, 6.4267e-20, 3.4187e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.1467e-06, 5.2880e-07, 1.0000e+00, 2.1982e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.6968e-15, 1.9651e-15, 1.0000e+00, 6.7557e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4753e-20, 3.8247e-21, 1.0000e+00, 1.4729e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "59000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [8.3363e-21, 9.9306e-21, 2.6723e-12, 8.2130e-21],\n",
      "        [3.6431e-34, 3.8341e-34, 5.3011e-20, 3.5518e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.2139e-06, 5.4537e-07, 9.9999e-01, 2.2675e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.8418e-15, 2.3036e-15, 1.0000e+00, 7.9118e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.9346e-20, 5.0157e-21, 1.0000e+00, 1.9325e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "60000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [8.1870e-21, 9.7631e-21, 2.3114e-12, 8.0650e-21],\n",
      "        [3.7799e-34, 3.9783e-34, 4.3258e-20, 3.6867e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.3078e-06, 5.6854e-07, 9.9999e-01, 2.3642e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.2965e-15, 2.7338e-15, 1.0000e+00, 9.3805e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.5641e-20, 6.6486e-21, 1.0000e+00, 2.5627e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "61000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [8.0608e-21, 9.6219e-21, 2.0010e-12, 7.9397e-21],\n",
      "        [3.9153e-34, 4.1209e-34, 3.5240e-20, 3.8199e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.4218e-06, 5.9667e-07, 9.9999e-01, 2.4814e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1065e-14, 3.2568e-15, 1.0000e+00, 1.1166e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.3961e-20, 8.8065e-21, 1.0000e+00, 3.3958e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "62000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [7.9505e-21, 9.4982e-21, 1.7402e-12, 7.8304e-21],\n",
      "        [4.0418e-34, 4.2540e-34, 2.8823e-20, 3.9444e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([2.5460e-06, 6.2729e-07, 9.9999e-01, 2.6090e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3102e-14, 3.8594e-15, 1.0000e+00, 1.3222e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.4428e-20, 1.1521e-20, 1.0000e+00, 4.4442e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "63000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [7.8537e-21, 9.3898e-21, 1.5262e-12, 7.7346e-21],\n",
      "        [4.1595e-34, 4.3779e-34, 2.3836e-20, 4.0603e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.6753e-06, 6.5917e-07, 9.9999e-01, 2.7419e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5381e-14, 4.5341e-15, 1.0000e+00, 1.5524e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.7187e-20, 1.4830e-20, 1.0000e+00, 5.7225e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "64000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [7.7683e-21, 9.2939e-21, 1.3512e-12, 7.6501e-21],\n",
      "        [4.2685e-34, 4.4925e-34, 1.9969e-20, 4.1677e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.8053e-06, 6.9124e-07, 9.9999e-01, 2.8755e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.7868e-14, 5.2706e-15, 1.0000e+00, 1.8035e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.2272e-20, 1.8742e-20, 1.0000e+00, 7.2344e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "65000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [7.6947e-21, 9.2114e-21, 1.2081e-12, 7.5773e-21],\n",
      "        [4.3692e-34, 4.5984e-34, 1.6960e-20, 4.2668e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.9342e-06, 7.2303e-07, 9.9999e-01, 3.0079e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.0536e-14, 6.0611e-15, 1.0000e+00, 2.0730e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.9734e-20, 2.3271e-20, 1.0000e+00, 8.9853e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "66000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [7.6275e-21, 9.1358e-21, 1.0898e-12, 7.5106e-21],\n",
      "        [4.4626e-34, 4.6965e-34, 1.4592e-20, 4.3589e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.0608e-06, 7.5429e-07, 9.9999e-01, 3.1380e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.3361e-14, 6.8987e-15, 1.0000e+00, 2.3582e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0957e-19, 2.8417e-20, 1.0000e+00, 1.0975e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "67000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [7.5648e-21, 9.0652e-21, 9.9117e-13, 7.4485e-21],\n",
      "        [4.5484e-34, 4.7867e-34, 1.2705e-20, 4.4434e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.1846e-06, 7.8484e-07, 9.9999e-01, 3.2652e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.6324e-14, 7.7778e-15, 1.0000e+00, 2.6575e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3176e-19, 3.4172e-20, 1.0000e+00, 1.3200e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "68000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [7.5068e-21, 8.9998e-21, 9.0815e-13, 7.3914e-21],\n",
      "        [4.6257e-34, 4.8679e-34, 1.1180e-20, 4.5198e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.3042e-06, 8.1435e-07, 9.9999e-01, 3.3881e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.9405e-14, 8.6920e-15, 1.0000e+00, 2.9687e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5628e-19, 4.0533e-20, 1.0000e+00, 1.5661e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "69000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [7.4546e-21, 8.9408e-21, 8.3769e-13, 7.3398e-21],\n",
      "        [4.6998e-34, 4.9456e-34, 9.9365e-21, 4.5929e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.4193e-06, 8.4272e-07, 9.9999e-01, 3.5064e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.2593e-14, 9.6378e-15, 1.0000e+00, 3.2907e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.8314e-19, 4.7495e-20, 1.0000e+00, 1.8356e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "70000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [7.4084e-21, 8.8886e-21, 7.7723e-13, 7.2942e-21],\n",
      "        [4.7704e-34, 5.0198e-34, 8.9069e-21, 4.6627e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.5318e-06, 8.7043e-07, 9.9999e-01, 3.6221e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.5905e-14, 1.0621e-14, 1.0000e+00, 3.6253e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.1252e-19, 5.5111e-20, 1.0000e+00, 2.1305e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "71000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [7.3695e-21, 8.8451e-21, 7.2492e-13, 7.2556e-21],\n",
      "        [4.8409e-34, 5.0939e-34, 8.0453e-21, 4.7324e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.6413e-06, 8.9741e-07, 9.9999e-01, 3.7346e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.9322e-14, 1.1635e-14, 1.0000e+00, 3.9705e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.4439e-19, 6.3375e-20, 1.0000e+00, 2.4505e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "72000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [7.3359e-21, 8.8078e-21, 6.7933e-13, 7.2223e-21],\n",
      "        [4.9125e-34, 5.1691e-34, 7.3196e-21, 4.8030e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([3.7465e-06, 9.2334e-07, 9.9999e-01, 3.8429e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.2817e-14, 1.2673e-14, 1.0000e+00, 4.3236e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.7860e-19, 7.2245e-20, 1.0000e+00, 2.7942e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "73000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [7.3030e-21, 8.7709e-21, 6.3904e-13, 7.1897e-21],\n",
      "        [4.9811e-34, 5.2410e-34, 6.6984e-21, 4.8704e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.8490e-06, 9.4857e-07, 9.9999e-01, 3.9484e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.6400e-14, 1.3737e-14, 1.0000e+00, 4.6858e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.1526e-19, 8.1746e-20, 1.0000e+00, 3.1625e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "74000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [7.2703e-21, 8.7343e-21, 6.0310e-13, 7.1574e-21],\n",
      "        [5.0444e-34, 5.3075e-34, 6.1589e-21, 4.9329e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.9493e-06, 9.7328e-07, 9.9999e-01, 4.0516e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.0074e-14, 1.4829e-14, 1.0000e+00, 5.0572e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.5435e-19, 9.1877e-20, 1.0000e+00, 3.5554e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "75000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [7.2379e-21, 8.6975e-21, 5.7086e-13, 7.1253e-21],\n",
      "        [5.1014e-34, 5.3672e-34, 5.6857e-21, 4.9891e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.0478e-06, 9.9750e-07, 9.9999e-01, 4.1530e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.3843e-14, 1.5948e-14, 1.0000e+00, 5.4382e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.9607e-19, 1.0269e-19, 1.0000e+00, 3.9747e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "76000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [7.2055e-21, 8.6609e-21, 5.4170e-13, 7.0933e-21],\n",
      "        [5.1560e-34, 5.4245e-34, 5.2694e-21, 5.0432e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.1422e-06, 1.0207e-06, 9.9999e-01, 4.2503e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.7642e-14, 1.7077e-14, 1.0000e+00, 5.8225e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.3983e-19, 1.1402e-19, 1.0000e+00, 4.4148e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "77000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [7.1733e-21, 8.6244e-21, 5.1549e-13, 7.0616e-21],\n",
      "        [5.2079e-34, 5.4788e-34, 4.9048e-21, 5.0945e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.2352e-06, 1.0436e-06, 9.9999e-01, 4.3462e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.1531e-14, 1.8233e-14, 1.0000e+00, 6.2159e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.8619e-19, 1.2603e-19, 1.0000e+00, 4.8812e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "78000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [7.1422e-21, 8.5890e-21, 4.9160e-13, 7.0309e-21],\n",
      "        [5.2569e-34, 5.5300e-34, 4.5793e-21, 5.1429e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.3279e-06, 1.0664e-06, 9.9999e-01, 4.4418e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.5545e-14, 1.9427e-14, 1.0000e+00, 6.6220e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.3560e-19, 1.3883e-19, 1.0000e+00, 5.3784e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "79000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [7.1122e-21, 8.5550e-21, 4.6963e-13, 7.0013e-21],\n",
      "        [5.3049e-34, 5.5805e-34, 4.2866e-21, 5.1905e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.4163e-06, 1.0882e-06, 9.9999e-01, 4.5330e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.9554e-14, 2.0620e-14, 1.0000e+00, 7.0276e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.8678e-19, 1.5209e-19, 1.0000e+00, 5.8934e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "80000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [7.0839e-21, 8.5226e-21, 4.4979e-13, 6.9731e-21],\n",
      "        [5.3526e-34, 5.6304e-34, 4.0287e-21, 5.2377e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.5051e-06, 1.1101e-06, 9.9999e-01, 4.6245e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.3700e-14, 2.1854e-14, 1.0000e+00, 7.4471e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.4130e-19, 1.6622e-19, 1.0000e+00, 6.4422e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "81000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [7.0558e-21, 8.4908e-21, 4.3131e-13, 6.9456e-21],\n",
      "        [5.3998e-34, 5.6798e-34, 3.7932e-21, 5.2841e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.5907e-06, 1.1312e-06, 9.9999e-01, 4.7128e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.7859e-14, 2.3092e-14, 1.0000e+00, 7.8680e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.9758e-19, 1.8080e-19, 1.0000e+00, 7.0089e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "82000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [7.0290e-21, 8.4602e-21, 4.1444e-13, 6.9191e-21],\n",
      "        [5.4423e-34, 5.7245e-34, 3.5816e-21, 5.3264e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([4.6776e-06, 1.1526e-06, 9.9999e-01, 4.8024e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.2182e-14, 2.4378e-14, 1.0000e+00, 8.3056e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.5746e-19, 1.9632e-19, 1.0000e+00, 7.6119e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "83000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [7.0034e-21, 8.4310e-21, 3.9862e-13, 6.8938e-21],\n",
      "        [5.4817e-34, 5.7661e-34, 3.3852e-21, 5.3655e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.7599e-06, 1.1728e-06, 9.9999e-01, 4.8873e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.6455e-14, 2.5650e-14, 1.0000e+00, 8.7380e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.1851e-19, 2.1214e-19, 1.0000e+00, 8.2266e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "84000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [6.9784e-21, 8.4024e-21, 3.8421e-13, 6.8692e-21],\n",
      "        [5.5202e-34, 5.8063e-34, 3.2102e-21, 5.4035e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.8439e-06, 1.1935e-06, 9.9999e-01, 4.9738e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.0905e-14, 2.6975e-14, 1.0000e+00, 9.1881e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.8361e-19, 2.2900e-19, 1.0000e+00, 8.8819e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "85000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [6.9546e-21, 8.3753e-21, 3.7058e-13, 6.8455e-21],\n",
      "        [5.5584e-34, 5.8464e-34, 3.0471e-21, 5.4412e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.9248e-06, 1.2135e-06, 9.9999e-01, 5.0572e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.5352e-14, 2.8299e-14, 1.0000e+00, 9.6379e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.5044e-19, 2.4632e-19, 1.0000e+00, 9.5547e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "86000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [6.9307e-21, 8.3480e-21, 3.5796e-13, 6.8220e-21],\n",
      "        [5.5944e-34, 5.8841e-34, 2.8988e-21, 5.4769e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.0038e-06, 1.2329e-06, 9.9999e-01, 5.1385e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.9835e-14, 2.9634e-14, 1.0000e+00, 1.0091e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0196e-18, 2.6422e-19, 1.0000e+00, 1.0251e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "87000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [6.9069e-21, 8.3209e-21, 3.4619e-13, 6.7985e-21],\n",
      "        [5.6294e-34, 5.9209e-34, 2.7629e-21, 5.5115e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.0841e-06, 1.2527e-06, 9.9999e-01, 5.2211e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0449e-13, 3.1021e-14, 1.0000e+00, 1.0562e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0928e-18, 2.8321e-19, 1.0000e+00, 1.0989e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "88000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [6.8851e-21, 8.2961e-21, 3.3501e-13, 6.7770e-21],\n",
      "        [5.6650e-34, 5.9584e-34, 2.6355e-21, 5.5466e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.1627e-06, 1.2721e-06, 9.9999e-01, 5.3019e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0916e-13, 3.2415e-14, 1.0000e+00, 1.1034e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1681e-18, 3.0273e-19, 1.0000e+00, 1.1746e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "89000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [6.8648e-21, 8.2731e-21, 3.2468e-13, 6.7568e-21],\n",
      "        [5.7004e-34, 5.9956e-34, 2.5194e-21, 5.5817e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.2387e-06, 1.2908e-06, 9.9999e-01, 5.3799e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1382e-13, 3.3805e-14, 1.0000e+00, 1.1505e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2448e-18, 3.2261e-19, 1.0000e+00, 1.2518e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "90000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [6.8454e-21, 8.2512e-21, 3.1507e-13, 6.7377e-21],\n",
      "        [5.7332e-34, 6.0302e-34, 2.4128e-21, 5.6140e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.3161e-06, 1.3099e-06, 9.9999e-01, 5.4594e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1866e-13, 3.5247e-14, 1.0000e+00, 1.1994e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3259e-18, 3.4364e-19, 1.0000e+00, 1.3334e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "91000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [6.8273e-21, 8.2307e-21, 3.0588e-13, 6.7197e-21],\n",
      "        [5.7662e-34, 6.0649e-34, 2.3119e-21, 5.6464e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4585e-06, 3.9830e-07, 1.0000e+00, 1.5152e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.5722e-15, 8.8762e-16, 1.0000e+00, 2.6457e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.9181e-21, 1.5642e-21, 1.0000e+00, 5.0581e-21],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "92000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [2.1589e-21, 2.7281e-21, 1.2242e-12, 2.1376e-21],\n",
      "        [6.1309e-35, 7.1402e-35, 1.8182e-20, 6.0696e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([1.4398e-06, 3.9327e-07, 1.0000e+00, 1.4959e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.6129e-15, 9.0229e-16, 1.0000e+00, 2.6878e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.1669e-21, 1.6435e-21, 1.0000e+00, 5.3157e-21],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "93000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [2.1397e-21, 2.7051e-21, 1.1790e-12, 2.1184e-21],\n",
      "        [6.2566e-35, 7.2861e-35, 1.7434e-20, 6.1954e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4318e-06, 3.9116e-07, 1.0000e+00, 1.4879e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.6971e-15, 9.3202e-16, 1.0000e+00, 2.7747e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.5465e-21, 1.7645e-21, 1.0000e+00, 5.7081e-21],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "94000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [2.1208e-21, 2.6826e-21, 1.1259e-12, 2.0996e-21],\n",
      "        [6.3835e-35, 7.4336e-35, 1.6479e-20, 6.3220e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4355e-06, 3.9224e-07, 1.0000e+00, 1.4919e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.8306e-15, 9.7884e-16, 1.0000e+00, 2.9124e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.0848e-21, 1.9360e-21, 1.0000e+00, 6.2642e-21],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "95000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [2.1024e-21, 2.6607e-21, 1.0662e-12, 2.0814e-21],\n",
      "        [6.5087e-35, 7.5790e-35, 1.5355e-20, 6.4473e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4511e-06, 3.9656e-07, 1.0000e+00, 1.5082e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.0171e-15, 1.0440e-15, 1.0000e+00, 3.1046e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.8082e-21, 2.1665e-21, 1.0000e+00, 7.0109e-21],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "96000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [2.0850e-21, 2.6400e-21, 1.0027e-12, 2.0640e-21],\n",
      "        [6.6305e-35, 7.7207e-35, 1.4132e-20, 6.5693e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4771e-06, 4.0375e-07, 1.0000e+00, 1.5355e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.2558e-15, 1.1274e-15, 1.0000e+00, 3.3505e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.7318e-21, 2.4608e-21, 1.0000e+00, 7.9643e-21],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "97000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [2.0686e-21, 2.6205e-21, 9.3851e-13, 2.0478e-21],\n",
      "        [6.7458e-35, 7.8544e-35, 1.2887e-20, 6.6844e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5116e-06, 4.1325e-07, 1.0000e+00, 1.5716e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.5442e-15, 1.2279e-15, 1.0000e+00, 3.6475e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.8710e-21, 2.8237e-21, 1.0000e+00, 9.1404e-21],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "98000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [2.0535e-21, 2.6025e-21, 8.7586e-13, 2.0328e-21],\n",
      "        [6.8571e-35, 7.9838e-35, 1.1685e-20, 6.7960e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5509e-06, 4.2403e-07, 1.0000e+00, 1.6125e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.8708e-15, 1.3418e-15, 1.0000e+00, 3.9840e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0210e-20, 3.2499e-21, 1.0000e+00, 1.0523e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "99000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [2.0397e-21, 2.5860e-21, 8.1723e-13, 2.0191e-21],\n",
      "        [6.9657e-35, 8.1099e-35, 1.0582e-20, 6.9049e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5950e-06, 4.3612e-07, 1.0000e+00, 1.6586e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.2393e-15, 1.4701e-15, 1.0000e+00, 4.3636e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1774e-20, 3.7480e-21, 1.0000e+00, 1.2138e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "100000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [2.0274e-21, 2.5714e-21, 7.6281e-13, 2.0069e-21],\n",
      "        [7.0683e-35, 8.2287e-35, 9.5752e-21, 7.0076e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.6395e-06, 4.4833e-07, 1.0000e+00, 1.7051e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.6284e-15, 1.6058e-15, 1.0000e+00, 4.7646e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3506e-20, 4.2992e-21, 1.0000e+00, 1.3927e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "101000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [2.0171e-21, 2.5592e-21, 7.1452e-13, 1.9966e-21],\n",
      "        [7.1748e-35, 8.3522e-35, 8.7098e-21, 7.1141e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.6858e-06, 4.6101e-07, 1.0000e+00, 1.7534e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.0464e-15, 1.7514e-15, 1.0000e+00, 5.1951e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5445e-20, 4.9166e-21, 1.0000e+00, 1.5930e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "102000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [2.0077e-21, 2.5481e-21, 6.7073e-13, 1.9873e-21],\n",
      "        [7.2802e-35, 8.4744e-35, 7.9463e-21, 7.2194e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([1.7308e-06, 4.7334e-07, 1.0000e+00, 1.8003e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.4763e-15, 1.9013e-15, 1.0000e+00, 5.6382e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.7537e-20, 5.5826e-21, 1.0000e+00, 1.8091e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "103000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.9986e-21, 2.5373e-21, 6.3167e-13, 1.9783e-21],\n",
      "        [7.3812e-35, 8.5918e-35, 7.2849e-21, 7.3204e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.7756e-06, 4.8562e-07, 1.0000e+00, 1.8472e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.9227e-15, 2.0570e-15, 1.0000e+00, 6.0984e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.9797e-20, 6.3021e-21, 1.0000e+00, 2.0428e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "104000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.9894e-21, 2.5264e-21, 5.9644e-13, 1.9691e-21],\n",
      "        [7.4729e-35, 8.6979e-35, 6.7024e-21, 7.4120e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.8199e-06, 4.9773e-07, 1.0000e+00, 1.8934e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.3830e-15, 2.2176e-15, 1.0000e+00, 6.5729e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.2221e-20, 7.0736e-21, 1.0000e+00, 2.2933e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "105000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.9804e-21, 2.5156e-21, 5.6464e-13, 1.9601e-21],\n",
      "        [7.5569e-35, 8.7955e-35, 6.1889e-21, 7.4962e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.8634e-06, 5.0965e-07, 1.0000e+00, 1.9389e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.8562e-15, 2.3826e-15, 1.0000e+00, 7.0608e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.4815e-20, 7.8991e-21, 1.0000e+00, 2.5616e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "106000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.9714e-21, 2.5049e-21, 5.3580e-13, 1.9512e-21],\n",
      "        [7.6378e-35, 8.8892e-35, 5.7355e-21, 7.5774e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.9059e-06, 5.2129e-07, 1.0000e+00, 1.9834e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.3381e-15, 2.5508e-15, 1.0000e+00, 7.5580e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.7556e-20, 8.7711e-21, 1.0000e+00, 2.8451e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "107000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.9625e-21, 2.4941e-21, 5.0971e-13, 1.9423e-21],\n",
      "        [7.7134e-35, 8.9766e-35, 5.3351e-21, 7.6531e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.9472e-06, 5.3261e-07, 1.0000e+00, 2.0266e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.8272e-15, 2.7215e-15, 1.0000e+00, 8.0628e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.0440e-20, 9.6890e-21, 1.0000e+00, 3.1437e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "108000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.9537e-21, 2.4836e-21, 4.8604e-13, 1.9337e-21],\n",
      "        [7.7850e-35, 9.0593e-35, 4.9800e-21, 7.7251e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.9884e-06, 5.4389e-07, 1.0000e+00, 2.0697e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.3317e-15, 2.8977e-15, 1.0000e+00, 8.5835e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.3514e-20, 1.0668e-20, 1.0000e+00, 3.4621e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "109000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.9454e-21, 2.4736e-21, 4.6428e-13, 1.9255e-21],\n",
      "        [7.8557e-35, 9.1413e-35, 4.6607e-21, 7.7960e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.0279e-06, 5.5474e-07, 1.0000e+00, 2.1111e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.8386e-15, 3.0749e-15, 1.0000e+00, 9.1067e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.6715e-20, 1.1687e-20, 1.0000e+00, 3.7935e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "110000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.9374e-21, 2.4639e-21, 4.4452e-13, 1.9175e-21],\n",
      "        [7.9264e-35, 9.2232e-35, 4.3781e-21, 7.8669e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.0673e-06, 5.6553e-07, 1.0000e+00, 2.1524e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.3590e-15, 3.2568e-15, 1.0000e+00, 9.6438e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.0101e-20, 1.2765e-20, 1.0000e+00, 4.1441e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "111000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.9297e-21, 2.4547e-21, 4.2626e-13, 1.9099e-21],\n",
      "        [7.9943e-35, 9.3020e-35, 4.1213e-21, 7.9351e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.1057e-06, 5.7605e-07, 1.0000e+00, 2.1925e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.8850e-15, 3.4406e-15, 1.0000e+00, 1.0187e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.3614e-20, 1.3883e-20, 1.0000e+00, 4.5079e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "112000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.9224e-21, 2.4458e-21, 4.0951e-13, 1.9026e-21],\n",
      "        [8.0547e-35, 9.3723e-35, 3.8888e-21, 7.9959e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([2.1444e-06, 5.8665e-07, 9.9999e-01, 2.2330e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0428e-14, 3.6303e-15, 1.0000e+00, 1.0747e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.7326e-20, 1.5065e-20, 1.0000e+00, 4.8925e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "113000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.9154e-21, 2.4375e-21, 3.9389e-13, 1.8957e-21],\n",
      "        [8.1104e-35, 9.4367e-35, 3.6749e-21, 8.0518e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.1815e-06, 5.9682e-07, 9.9999e-01, 2.2718e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0969e-14, 3.8196e-15, 1.0000e+00, 1.1306e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.1136e-20, 1.6277e-20, 1.0000e+00, 5.2873e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "114000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.9086e-21, 2.4293e-21, 3.7958e-13, 1.8889e-21],\n",
      "        [8.1633e-35, 9.4978e-35, 3.4825e-21, 8.1046e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.2194e-06, 6.0722e-07, 9.9999e-01, 2.3115e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1532e-14, 4.0168e-15, 1.0000e+00, 1.1887e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.5195e-20, 1.7570e-20, 1.0000e+00, 5.7077e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "115000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.9020e-21, 2.4213e-21, 3.6604e-13, 1.8824e-21],\n",
      "        [8.2144e-35, 9.5570e-35, 3.3030e-21, 8.1557e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.2554e-06, 6.1708e-07, 9.9999e-01, 2.3491e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2089e-14, 4.2116e-15, 1.0000e+00, 1.2462e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.9318e-20, 1.8883e-20, 1.0000e+00, 6.1349e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "116000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8955e-21, 2.4134e-21, 3.5362e-13, 1.8759e-21],\n",
      "        [8.2632e-35, 9.6137e-35, 3.1417e-21, 8.2048e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.2908e-06, 6.2680e-07, 9.9999e-01, 2.3862e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2655e-14, 4.4097e-15, 1.0000e+00, 1.3046e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.3623e-20, 2.0252e-20, 1.0000e+00, 6.5806e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "117000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8891e-21, 2.4057e-21, 3.4195e-13, 1.8696e-21],\n",
      "        [8.3111e-35, 9.6693e-35, 2.9926e-21, 8.2530e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.3271e-06, 6.3675e-07, 9.9999e-01, 2.4241e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3245e-14, 4.6161e-15, 1.0000e+00, 1.3654e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.8193e-20, 2.1708e-20, 1.0000e+00, 7.0541e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "118000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8831e-21, 2.3985e-21, 3.3085e-13, 1.8636e-21],\n",
      "        [8.3591e-35, 9.7246e-35, 2.8525e-21, 8.3007e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.3620e-06, 6.4637e-07, 9.9999e-01, 2.4605e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3828e-14, 4.8205e-15, 1.0000e+00, 1.4255e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.2815e-20, 2.3181e-20, 1.0000e+00, 7.5328e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "119000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8775e-21, 2.3918e-21, 3.2071e-13, 1.8580e-21],\n",
      "        [8.4047e-35, 9.7778e-35, 2.7264e-21, 8.3466e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.3964e-06, 6.5579e-07, 9.9999e-01, 2.4963e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4418e-14, 5.0274e-15, 1.0000e+00, 1.4864e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.7594e-20, 2.4703e-20, 1.0000e+00, 8.0273e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "120000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8723e-21, 2.3856e-21, 3.1118e-13, 1.8529e-21],\n",
      "        [8.4492e-35, 9.8294e-35, 2.6094e-21, 8.3909e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.4316e-06, 6.6548e-07, 9.9999e-01, 2.5331e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5032e-14, 5.2426e-15, 1.0000e+00, 1.5497e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.2658e-20, 2.6317e-20, 1.0000e+00, 8.5518e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "121000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8675e-21, 2.3799e-21, 3.0210e-13, 1.8481e-21],\n",
      "        [8.4963e-35, 9.8841e-35, 2.4994e-21, 8.4379e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.4676e-06, 6.7537e-07, 9.9999e-01, 2.5706e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5670e-14, 5.4663e-15, 1.0000e+00, 1.6154e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.8021e-20, 2.8026e-20, 1.0000e+00, 9.1071e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "122000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8630e-21, 2.3745e-21, 2.9338e-13, 1.8436e-21],\n",
      "        [8.5442e-35, 9.9399e-35, 2.3953e-21, 8.4860e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([2.4999e-06, 6.8428e-07, 9.9999e-01, 2.6044e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.6276e-14, 5.6791e-15, 1.0000e+00, 1.6779e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.3274e-20, 2.9701e-20, 1.0000e+00, 9.6511e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "123000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8592e-21, 2.3699e-21, 2.8556e-13, 1.8398e-21],\n",
      "        [8.5968e-35, 1.0001e-34, 2.3041e-21, 8.5382e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.5327e-06, 6.9331e-07, 9.9999e-01, 2.6386e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.6901e-14, 5.8984e-15, 1.0000e+00, 1.7423e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.8775e-20, 3.1454e-20, 1.0000e+00, 1.0221e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "124000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8557e-21, 2.3659e-21, 2.7810e-13, 1.8363e-21],\n",
      "        [8.6487e-35, 1.0061e-34, 2.2177e-21, 8.5903e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.5661e-06, 7.0247e-07, 9.9999e-01, 2.6734e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.7547e-14, 6.1252e-15, 1.0000e+00, 1.8090e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0456e-19, 3.3297e-20, 1.0000e+00, 1.0819e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "125000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8526e-21, 2.3622e-21, 2.7092e-13, 1.8332e-21],\n",
      "        [8.7003e-35, 1.0121e-34, 2.1353e-21, 8.6415e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.5998e-06, 7.1173e-07, 9.9999e-01, 2.7086e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.8212e-14, 6.3584e-15, 1.0000e+00, 1.8775e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1060e-19, 3.5225e-20, 1.0000e+00, 1.1446e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "126000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8497e-21, 2.3588e-21, 2.6405e-13, 1.8303e-21],\n",
      "        [8.7516e-35, 1.0181e-34, 2.0571e-21, 8.6927e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.6335e-06, 7.2100e-07, 9.9999e-01, 2.7438e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.8894e-14, 6.5978e-15, 1.0000e+00, 1.9479e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1692e-19, 3.7238e-20, 1.0000e+00, 1.2100e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "127000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8473e-21, 2.3562e-21, 2.5748e-13, 1.8279e-21],\n",
      "        [8.8039e-35, 1.0241e-34, 1.9830e-21, 8.7450e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.6637e-06, 7.2932e-07, 9.9999e-01, 2.7753e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.9541e-14, 6.8248e-15, 1.0000e+00, 2.0146e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2304e-19, 3.9187e-20, 1.0000e+00, 1.2734e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "128000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8456e-21, 2.3542e-21, 2.5158e-13, 1.8262e-21],\n",
      "        [8.8551e-35, 1.0301e-34, 1.9171e-21, 8.7961e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.6943e-06, 7.3771e-07, 9.9999e-01, 2.8072e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.0203e-14, 7.0571e-15, 1.0000e+00, 2.0828e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2939e-19, 4.1209e-20, 1.0000e+00, 1.3391e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "129000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8438e-21, 2.3523e-21, 2.4590e-13, 1.8245e-21],\n",
      "        [8.9041e-35, 1.0358e-34, 1.8542e-21, 8.8450e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.7252e-06, 7.4620e-07, 9.9999e-01, 2.8394e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.0884e-14, 7.2963e-15, 1.0000e+00, 2.1531e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3603e-19, 4.3327e-20, 1.0000e+00, 1.4080e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "130000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8425e-21, 2.3508e-21, 2.4043e-13, 1.8231e-21],\n",
      "        [8.9561e-35, 1.0418e-34, 1.7942e-21, 8.8967e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.7570e-06, 7.5493e-07, 9.9999e-01, 2.8726e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.1592e-14, 7.5447e-15, 1.0000e+00, 2.2261e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4303e-19, 4.5558e-20, 1.0000e+00, 1.4805e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "131000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8419e-21, 2.3504e-21, 2.3518e-13, 1.8225e-21],\n",
      "        [9.0138e-35, 1.0485e-34, 1.7374e-21, 8.9543e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.7896e-06, 7.6388e-07, 9.9999e-01, 2.9067e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.2324e-14, 7.8016e-15, 1.0000e+00, 2.3015e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5036e-19, 4.7892e-20, 1.0000e+00, 1.5564e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "132000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8415e-21, 2.3501e-21, 2.3011e-13, 1.8221e-21],\n",
      "        [9.0703e-35, 1.0550e-34, 1.6828e-21, 9.0106e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([2.8226e-06, 7.7296e-07, 9.9999e-01, 2.9411e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.3078e-14, 8.0660e-15, 1.0000e+00, 2.3793e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5801e-19, 5.0331e-20, 1.0000e+00, 1.6356e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "133000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8412e-21, 2.3499e-21, 2.2519e-13, 1.8217e-21],\n",
      "        [9.1260e-35, 1.0615e-34, 1.6303e-21, 9.0662e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.8528e-06, 7.8125e-07, 9.9999e-01, 2.9727e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.3799e-14, 8.3190e-15, 1.0000e+00, 2.4536e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.6549e-19, 5.2715e-20, 1.0000e+00, 1.7132e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "134000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8408e-21, 2.3497e-21, 2.2066e-13, 1.8213e-21],\n",
      "        [9.1806e-35, 1.0679e-34, 1.5826e-21, 9.1206e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.8815e-06, 7.8912e-07, 9.9999e-01, 3.0026e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.4506e-14, 8.5673e-15, 1.0000e+00, 2.5265e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.7298e-19, 5.5101e-20, 1.0000e+00, 1.7907e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "135000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8404e-21, 2.3495e-21, 2.1641e-13, 1.8210e-21],\n",
      "        [9.2355e-35, 1.0742e-34, 1.5385e-21, 9.1754e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.9104e-06, 7.9707e-07, 9.9999e-01, 3.0328e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.5230e-14, 8.8215e-15, 1.0000e+00, 2.6012e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.8075e-19, 5.7578e-20, 1.0000e+00, 1.8713e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "136000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8401e-21, 2.3492e-21, 2.1226e-13, 1.8206e-21],\n",
      "        [9.2903e-35, 1.0806e-34, 1.4959e-21, 9.2299e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.9396e-06, 8.0508e-07, 9.9999e-01, 3.0633e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.5968e-14, 9.0807e-15, 1.0000e+00, 2.6774e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.8878e-19, 6.0135e-20, 1.0000e+00, 1.9545e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "137000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8397e-21, 2.3490e-21, 2.0826e-13, 1.8202e-21],\n",
      "        [9.3443e-35, 1.0868e-34, 1.4550e-21, 9.2835e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.9692e-06, 8.1320e-07, 9.9999e-01, 3.0942e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.6727e-14, 9.3470e-15, 1.0000e+00, 2.7556e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.9714e-19, 6.2797e-20, 1.0000e+00, 2.0410e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "138000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8394e-21, 2.3487e-21, 2.0434e-13, 1.8198e-21],\n",
      "        [9.3973e-35, 1.0930e-34, 1.4154e-21, 9.3363e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.9989e-06, 8.2137e-07, 9.9999e-01, 3.1252e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.7501e-14, 9.6189e-15, 1.0000e+00, 2.8354e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.0579e-19, 6.5553e-20, 1.0000e+00, 2.1306e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "139000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8390e-21, 2.3485e-21, 2.0054e-13, 1.8194e-21],\n",
      "        [9.4503e-35, 1.0991e-34, 1.3772e-21, 9.3890e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.0294e-06, 8.2973e-07, 9.9999e-01, 3.1571e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.8300e-14, 9.8993e-15, 1.0000e+00, 2.9178e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.1482e-19, 6.8430e-20, 1.0000e+00, 2.2242e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "140000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8386e-21, 2.3482e-21, 1.9682e-13, 1.8190e-21],\n",
      "        [9.5030e-35, 1.1052e-34, 1.3402e-21, 9.4416e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.0605e-06, 8.3827e-07, 9.9999e-01, 3.1896e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.9123e-14, 1.0188e-14, 1.0000e+00, 3.0026e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.2422e-19, 7.1424e-20, 1.0000e+00, 2.3216e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "141000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8383e-21, 2.3479e-21, 1.9319e-13, 1.8187e-21],\n",
      "        [9.5554e-35, 1.1113e-34, 1.3043e-21, 9.4935e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.0919e-06, 8.4688e-07, 9.9999e-01, 3.2223e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.9961e-14, 1.0483e-14, 1.0000e+00, 3.0891e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.3392e-19, 7.4515e-20, 1.0000e+00, 2.4222e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "142000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8379e-21, 2.3477e-21, 1.8967e-13, 1.8183e-21],\n",
      "        [9.6058e-35, 1.1172e-34, 1.2697e-21, 9.5439e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([3.1196e-06, 8.5449e-07, 9.9999e-01, 3.2513e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.0741e-14, 1.0756e-14, 1.0000e+00, 3.1695e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.4314e-19, 7.7454e-20, 1.0000e+00, 2.5177e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "143000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8376e-21, 2.3474e-21, 1.8648e-13, 1.8179e-21],\n",
      "        [9.6556e-35, 1.1229e-34, 1.2389e-21, 9.5935e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.1460e-06, 8.6175e-07, 9.9999e-01, 3.2788e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.1507e-14, 1.1026e-14, 1.0000e+00, 3.2485e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.5237e-19, 8.0393e-20, 1.0000e+00, 2.6133e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "144000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8372e-21, 2.3472e-21, 1.8345e-13, 1.8175e-21],\n",
      "        [9.7056e-35, 1.1287e-34, 1.2099e-21, 9.6433e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.1726e-06, 8.6902e-07, 9.9999e-01, 3.3065e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.2287e-14, 1.1300e-14, 1.0000e+00, 3.3289e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.6186e-19, 8.3417e-20, 1.0000e+00, 2.7117e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "145000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8368e-21, 2.3469e-21, 1.8049e-13, 1.8172e-21],\n",
      "        [9.7550e-35, 1.1345e-34, 1.1819e-21, 9.6924e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.1991e-06, 8.7631e-07, 9.9999e-01, 3.3342e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.3080e-14, 1.1578e-14, 1.0000e+00, 3.4107e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.7165e-19, 8.6534e-20, 1.0000e+00, 2.8131e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "146000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8365e-21, 2.3466e-21, 1.7760e-13, 1.8167e-21],\n",
      "        [9.8044e-35, 1.1402e-34, 1.1546e-21, 9.7416e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.2258e-06, 8.8364e-07, 9.9999e-01, 3.3621e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.3890e-14, 1.1863e-14, 1.0000e+00, 3.4941e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.8174e-19, 8.9748e-20, 1.0000e+00, 2.9177e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "147000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8361e-21, 2.3463e-21, 1.7478e-13, 1.8164e-21],\n",
      "        [9.8537e-35, 1.1459e-34, 1.1282e-21, 9.7907e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.2523e-06, 8.9092e-07, 9.9999e-01, 3.3898e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.4707e-14, 1.2150e-14, 1.0000e+00, 3.5784e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.9207e-19, 9.3041e-20, 1.0000e+00, 3.0247e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "148000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8358e-21, 2.3460e-21, 1.7203e-13, 1.8160e-21],\n",
      "        [9.9029e-35, 1.1516e-34, 1.1027e-21, 9.8398e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.2789e-06, 8.9821e-07, 9.9999e-01, 3.4175e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.5538e-14, 1.2442e-14, 1.0000e+00, 3.6641e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.0271e-19, 9.6428e-20, 1.0000e+00, 3.1350e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "149000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8354e-21, 2.3457e-21, 1.6934e-13, 1.8156e-21],\n",
      "        [9.9521e-35, 1.1573e-34, 1.0780e-21, 9.8887e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.3060e-06, 9.0564e-07, 9.9999e-01, 3.4457e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.6390e-14, 1.2742e-14, 1.0000e+00, 3.7519e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.1370e-19, 9.9928e-20, 1.0000e+00, 3.2488e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "150000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8351e-21, 2.3455e-21, 1.6671e-13, 1.8152e-21],\n",
      "        [9.9996e-35, 1.1628e-34, 1.0539e-21, 9.9360e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.3335e-06, 9.1319e-07, 9.9999e-01, 3.4744e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.7264e-14, 1.3049e-14, 1.0000e+00, 3.8420e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.2509e-19, 1.0356e-19, 1.0000e+00, 3.3668e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "151000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8348e-21, 2.3452e-21, 1.6413e-13, 1.8149e-21],\n",
      "        [1.0048e-34, 1.1683e-34, 1.0303e-21, 9.9837e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.3612e-06, 9.2078e-07, 9.9999e-01, 3.5033e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.8157e-14, 1.3362e-14, 1.0000e+00, 3.9340e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.3687e-19, 1.0731e-19, 1.0000e+00, 3.4889e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "152000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8344e-21, 2.3450e-21, 1.6160e-13, 1.8146e-21],\n",
      "        [1.0096e-34, 1.1740e-34, 1.0074e-21, 1.0032e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([3.3891e-06, 9.2842e-07, 9.9999e-01, 3.5324e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.9068e-14, 1.3682e-14, 1.0000e+00, 4.0279e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.4902e-19, 1.1118e-19, 1.0000e+00, 3.6149e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "153000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8342e-21, 2.3449e-21, 1.5912e-13, 1.8144e-21],\n",
      "        [1.0145e-34, 1.1796e-34, 9.8508e-22, 1.0081e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.4172e-06, 9.3614e-07, 9.9999e-01, 3.5618e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.9997e-14, 1.4009e-14, 1.0000e+00, 4.1236e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.6154e-19, 1.1516e-19, 1.0000e+00, 3.7445e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "154000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8340e-21, 2.3448e-21, 1.5669e-13, 1.8141e-21],\n",
      "        [1.0192e-34, 1.1851e-34, 9.6339e-22, 1.0128e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.4454e-06, 9.4386e-07, 9.9999e-01, 3.5912e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.0937e-14, 1.4339e-14, 1.0000e+00, 4.2206e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.7435e-19, 1.1924e-19, 1.0000e+00, 3.8773e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "155000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8338e-21, 2.3447e-21, 1.5434e-13, 1.8139e-21],\n",
      "        [1.0239e-34, 1.1905e-34, 9.4239e-22, 1.0174e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.4681e-06, 9.5006e-07, 9.9999e-01, 3.6148e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.1757e-14, 1.4628e-14, 1.0000e+00, 4.3052e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.8583e-19, 1.2290e-19, 1.0000e+00, 3.9963e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "156000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8336e-21, 2.3446e-21, 1.5228e-13, 1.8136e-21],\n",
      "        [1.0285e-34, 1.1959e-34, 9.2448e-22, 1.0220e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.4903e-06, 9.5617e-07, 9.9999e-01, 3.6380e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.2577e-14, 1.4916e-14, 1.0000e+00, 4.3896e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.9743e-19, 1.2659e-19, 1.0000e+00, 4.1164e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "157000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8334e-21, 2.3445e-21, 1.5030e-13, 1.8135e-21],\n",
      "        [1.0331e-34, 1.2012e-34, 9.0731e-22, 1.0266e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.5132e-06, 9.6243e-07, 9.9999e-01, 3.6619e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.3416e-14, 1.5211e-14, 1.0000e+00, 4.4761e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.0937e-19, 1.3039e-19, 1.0000e+00, 4.2402e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "158000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8333e-21, 2.3446e-21, 1.4835e-13, 1.8133e-21],\n",
      "        [1.0377e-34, 1.2065e-34, 8.9052e-22, 1.0312e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.5364e-06, 9.6879e-07, 9.9999e-01, 3.6861e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.4272e-14, 1.5512e-14, 1.0000e+00, 4.5643e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.2166e-19, 1.3430e-19, 1.0000e+00, 4.3676e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "159000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8332e-21, 2.3446e-21, 1.4644e-13, 1.8132e-21],\n",
      "        [1.0422e-34, 1.2118e-34, 8.7410e-22, 1.0357e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.5598e-06, 9.7519e-07, 9.9999e-01, 3.7105e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.5143e-14, 1.5818e-14, 1.0000e+00, 4.6541e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.3429e-19, 1.3832e-19, 1.0000e+00, 4.4984e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "160000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8331e-21, 2.3446e-21, 1.4455e-13, 1.8131e-21],\n",
      "        [1.0468e-34, 1.2170e-34, 8.5801e-22, 1.0402e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.5834e-06, 9.8165e-07, 9.9999e-01, 3.7351e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.6032e-14, 1.6130e-14, 1.0000e+00, 4.7457e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.4730e-19, 1.4246e-19, 1.0000e+00, 4.6332e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "161000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8330e-21, 2.3447e-21, 1.4269e-13, 1.8130e-21],\n",
      "        [1.0513e-34, 1.2223e-34, 8.4224e-22, 1.0448e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.6073e-06, 9.8819e-07, 9.9999e-01, 3.7599e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.6940e-14, 1.6449e-14, 1.0000e+00, 4.8392e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.6071e-19, 1.4673e-19, 1.0000e+00, 4.7720e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "162000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8330e-21, 2.3448e-21, 1.4087e-13, 1.8130e-21],\n",
      "        [1.0559e-34, 1.2276e-34, 8.2681e-22, 1.0494e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([3.6314e-06, 9.9479e-07, 9.9999e-01, 3.7851e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.7860e-14, 1.6773e-14, 1.0000e+00, 4.9341e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.7441e-19, 1.5109e-19, 1.0000e+00, 4.9142e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "163000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8330e-21, 2.3450e-21, 1.3908e-13, 1.8130e-21],\n",
      "        [1.0605e-34, 1.2330e-34, 8.1179e-22, 1.0539e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.6555e-06, 1.0014e-06, 9.9999e-01, 3.8102e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.8787e-14, 1.7099e-14, 1.0000e+00, 5.0296e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.8832e-19, 1.5552e-19, 1.0000e+00, 5.0583e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "164000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8330e-21, 2.3451e-21, 1.3734e-13, 1.8129e-21],\n",
      "        [1.0650e-34, 1.2382e-34, 7.9728e-22, 1.0584e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.6801e-06, 1.0081e-06, 9.9999e-01, 3.8358e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.9732e-14, 1.7431e-14, 1.0000e+00, 5.1270e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.0256e-19, 1.6006e-19, 1.0000e+00, 5.2058e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "165000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8330e-21, 2.3452e-21, 1.3564e-13, 1.8129e-21],\n",
      "        [1.0693e-34, 1.2431e-34, 7.8297e-22, 1.0626e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.7049e-06, 1.0149e-06, 9.9999e-01, 3.8617e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.0695e-14, 1.7770e-14, 1.0000e+00, 5.2262e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.1718e-19, 1.6471e-19, 1.0000e+00, 5.3575e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "166000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8330e-21, 2.3454e-21, 1.3396e-13, 1.8129e-21],\n",
      "        [1.0734e-34, 1.2479e-34, 7.6894e-22, 1.0667e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.7300e-06, 1.0218e-06, 9.9999e-01, 3.8880e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.1675e-14, 1.8114e-14, 1.0000e+00, 5.3272e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.3218e-19, 1.6949e-19, 1.0000e+00, 5.5128e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "167000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8329e-21, 2.3455e-21, 1.3231e-13, 1.8129e-21],\n",
      "        [1.0775e-34, 1.2526e-34, 7.5519e-22, 1.0708e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.7553e-06, 1.0287e-06, 9.9999e-01, 3.9144e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.2668e-14, 1.8463e-14, 1.0000e+00, 5.4296e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.4752e-19, 1.7437e-19, 1.0000e+00, 5.6718e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "168000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8330e-21, 2.3457e-21, 1.3069e-13, 1.8129e-21],\n",
      "        [1.0815e-34, 1.2573e-34, 7.4181e-22, 1.0748e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.7809e-06, 1.0357e-06, 9.9999e-01, 3.9410e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.3682e-14, 1.8820e-14, 1.0000e+00, 5.5342e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.6328e-19, 1.7938e-19, 1.0000e+00, 5.8350e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "169000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8330e-21, 2.3459e-21, 1.2910e-13, 1.8129e-21],\n",
      "        [1.0856e-34, 1.2620e-34, 7.2865e-22, 1.0788e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.8068e-06, 1.0428e-06, 9.9999e-01, 3.9680e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.4716e-14, 1.9183e-14, 1.0000e+00, 5.6406e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.7949e-19, 1.8454e-19, 1.0000e+00, 6.0030e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "170000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8331e-21, 2.3461e-21, 1.2754e-13, 1.8130e-21],\n",
      "        [1.0896e-34, 1.2667e-34, 7.1577e-22, 1.0829e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.8331e-06, 1.0500e-06, 9.9999e-01, 3.9954e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.5772e-14, 1.9554e-14, 1.0000e+00, 5.7494e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.9616e-19, 1.8985e-19, 1.0000e+00, 6.1759e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "171000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8332e-21, 2.3464e-21, 1.2599e-13, 1.8130e-21],\n",
      "        [1.0936e-34, 1.2713e-34, 7.0313e-22, 1.0869e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.8598e-06, 1.0573e-06, 9.9999e-01, 4.0232e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.6849e-14, 1.9933e-14, 1.0000e+00, 5.8605e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.1331e-19, 1.9531e-19, 1.0000e+00, 6.3535e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "172000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8333e-21, 2.3466e-21, 1.2447e-13, 1.8131e-21],\n",
      "        [1.0976e-34, 1.2760e-34, 6.9074e-22, 1.0908e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([3.8867e-06, 1.0647e-06, 9.9999e-01, 4.0513e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.7943e-14, 2.0317e-14, 1.0000e+00, 5.9732e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.3088e-19, 2.0089e-19, 1.0000e+00, 6.5355e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "173000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8333e-21, 2.3468e-21, 1.2298e-13, 1.8132e-21],\n",
      "        [1.1015e-34, 1.2805e-34, 6.7865e-22, 1.0948e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.9138e-06, 1.0721e-06, 9.9999e-01, 4.0796e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.9056e-14, 2.0708e-14, 1.0000e+00, 6.0879e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.4887e-19, 2.0662e-19, 1.0000e+00, 6.7220e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "174000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8334e-21, 2.3470e-21, 1.2151e-13, 1.8132e-21],\n",
      "        [1.1054e-34, 1.2850e-34, 6.6678e-22, 1.0986e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.9411e-06, 1.0795e-06, 9.9999e-01, 4.1080e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.0186e-14, 2.1105e-14, 1.0000e+00, 6.2042e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.6729e-19, 2.1248e-19, 1.0000e+00, 6.9130e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "175000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8335e-21, 2.3472e-21, 1.2006e-13, 1.8133e-21],\n",
      "        [1.1093e-34, 1.2896e-34, 6.5519e-22, 1.1025e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.9640e-06, 1.0858e-06, 9.9999e-01, 4.1318e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.1188e-14, 2.1458e-14, 1.0000e+00, 6.3075e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.8403e-19, 2.1780e-19, 1.0000e+00, 7.0863e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "176000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8335e-21, 2.3474e-21, 1.1878e-13, 1.8133e-21],\n",
      "        [1.1133e-34, 1.2942e-34, 6.4515e-22, 1.1064e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.9845e-06, 1.0914e-06, 9.9999e-01, 4.1533e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.2127e-14, 2.1788e-14, 1.0000e+00, 6.4043e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.9996e-19, 2.2287e-19, 1.0000e+00, 7.2514e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "177000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8336e-21, 2.3476e-21, 1.1760e-13, 1.8133e-21],\n",
      "        [1.1172e-34, 1.2987e-34, 6.3597e-22, 1.1104e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.0053e-06, 1.0971e-06, 9.9999e-01, 4.1749e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.3079e-14, 2.2122e-14, 1.0000e+00, 6.5023e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.1620e-19, 2.2804e-19, 1.0000e+00, 7.4197e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "178000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8337e-21, 2.3478e-21, 1.1643e-13, 1.8134e-21],\n",
      "        [1.1211e-34, 1.3033e-34, 6.2699e-22, 1.1143e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.0262e-06, 1.1028e-06, 9.9999e-01, 4.1966e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.4041e-14, 2.2460e-14, 1.0000e+00, 6.6014e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.3273e-19, 2.3329e-19, 1.0000e+00, 7.5909e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "179000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8337e-21, 2.3480e-21, 1.1528e-13, 1.8134e-21],\n",
      "        [1.1250e-34, 1.3078e-34, 6.1820e-22, 1.1182e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.0471e-06, 1.1085e-06, 9.9999e-01, 4.2184e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.5015e-14, 2.2803e-14, 1.0000e+00, 6.7018e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.4962e-19, 2.3866e-19, 1.0000e+00, 7.7659e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "180000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8338e-21, 2.3482e-21, 1.1415e-13, 1.8134e-21],\n",
      "        [1.1290e-34, 1.3123e-34, 6.0954e-22, 1.1221e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.0681e-06, 1.1142e-06, 9.9999e-01, 4.2403e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.6002e-14, 2.3150e-14, 1.0000e+00, 6.8034e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.6683e-19, 2.4413e-19, 1.0000e+00, 7.9444e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "181000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8338e-21, 2.3483e-21, 1.1303e-13, 1.8135e-21],\n",
      "        [1.1329e-34, 1.3169e-34, 6.0102e-22, 1.1260e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.0892e-06, 1.1200e-06, 9.9999e-01, 4.2623e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.6997e-14, 2.3499e-14, 1.0000e+00, 6.9060e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.8434e-19, 2.4970e-19, 1.0000e+00, 8.1257e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "182000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8338e-21, 2.3485e-21, 1.1193e-13, 1.8135e-21],\n",
      "        [1.1368e-34, 1.3214e-34, 5.9268e-22, 1.1299e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([4.1102e-06, 1.1257e-06, 9.9999e-01, 4.2842e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.8004e-14, 2.3854e-14, 1.0000e+00, 7.0097e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.0218e-19, 2.5537e-19, 1.0000e+00, 8.3107e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "183000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8339e-21, 2.3486e-21, 1.1084e-13, 1.8136e-21],\n",
      "        [1.1407e-34, 1.3259e-34, 5.8449e-22, 1.1338e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.1313e-06, 1.1315e-06, 9.9999e-01, 4.3062e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.9023e-14, 2.4211e-14, 1.0000e+00, 7.1146e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.2036e-19, 2.6115e-19, 1.0000e+00, 8.4991e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "184000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8340e-21, 2.3489e-21, 1.0977e-13, 1.8136e-21],\n",
      "        [1.1447e-34, 1.3305e-34, 5.7646e-22, 1.1377e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.1525e-06, 1.1373e-06, 9.9999e-01, 4.3283e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.0053e-14, 2.4574e-14, 1.0000e+00, 7.2209e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.3890e-19, 2.6705e-19, 1.0000e+00, 8.6912e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "185000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8340e-21, 2.3490e-21, 1.0871e-13, 1.8137e-21],\n",
      "        [1.1486e-34, 1.3351e-34, 5.6856e-22, 1.1417e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.1742e-06, 1.1432e-06, 9.9999e-01, 4.3509e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.1104e-14, 2.4943e-14, 1.0000e+00, 7.3291e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.5789e-19, 2.7309e-19, 1.0000e+00, 8.8879e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "186000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8341e-21, 2.3493e-21, 1.0767e-13, 1.8137e-21],\n",
      "        [1.1526e-34, 1.3396e-34, 5.6079e-22, 1.1456e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.1960e-06, 1.1491e-06, 9.9999e-01, 4.3736e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.2169e-14, 2.5318e-14, 1.0000e+00, 7.4388e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.7723e-19, 2.7924e-19, 1.0000e+00, 9.0885e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "187000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8341e-21, 2.3494e-21, 1.0664e-13, 1.8137e-21],\n",
      "        [1.1564e-34, 1.3441e-34, 5.5313e-22, 1.1494e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.2180e-06, 1.1551e-06, 9.9999e-01, 4.3965e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.3247e-14, 2.5696e-14, 1.0000e+00, 7.5497e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.9695e-19, 2.8550e-19, 1.0000e+00, 9.2926e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "188000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8341e-21, 2.3496e-21, 1.0562e-13, 1.8137e-21],\n",
      "        [1.1602e-34, 1.3485e-34, 5.4560e-22, 1.1532e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.2403e-06, 1.1612e-06, 9.9999e-01, 4.4197e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.4340e-14, 2.6081e-14, 1.0000e+00, 7.6625e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.1706e-19, 2.9190e-19, 1.0000e+00, 9.5011e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "189000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8342e-21, 2.3497e-21, 1.0462e-13, 1.8138e-21],\n",
      "        [1.1640e-34, 1.3529e-34, 5.3821e-22, 1.1570e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.2627e-06, 1.1674e-06, 9.9999e-01, 4.4431e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.5447e-14, 2.6471e-14, 1.0000e+00, 7.7765e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.3754e-19, 2.9842e-19, 1.0000e+00, 9.7133e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "190000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8342e-21, 2.3499e-21, 1.0363e-13, 1.8138e-21],\n",
      "        [1.1677e-34, 1.3571e-34, 5.3091e-22, 1.1606e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.2854e-06, 1.1736e-06, 9.9999e-01, 4.4667e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.6573e-14, 2.6867e-14, 1.0000e+00, 7.8926e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.5847e-19, 3.0506e-19, 1.0000e+00, 9.9302e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "191000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8343e-21, 2.3501e-21, 1.0265e-13, 1.8139e-21],\n",
      "        [1.1713e-34, 1.3613e-34, 5.2370e-22, 1.1643e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.3081e-06, 1.1798e-06, 9.9999e-01, 4.4904e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.7711e-14, 2.7267e-14, 1.0000e+00, 8.0098e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.7973e-19, 3.1183e-19, 1.0000e+00, 1.0151e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "192000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8343e-21, 2.3503e-21, 1.0169e-13, 1.8139e-21],\n",
      "        [1.1749e-34, 1.3655e-34, 5.1663e-22, 1.1678e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([4.3309e-06, 1.1860e-06, 9.9999e-01, 4.5141e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.8857e-14, 2.7670e-14, 1.0000e+00, 8.1278e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0013e-18, 3.1869e-19, 1.0000e+00, 1.0374e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "193000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8344e-21, 2.3504e-21, 1.0075e-13, 1.8140e-21],\n",
      "        [1.1785e-34, 1.3696e-34, 5.0970e-22, 1.1714e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.3538e-06, 1.1923e-06, 9.9999e-01, 4.5380e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.0017e-14, 2.8078e-14, 1.0000e+00, 8.2472e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0233e-18, 3.2568e-19, 1.0000e+00, 1.0602e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "194000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8344e-21, 2.3506e-21, 9.9815e-14, 1.8140e-21],\n",
      "        [1.1821e-34, 1.3737e-34, 5.0292e-22, 1.1750e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.3774e-06, 1.1987e-06, 9.9999e-01, 4.5626e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.1203e-14, 2.8495e-14, 1.0000e+00, 8.3695e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0459e-18, 3.3286e-19, 1.0000e+00, 1.0836e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "195000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8345e-21, 2.3507e-21, 9.8892e-14, 1.8140e-21],\n",
      "        [1.1856e-34, 1.3779e-34, 4.9623e-22, 1.1785e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.4015e-06, 1.2053e-06, 9.9999e-01, 4.5877e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.2413e-14, 2.8921e-14, 1.0000e+00, 8.4942e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0690e-18, 3.4023e-19, 1.0000e+00, 1.1076e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "196000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8345e-21, 2.3509e-21, 9.7980e-14, 1.8140e-21],\n",
      "        [1.1892e-34, 1.3821e-34, 4.8963e-22, 1.1821e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.4258e-06, 1.2120e-06, 9.9999e-01, 4.6132e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.3640e-14, 2.9353e-14, 1.0000e+00, 8.6207e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0927e-18, 3.4774e-19, 1.0000e+00, 1.1321e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "197000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8346e-21, 2.3511e-21, 9.7078e-14, 1.8141e-21],\n",
      "        [1.1927e-34, 1.3862e-34, 4.8314e-22, 1.1856e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.4504e-06, 1.2188e-06, 9.9999e-01, 4.6388e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.4887e-14, 2.9792e-14, 1.0000e+00, 8.7491e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1167e-18, 3.5542e-19, 1.0000e+00, 1.1571e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "198000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8346e-21, 2.3512e-21, 9.6188e-14, 1.8141e-21],\n",
      "        [1.1962e-34, 1.3902e-34, 4.7674e-22, 1.1891e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.4752e-06, 1.2256e-06, 9.9999e-01, 4.6647e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.6146e-14, 3.0236e-14, 1.0000e+00, 8.8790e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1412e-18, 3.6320e-19, 1.0000e+00, 1.1824e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "199000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8347e-21, 2.3513e-21, 9.5311e-14, 1.8142e-21],\n",
      "        [1.1997e-34, 1.3941e-34, 4.7044e-22, 1.1925e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.5000e-06, 1.2324e-06, 9.9999e-01, 4.6906e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.7418e-14, 3.0685e-14, 1.0000e+00, 9.0100e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1662e-18, 3.7113e-19, 1.0000e+00, 1.2083e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "200000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8347e-21, 2.3515e-21, 9.4448e-14, 1.8142e-21],\n",
      "        [1.2031e-34, 1.3981e-34, 4.6427e-22, 1.1959e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.5251e-06, 1.2393e-06, 9.9999e-01, 4.7168e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.8711e-14, 3.1140e-14, 1.0000e+00, 9.1433e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1916e-18, 3.7924e-19, 1.0000e+00, 1.2347e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "201000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8348e-21, 2.3516e-21, 9.3592e-14, 1.8142e-21],\n",
      "        [1.2065e-34, 1.4021e-34, 4.5818e-22, 1.1993e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.5509e-06, 1.2464e-06, 9.9999e-01, 4.7437e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.0034e-14, 3.1606e-14, 1.0000e+00, 9.2796e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2178e-18, 3.8757e-19, 1.0000e+00, 1.2618e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "202000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8348e-21, 2.3518e-21, 9.2746e-14, 1.8143e-21],\n",
      "        [1.2100e-34, 1.4060e-34, 4.5218e-22, 1.2028e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([4.5769e-06, 1.2536e-06, 9.9999e-01, 4.7708e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.1373e-14, 3.2079e-14, 1.0000e+00, 9.4176e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2444e-18, 3.9606e-19, 1.0000e+00, 1.2894e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "203000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8349e-21, 2.3519e-21, 9.1909e-14, 1.8143e-21],\n",
      "        [1.2134e-34, 1.4100e-34, 4.4628e-22, 1.2062e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.6029e-06, 1.2607e-06, 9.9999e-01, 4.7979e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.2726e-14, 3.2556e-14, 1.0000e+00, 9.5571e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2716e-18, 4.0470e-19, 1.0000e+00, 1.3175e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "204000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8349e-21, 2.3521e-21, 9.1085e-14, 1.8143e-21],\n",
      "        [1.2168e-34, 1.4140e-34, 4.4049e-22, 1.2096e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.6288e-06, 1.2679e-06, 9.9999e-01, 4.8250e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.4088e-14, 3.3036e-14, 1.0000e+00, 9.6974e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2990e-18, 4.1345e-19, 1.0000e+00, 1.3460e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "205000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8349e-21, 2.3523e-21, 9.0275e-14, 1.8144e-21],\n",
      "        [1.2203e-34, 1.4180e-34, 4.3483e-22, 1.2130e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.6548e-06, 1.2750e-06, 9.9999e-01, 4.8521e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.5461e-14, 3.3521e-14, 1.0000e+00, 9.8390e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3269e-18, 4.2234e-19, 1.0000e+00, 1.3750e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "206000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8350e-21, 2.3524e-21, 8.9478e-14, 1.8144e-21],\n",
      "        [1.2237e-34, 1.4219e-34, 4.2928e-22, 1.2165e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.6809e-06, 1.2822e-06, 9.9999e-01, 4.8793e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.6849e-14, 3.4010e-14, 1.0000e+00, 9.9822e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3553e-18, 4.3139e-19, 1.0000e+00, 1.4044e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "207000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8350e-21, 2.3526e-21, 8.8692e-14, 1.8144e-21],\n",
      "        [1.2272e-34, 1.4259e-34, 4.2382e-22, 1.2199e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.7071e-06, 1.2894e-06, 9.9999e-01, 4.9066e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.8254e-14, 3.4506e-14, 1.0000e+00, 1.0127e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3842e-18, 4.4058e-19, 1.0000e+00, 1.4344e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "208000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8351e-21, 2.3527e-21, 8.7915e-14, 1.8145e-21],\n",
      "        [1.2306e-34, 1.4299e-34, 4.1846e-22, 1.2233e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.7335e-06, 1.2967e-06, 9.9999e-01, 4.9342e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.9681e-14, 3.5009e-14, 1.0000e+00, 1.0274e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4138e-18, 4.4999e-19, 1.0000e+00, 1.4650e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "209000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8351e-21, 2.3528e-21, 8.7146e-14, 1.8145e-21],\n",
      "        [1.2341e-34, 1.4338e-34, 4.1317e-22, 1.2267e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.7601e-06, 1.3040e-06, 9.9999e-01, 4.9620e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0113e-13, 3.5520e-14, 1.0000e+00, 1.0423e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4440e-18, 4.5960e-19, 1.0000e+00, 1.4963e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "210000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8352e-21, 2.3530e-21, 8.6383e-14, 1.8146e-21],\n",
      "        [1.2375e-34, 1.4378e-34, 4.0795e-22, 1.2302e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.7869e-06, 1.3114e-06, 9.9999e-01, 4.9900e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0259e-13, 3.6038e-14, 1.0000e+00, 1.0574e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4747e-18, 4.6941e-19, 1.0000e+00, 1.5282e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "211000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8352e-21, 2.3531e-21, 8.5629e-14, 1.8146e-21],\n",
      "        [1.2409e-34, 1.4418e-34, 4.0280e-22, 1.2336e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.8109e-06, 1.3180e-06, 9.9999e-01, 5.0150e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0396e-13, 3.6519e-14, 1.0000e+00, 1.0715e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5038e-18, 4.7866e-19, 1.0000e+00, 1.5583e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "212000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8353e-21, 2.3533e-21, 8.4932e-14, 1.8146e-21],\n",
      "        [1.2444e-34, 1.4458e-34, 3.9811e-22, 1.2370e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([4.8291e-06, 1.3230e-06, 9.9999e-01, 5.0341e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0508e-13, 3.6917e-14, 1.0000e+00, 1.0831e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5284e-18, 4.8651e-19, 1.0000e+00, 1.5839e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "213000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8353e-21, 2.3534e-21, 8.4342e-14, 1.8147e-21],\n",
      "        [1.2479e-34, 1.4498e-34, 3.9427e-22, 1.2405e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.8475e-06, 1.3281e-06, 9.9999e-01, 5.0533e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0622e-13, 3.7320e-14, 1.0000e+00, 1.0949e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5535e-18, 4.9448e-19, 1.0000e+00, 1.6099e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "214000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8354e-21, 2.3536e-21, 8.3757e-14, 1.8147e-21],\n",
      "        [1.2513e-34, 1.4537e-34, 3.9045e-22, 1.2439e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.8660e-06, 1.3332e-06, 9.9999e-01, 5.0726e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0738e-13, 3.7727e-14, 1.0000e+00, 1.1067e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5789e-18, 5.0259e-19, 1.0000e+00, 1.6363e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "215000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8354e-21, 2.3537e-21, 8.3177e-14, 1.8147e-21],\n",
      "        [1.2546e-34, 1.4576e-34, 3.8666e-22, 1.2472e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.8848e-06, 1.3384e-06, 9.9999e-01, 5.0922e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0854e-13, 3.8139e-14, 1.0000e+00, 1.1187e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.6047e-18, 5.1080e-19, 1.0000e+00, 1.6630e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "216000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8354e-21, 2.3538e-21, 8.2602e-14, 1.8147e-21],\n",
      "        [1.2579e-34, 1.4613e-34, 3.8291e-22, 1.2505e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.9034e-06, 1.3435e-06, 9.9999e-01, 5.1116e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0970e-13, 3.8548e-14, 1.0000e+00, 1.1307e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.6305e-18, 5.1900e-19, 1.0000e+00, 1.6897e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "217000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8355e-21, 2.3539e-21, 8.2043e-14, 1.8148e-21],\n",
      "        [1.2611e-34, 1.4650e-34, 3.7925e-22, 1.2537e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.9224e-06, 1.3488e-06, 9.9999e-01, 5.1315e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1088e-13, 3.8964e-14, 1.0000e+00, 1.1428e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.6566e-18, 5.2730e-19, 1.0000e+00, 1.7168e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "218000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8355e-21, 2.3541e-21, 8.1489e-14, 1.8148e-21],\n",
      "        [1.2640e-34, 1.4684e-34, 3.7559e-22, 1.2565e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.9415e-06, 1.3540e-06, 9.9999e-01, 5.1515e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1207e-13, 3.9385e-14, 1.0000e+00, 1.1551e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.6830e-18, 5.3574e-19, 1.0000e+00, 1.7442e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "219000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8356e-21, 2.3542e-21, 8.0939e-14, 1.8148e-21],\n",
      "        [1.2669e-34, 1.4717e-34, 3.7196e-22, 1.2594e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.9608e-06, 1.3593e-06, 9.9999e-01, 5.1716e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1327e-13, 3.9809e-14, 1.0000e+00, 1.1675e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.7098e-18, 5.4429e-19, 1.0000e+00, 1.7720e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "220000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8356e-21, 2.3544e-21, 8.0394e-14, 1.8148e-21],\n",
      "        [1.2697e-34, 1.4750e-34, 3.6838e-22, 1.2622e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.9802e-06, 1.3647e-06, 9.9999e-01, 5.1918e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1448e-13, 4.0238e-14, 1.0000e+00, 1.1800e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.7370e-18, 5.5293e-19, 1.0000e+00, 1.8002e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "221000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8357e-21, 2.3545e-21, 7.9855e-14, 1.8149e-21],\n",
      "        [1.2724e-34, 1.4781e-34, 3.6482e-22, 1.2649e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.9997e-06, 1.3701e-06, 9.9999e-01, 5.2123e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1571e-13, 4.0671e-14, 1.0000e+00, 1.1926e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.7646e-18, 5.6172e-19, 1.0000e+00, 1.8288e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "222000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8357e-21, 2.3546e-21, 7.9321e-14, 1.8150e-21],\n",
      "        [1.2751e-34, 1.4812e-34, 3.6128e-22, 1.2676e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([5.0193e-06, 1.3755e-06, 9.9999e-01, 5.2327e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1694e-13, 4.1107e-14, 1.0000e+00, 1.2054e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.7925e-18, 5.7060e-19, 1.0000e+00, 1.8578e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "223000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8358e-21, 2.3547e-21, 7.8791e-14, 1.8150e-21],\n",
      "        [1.2778e-34, 1.4843e-34, 3.5780e-22, 1.2703e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.0389e-06, 1.3809e-06, 9.9999e-01, 5.2532e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1819e-13, 4.1548e-14, 1.0000e+00, 1.2182e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.8208e-18, 5.7963e-19, 1.0000e+00, 1.8871e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "224000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8358e-21, 2.3549e-21, 7.8266e-14, 1.8150e-21],\n",
      "        [1.2805e-34, 1.4874e-34, 3.5436e-22, 1.2730e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.0586e-06, 1.3863e-06, 9.9999e-01, 5.2738e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1945e-13, 4.1994e-14, 1.0000e+00, 1.2313e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.8496e-18, 5.8879e-19, 1.0000e+00, 1.9170e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "225000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8359e-21, 2.3550e-21, 7.7745e-14, 1.8151e-21],\n",
      "        [1.2832e-34, 1.4906e-34, 3.5096e-22, 1.2757e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.0785e-06, 1.3918e-06, 9.9999e-01, 5.2946e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2073e-13, 4.2445e-14, 1.0000e+00, 1.2444e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.8788e-18, 5.9812e-19, 1.0000e+00, 1.9473e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "226000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8359e-21, 2.3552e-21, 7.7228e-14, 1.8151e-21],\n",
      "        [1.2859e-34, 1.4937e-34, 3.4758e-22, 1.2784e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.0991e-06, 1.3975e-06, 9.9999e-01, 5.3161e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2204e-13, 4.2906e-14, 1.0000e+00, 1.2579e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.9088e-18, 6.0765e-19, 1.0000e+00, 1.9784e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "227000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8360e-21, 2.3553e-21, 7.6713e-14, 1.8151e-21],\n",
      "        [1.2886e-34, 1.4968e-34, 3.4424e-22, 1.2811e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.1198e-06, 1.4032e-06, 9.9999e-01, 5.3377e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2336e-13, 4.3372e-14, 1.0000e+00, 1.2715e-13],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.9392e-18, 6.1734e-19, 1.0000e+00, 2.0099e-18],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "228000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [1.8360e-21, 2.3554e-21, 7.6202e-14, 1.8152e-21],\n",
      "        [1.2913e-34, 1.4999e-34, 3.4093e-22, 1.2838e-34]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.8288e-07, 2.2470e-07, 1.0000e+00, 8.2452e-07],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2958e-15, 4.6824e-16, 1.0000e+00, 1.3519e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.7769e-21, 1.2346e-21, 1.0000e+00, 3.9798e-21],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "229000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9717e-22, 6.2591e-22, 3.0036e-13, 4.9249e-22],\n",
      "        [1.4775e-35, 1.6827e-35, 3.0626e-21, 1.4782e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.7940e-07, 2.2372e-07, 1.0000e+00, 8.2087e-07],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2984e-15, 4.6926e-16, 1.0000e+00, 1.3546e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.8140e-21, 1.2468e-21, 1.0000e+00, 4.0191e-21],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "230000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9662e-22, 6.2533e-22, 2.9812e-13, 4.9195e-22],\n",
      "        [1.4884e-35, 1.6952e-35, 3.0415e-21, 1.4892e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.7784e-07, 2.2328e-07, 1.0000e+00, 8.1924e-07],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3076e-15, 4.7269e-16, 1.0000e+00, 1.3642e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.8786e-21, 1.2681e-21, 1.0000e+00, 4.0874e-21],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "231000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9580e-22, 6.2439e-22, 2.9494e-13, 4.9114e-22],\n",
      "        [1.4987e-35, 1.7069e-35, 3.0056e-21, 1.4995e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.7798e-07, 2.2334e-07, 1.0000e+00, 8.1941e-07],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3229e-15, 4.7833e-16, 1.0000e+00, 1.3802e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.9684e-21, 1.2975e-21, 1.0000e+00, 4.1823e-21],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "232000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9493e-22, 6.2340e-22, 2.9107e-13, 4.9027e-22],\n",
      "        [1.5087e-35, 1.7184e-35, 2.9578e-21, 1.5096e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([7.8016e-07, 2.2398e-07, 1.0000e+00, 8.2171e-07],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3457e-15, 4.8668e-16, 1.0000e+00, 1.4040e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.0888e-21, 1.3370e-21, 1.0000e+00, 4.3094e-21],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "233000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9414e-22, 6.2248e-22, 2.8648e-13, 4.8949e-22],\n",
      "        [1.5187e-35, 1.7297e-35, 2.8977e-21, 1.5197e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.8427e-07, 2.2517e-07, 1.0000e+00, 8.2608e-07],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3757e-15, 4.9766e-16, 1.0000e+00, 1.4355e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.2409e-21, 1.3868e-21, 1.0000e+00, 4.4700e-21],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "234000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9337e-22, 6.2162e-22, 2.8125e-13, 4.8874e-22],\n",
      "        [1.5285e-35, 1.7410e-35, 2.8267e-21, 1.5296e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.9001e-07, 2.2683e-07, 1.0000e+00, 8.3214e-07],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4122e-15, 5.1096e-16, 1.0000e+00, 1.4736e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.4222e-21, 1.4462e-21, 1.0000e+00, 4.6614e-21],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "235000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9260e-22, 6.2074e-22, 2.7557e-13, 4.8799e-22],\n",
      "        [1.5385e-35, 1.7523e-35, 2.7484e-21, 1.5395e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.9717e-07, 2.2890e-07, 1.0000e+00, 8.3970e-07],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4546e-15, 5.2639e-16, 1.0000e+00, 1.5179e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.6313e-21, 1.5147e-21, 1.0000e+00, 4.8820e-21],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "236000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9189e-22, 6.1993e-22, 2.6958e-13, 4.8730e-22],\n",
      "        [1.5482e-35, 1.7634e-35, 2.6650e-21, 1.5494e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.0537e-07, 2.3127e-07, 1.0000e+00, 8.4836e-07],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5018e-15, 5.4357e-16, 1.0000e+00, 1.5672e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.8649e-21, 1.5911e-21, 1.0000e+00, 5.1285e-21],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "237000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9129e-22, 6.1926e-22, 2.6347e-13, 4.8671e-22],\n",
      "        [1.5581e-35, 1.7746e-35, 2.5794e-21, 1.5593e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.1452e-07, 2.3390e-07, 1.0000e+00, 8.5801e-07],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5536e-15, 5.6241e-16, 1.0000e+00, 1.6213e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.1216e-21, 1.6752e-21, 1.0000e+00, 5.3995e-21],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "238000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9084e-22, 6.1877e-22, 2.5734e-13, 4.8629e-22],\n",
      "        [1.5676e-35, 1.7855e-35, 2.4931e-21, 1.5689e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.2401e-07, 2.3663e-07, 1.0000e+00, 8.6803e-07],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.6074e-15, 5.8200e-16, 1.0000e+00, 1.6776e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.3910e-21, 1.7633e-21, 1.0000e+00, 5.6837e-21],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "239000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9044e-22, 6.1835e-22, 2.5141e-13, 4.8591e-22],\n",
      "        [1.5763e-35, 1.7955e-35, 2.4094e-21, 1.5776e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.3357e-07, 2.3938e-07, 1.0000e+00, 8.7811e-07],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.6627e-15, 6.0211e-16, 1.0000e+00, 1.7354e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.6720e-21, 1.8553e-21, 1.0000e+00, 5.9802e-21],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "240000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9007e-22, 6.1796e-22, 2.4568e-13, 4.8555e-22],\n",
      "        [1.5851e-35, 1.8055e-35, 2.3295e-21, 1.5865e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.4333e-07, 2.4219e-07, 1.0000e+00, 8.8841e-07],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.7200e-15, 6.2295e-16, 1.0000e+00, 1.7953e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.9679e-21, 1.9521e-21, 1.0000e+00, 6.2926e-21],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "241000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.8989e-22, 6.1780e-22, 2.4019e-13, 4.8538e-22],\n",
      "        [1.5949e-35, 1.8166e-35, 2.2537e-21, 1.5963e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.5341e-07, 2.4509e-07, 1.0000e+00, 8.9906e-07],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.7796e-15, 6.4460e-16, 1.0000e+00, 1.8575e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.2789e-21, 2.0539e-21, 1.0000e+00, 6.6208e-21],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "242000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.8982e-22, 6.1778e-22, 2.3490e-13, 4.8532e-22],\n",
      "        [1.6049e-35, 1.8280e-35, 2.1814e-21, 1.6064e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([8.6370e-07, 2.4805e-07, 1.0000e+00, 9.0991e-07],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.8410e-15, 6.6693e-16, 1.0000e+00, 1.9218e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.6043e-21, 2.1604e-21, 1.0000e+00, 6.9642e-21],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "243000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.8978e-22, 6.1779e-22, 2.2977e-13, 4.8529e-22],\n",
      "        [1.6148e-35, 1.8393e-35, 2.1118e-21, 1.6163e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.7411e-07, 2.5105e-07, 1.0000e+00, 9.2090e-07],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.9043e-15, 6.8995e-16, 1.0000e+00, 1.9879e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.9443e-21, 2.2717e-21, 1.0000e+00, 7.3231e-21],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "244000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.8975e-22, 6.1781e-22, 2.2480e-13, 4.8527e-22],\n",
      "        [1.6245e-35, 1.8504e-35, 2.0449e-21, 1.6260e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.8454e-07, 2.5404e-07, 1.0000e+00, 9.3191e-07],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.9686e-15, 7.1332e-16, 1.0000e+00, 2.0551e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.2937e-21, 2.3860e-21, 1.0000e+00, 7.6917e-21],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "245000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.8972e-22, 6.1785e-22, 2.2004e-13, 4.8526e-22],\n",
      "        [1.6334e-35, 1.8605e-35, 1.9809e-21, 1.6350e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.9372e-07, 2.5668e-07, 1.0000e+00, 9.4160e-07],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.0284e-15, 7.3508e-16, 1.0000e+00, 2.1177e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.6272e-21, 2.4951e-21, 1.0000e+00, 8.0435e-21],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "246000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.8971e-22, 6.1789e-22, 2.1576e-13, 4.8524e-22],\n",
      "        [1.6424e-35, 1.8707e-35, 1.9244e-21, 1.6440e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.0304e-07, 2.5936e-07, 1.0000e+00, 9.5143e-07],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.0900e-15, 7.5746e-16, 1.0000e+00, 2.1820e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.9744e-21, 2.6087e-21, 1.0000e+00, 8.4101e-21],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "247000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.8968e-22, 6.1791e-22, 2.1158e-13, 4.8523e-22],\n",
      "        [1.6512e-35, 1.8808e-35, 1.8698e-21, 1.6528e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.1245e-07, 2.6206e-07, 1.0000e+00, 9.6135e-07],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.1529e-15, 7.8033e-16, 1.0000e+00, 2.2477e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.3340e-21, 2.7264e-21, 1.0000e+00, 8.7897e-21],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "248000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.8965e-22, 6.1793e-22, 2.0753e-13, 4.8520e-22],\n",
      "        [1.6598e-35, 1.8907e-35, 1.8173e-21, 1.6615e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.2192e-07, 2.6478e-07, 1.0000e+00, 9.7135e-07],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.2172e-15, 8.0368e-16, 1.0000e+00, 2.3149e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.7064e-21, 2.8483e-21, 1.0000e+00, 9.1828e-21],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "249000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.8962e-22, 6.1795e-22, 2.0359e-13, 4.8519e-22],\n",
      "        [1.6685e-35, 1.9005e-35, 1.7668e-21, 1.6702e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.3171e-07, 2.6759e-07, 1.0000e+00, 9.8168e-07],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.2836e-15, 8.2783e-16, 1.0000e+00, 2.3843e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.0941e-21, 2.9751e-21, 1.0000e+00, 9.5920e-21],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "250000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.8959e-22, 6.1797e-22, 1.9975e-13, 4.8516e-22],\n",
      "        [1.6764e-35, 1.9095e-35, 1.7175e-21, 1.6782e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.4170e-07, 2.7046e-07, 1.0000e+00, 9.9222e-07],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.3519e-15, 8.5267e-16, 1.0000e+00, 2.4557e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.4972e-21, 3.1070e-21, 1.0000e+00, 1.0017e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "251000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.8956e-22, 6.1798e-22, 1.9602e-13, 4.8514e-22],\n",
      "        [1.6841e-35, 1.9183e-35, 1.6699e-21, 1.6859e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.5188e-07, 2.7338e-07, 1.0000e+00, 1.0030e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.4223e-15, 8.7826e-16, 1.0000e+00, 2.5293e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.9173e-21, 3.2445e-21, 1.0000e+00, 1.0461e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "252000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.8953e-22, 6.1800e-22, 1.9237e-13, 4.8511e-22],\n",
      "        [1.6916e-35, 1.9270e-35, 1.6237e-21, 1.6935e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([9.6219e-07, 2.7634e-07, 1.0000e+00, 1.0138e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.4944e-15, 9.0448e-16, 1.0000e+00, 2.6047e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0353e-20, 3.3870e-21, 1.0000e+00, 1.0921e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "253000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.8950e-22, 6.1801e-22, 1.8882e-13, 4.8509e-22],\n",
      "        [1.6990e-35, 1.9354e-35, 1.5790e-21, 1.7009e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.7214e-07, 2.7920e-07, 1.0000e+00, 1.0243e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.5660e-15, 9.3052e-16, 1.0000e+00, 2.6795e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0792e-20, 3.5308e-21, 1.0000e+00, 1.1385e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "254000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.8947e-22, 6.1803e-22, 1.8544e-13, 4.8507e-22],\n",
      "        [1.7064e-35, 1.9438e-35, 1.5371e-21, 1.7083e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.8080e-07, 2.8168e-07, 1.0000e+00, 1.0335e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.6318e-15, 9.5443e-16, 1.0000e+00, 2.7483e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1205e-20, 3.6657e-21, 1.0000e+00, 1.1820e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "255000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.8943e-22, 6.1803e-22, 1.8240e-13, 4.8505e-22],\n",
      "        [1.7136e-35, 1.9520e-35, 1.4999e-21, 1.7155e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.8964e-07, 2.8422e-07, 1.0000e+00, 1.0428e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.6994e-15, 9.7900e-16, 1.0000e+00, 2.8189e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1631e-20, 3.8053e-21, 1.0000e+00, 1.2270e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "256000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.8941e-22, 6.1804e-22, 1.7942e-13, 4.8501e-22],\n",
      "        [1.7202e-35, 1.9595e-35, 1.4636e-21, 1.7221e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.9850e-07, 2.8676e-07, 1.0000e+00, 1.0522e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.7680e-15, 1.0040e-15, 1.0000e+00, 2.8907e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2070e-20, 3.9489e-21, 1.0000e+00, 1.2734e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "257000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.8936e-22, 6.1804e-22, 1.7653e-13, 4.8499e-22],\n",
      "        [1.7267e-35, 1.9670e-35, 1.4284e-21, 1.7287e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0074e-06, 2.8931e-07, 1.0000e+00, 1.0616e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.8381e-15, 1.0294e-15, 1.0000e+00, 2.9639e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2523e-20, 4.0970e-21, 1.0000e+00, 1.3212e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "258000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.8932e-22, 6.1803e-22, 1.7369e-13, 4.8495e-22],\n",
      "        [1.7332e-35, 1.9745e-35, 1.3943e-21, 1.7353e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0163e-06, 2.9185e-07, 1.0000e+00, 1.0709e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.9093e-15, 1.0553e-15, 1.0000e+00, 3.0383e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2989e-20, 4.2493e-21, 1.0000e+00, 1.3703e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "259000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.8930e-22, 6.1803e-22, 1.7092e-13, 4.8492e-22],\n",
      "        [1.7398e-35, 1.9820e-35, 1.3613e-21, 1.7419e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0253e-06, 2.9444e-07, 1.0000e+00, 1.0805e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.9819e-15, 1.0817e-15, 1.0000e+00, 3.1142e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3467e-20, 4.4059e-21, 1.0000e+00, 1.4208e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "260000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.8925e-22, 6.1802e-22, 1.6822e-13, 4.8488e-22],\n",
      "        [1.7459e-35, 1.9889e-35, 1.3292e-21, 1.7480e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0346e-06, 2.9711e-07, 1.0000e+00, 1.0902e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.0565e-15, 1.1088e-15, 1.0000e+00, 3.1922e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3960e-20, 4.5672e-21, 1.0000e+00, 1.4729e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "261000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.8921e-22, 6.1802e-22, 1.6560e-13, 4.8485e-22],\n",
      "        [1.7513e-35, 1.9951e-35, 1.2978e-21, 1.7534e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0440e-06, 2.9982e-07, 1.0000e+00, 1.1002e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.1330e-15, 1.1367e-15, 1.0000e+00, 3.2722e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4471e-20, 4.7343e-21, 1.0000e+00, 1.5269e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "262000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.8920e-22, 6.1804e-22, 1.6302e-13, 4.8484e-22],\n",
      "        [1.7566e-35, 2.0011e-35, 1.2673e-21, 1.7587e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([1.0537e-06, 3.0260e-07, 1.0000e+00, 1.1105e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.2120e-15, 1.1654e-15, 1.0000e+00, 3.3547e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5001e-20, 4.9076e-21, 1.0000e+00, 1.5828e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "263000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.8917e-22, 6.1805e-22, 1.6048e-13, 4.8482e-22],\n",
      "        [1.7613e-35, 2.0066e-35, 1.2372e-21, 1.7634e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0636e-06, 3.0542e-07, 1.0000e+00, 1.1208e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.2929e-15, 1.1948e-15, 1.0000e+00, 3.4393e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5548e-20, 5.0867e-21, 1.0000e+00, 1.6406e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "264000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.8917e-22, 6.1808e-22, 1.5800e-13, 4.8482e-22],\n",
      "        [1.7659e-35, 2.0118e-35, 1.2079e-21, 1.7680e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0735e-06, 3.0826e-07, 1.0000e+00, 1.1313e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.3755e-15, 1.2248e-15, 1.0000e+00, 3.5257e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.6113e-20, 5.2712e-21, 1.0000e+00, 1.7001e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "265000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.8916e-22, 6.1812e-22, 1.5557e-13, 4.8482e-22],\n",
      "        [1.7703e-35, 2.0168e-35, 1.1794e-21, 1.7725e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0834e-06, 3.1111e-07, 1.0000e+00, 1.1418e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.4594e-15, 1.2553e-15, 1.0000e+00, 3.6133e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.6691e-20, 5.4603e-21, 1.0000e+00, 1.7612e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "266000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.8916e-22, 6.1813e-22, 1.5320e-13, 4.8481e-22],\n",
      "        [1.7745e-35, 2.0217e-35, 1.1519e-21, 1.7767e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0925e-06, 3.1370e-07, 1.0000e+00, 1.1514e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.5387e-15, 1.2841e-15, 1.0000e+00, 3.6962e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.7247e-20, 5.6419e-21, 1.0000e+00, 1.8198e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "267000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.8915e-22, 6.1817e-22, 1.5102e-13, 4.8482e-22],\n",
      "        [1.7789e-35, 2.0267e-35, 1.1269e-21, 1.7811e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1007e-06, 3.1603e-07, 1.0000e+00, 1.1599e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.6126e-15, 1.3109e-15, 1.0000e+00, 3.7734e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.7773e-20, 5.8141e-21, 1.0000e+00, 1.8754e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "268000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.8918e-22, 6.1825e-22, 1.4904e-13, 4.8484e-22],\n",
      "        [1.7833e-35, 2.0318e-35, 1.1044e-21, 1.7856e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1089e-06, 3.1838e-07, 1.0000e+00, 1.1686e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.6879e-15, 1.3383e-15, 1.0000e+00, 3.8521e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.8314e-20, 5.9912e-21, 1.0000e+00, 1.9326e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "269000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.8920e-22, 6.1831e-22, 1.4709e-13, 4.8488e-22],\n",
      "        [1.7879e-35, 2.0370e-35, 1.0825e-21, 1.7902e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1171e-06, 3.2073e-07, 1.0000e+00, 1.1773e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.7644e-15, 1.3661e-15, 1.0000e+00, 3.9321e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.8869e-20, 6.1725e-21, 1.0000e+00, 1.9911e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "270000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.8924e-22, 6.1840e-22, 1.4518e-13, 4.8491e-22],\n",
      "        [1.7924e-35, 2.0422e-35, 1.0612e-21, 1.7947e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1254e-06, 3.2311e-07, 1.0000e+00, 1.1860e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.8424e-15, 1.3945e-15, 1.0000e+00, 4.0136e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.9440e-20, 6.3591e-21, 1.0000e+00, 2.0514e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "271000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.8926e-22, 6.1846e-22, 1.4330e-13, 4.8494e-22],\n",
      "        [1.7969e-35, 2.0474e-35, 1.0403e-21, 1.7993e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1339e-06, 3.2552e-07, 1.0000e+00, 1.1949e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.9221e-15, 1.4234e-15, 1.0000e+00, 4.0969e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.0027e-20, 6.5512e-21, 1.0000e+00, 2.1134e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "272000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.8931e-22, 6.1855e-22, 1.4145e-13, 4.8499e-22],\n",
      "        [1.8014e-35, 2.0526e-35, 1.0199e-21, 1.8039e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([1.1425e-06, 3.2798e-07, 1.0000e+00, 1.2040e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.0038e-15, 1.4531e-15, 1.0000e+00, 4.1823e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.0633e-20, 6.7494e-21, 1.0000e+00, 2.1774e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "273000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.8935e-22, 6.1864e-22, 1.3963e-13, 4.8504e-22],\n",
      "        [1.8059e-35, 2.0577e-35, 9.9993e-22, 1.8083e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1512e-06, 3.3050e-07, 1.0000e+00, 1.2133e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.0873e-15, 1.4835e-15, 1.0000e+00, 4.2696e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.1256e-20, 6.9530e-21, 1.0000e+00, 2.2431e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "274000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.8939e-22, 6.1874e-22, 1.3784e-13, 4.8509e-22],\n",
      "        [1.8099e-35, 2.0623e-35, 9.8029e-22, 1.8124e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1600e-06, 3.3301e-07, 1.0000e+00, 1.2226e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.1720e-15, 1.5143e-15, 1.0000e+00, 4.3582e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.1893e-20, 7.1612e-21, 1.0000e+00, 2.3104e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "275000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.8945e-22, 6.1883e-22, 1.3609e-13, 4.8514e-22],\n",
      "        [1.8139e-35, 2.0669e-35, 9.6118e-22, 1.8164e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1687e-06, 3.3550e-07, 1.0000e+00, 1.2317e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.2567e-15, 1.5451e-15, 1.0000e+00, 4.4467e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.2535e-20, 7.3712e-21, 1.0000e+00, 2.3782e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "276000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.8949e-22, 6.1893e-22, 1.3440e-13, 4.8519e-22],\n",
      "        [1.8179e-35, 2.0714e-35, 9.4282e-22, 1.8204e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1777e-06, 3.3806e-07, 1.0000e+00, 1.2412e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.3437e-15, 1.5766e-15, 1.0000e+00, 4.5376e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.3196e-20, 7.5875e-21, 1.0000e+00, 2.4480e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "277000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.8954e-22, 6.1903e-22, 1.3273e-13, 4.8524e-22],\n",
      "        [1.8213e-35, 2.0754e-35, 9.2470e-22, 1.8238e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1868e-06, 3.4067e-07, 1.0000e+00, 1.2508e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.4328e-15, 1.6090e-15, 1.0000e+00, 4.6307e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.3876e-20, 7.8097e-21, 1.0000e+00, 2.5197e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "278000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.8959e-22, 6.1910e-22, 1.3108e-13, 4.8529e-22],\n",
      "        [1.8243e-35, 2.0789e-35, 9.0686e-22, 1.8269e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1961e-06, 3.4331e-07, 1.0000e+00, 1.2606e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.5236e-15, 1.6420e-15, 1.0000e+00, 4.7256e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.4575e-20, 8.0382e-21, 1.0000e+00, 2.5936e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "279000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.8961e-22, 6.1918e-22, 1.2946e-13, 4.8533e-22],\n",
      "        [1.8274e-35, 2.0824e-35, 8.8941e-22, 1.8299e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2054e-06, 3.4597e-07, 1.0000e+00, 1.2704e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.6158e-15, 1.6754e-15, 1.0000e+00, 4.8220e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.5290e-20, 8.2720e-21, 1.0000e+00, 2.6691e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "280000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.8967e-22, 6.1927e-22, 1.2787e-13, 4.8537e-22],\n",
      "        [1.8304e-35, 2.0859e-35, 8.7240e-22, 1.8329e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2148e-06, 3.4867e-07, 1.0000e+00, 1.2803e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.7101e-15, 1.7097e-15, 1.0000e+00, 4.9206e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.6027e-20, 8.5128e-21, 1.0000e+00, 2.7468e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "281000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.8971e-22, 6.1933e-22, 1.2630e-13, 4.8541e-22],\n",
      "        [1.8334e-35, 2.0894e-35, 8.5576e-22, 1.8359e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2244e-06, 3.5141e-07, 1.0000e+00, 1.2905e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.8065e-15, 1.7447e-15, 1.0000e+00, 5.0214e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.6785e-20, 8.7608e-21, 1.0000e+00, 2.8269e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "282000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.8975e-22, 6.1942e-22, 1.2476e-13, 4.8546e-22],\n",
      "        [1.8364e-35, 2.0928e-35, 8.3945e-22, 1.8389e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([1.2341e-06, 3.5418e-07, 1.0000e+00, 1.3007e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.9047e-15, 1.7803e-15, 1.0000e+00, 5.1239e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.7564e-20, 9.0152e-21, 1.0000e+00, 2.9091e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "283000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.8978e-22, 6.1949e-22, 1.2324e-13, 4.8549e-22],\n",
      "        [1.8393e-35, 2.0962e-35, 8.2352e-22, 1.8419e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2439e-06, 3.5697e-07, 1.0000e+00, 1.3110e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.0046e-15, 1.8166e-15, 1.0000e+00, 5.2283e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.8363e-20, 9.2762e-21, 1.0000e+00, 2.9934e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "284000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.8982e-22, 6.1955e-22, 1.2175e-13, 4.8552e-22],\n",
      "        [1.8422e-35, 2.0995e-35, 8.0794e-22, 1.8448e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2537e-06, 3.5978e-07, 1.0000e+00, 1.3214e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.1062e-15, 1.8535e-15, 1.0000e+00, 5.3344e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.9181e-20, 9.5436e-21, 1.0000e+00, 3.0798e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "285000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.8985e-22, 6.1961e-22, 1.2028e-13, 4.8557e-22],\n",
      "        [1.8451e-35, 2.1029e-35, 7.9275e-22, 1.8477e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2637e-06, 3.6263e-07, 1.0000e+00, 1.3319e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.2096e-15, 1.8910e-15, 1.0000e+00, 5.4425e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.0020e-20, 9.8179e-21, 1.0000e+00, 3.1684e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "286000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.8988e-22, 6.1969e-22, 1.1883e-13, 4.8559e-22],\n",
      "        [1.8480e-35, 2.1062e-35, 7.7794e-22, 1.8506e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2729e-06, 3.6525e-07, 1.0000e+00, 1.3416e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.3075e-15, 1.9266e-15, 1.0000e+00, 5.5449e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.0824e-20, 1.0081e-20, 1.0000e+00, 3.2532e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "287000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.8992e-22, 6.1976e-22, 1.1750e-13, 4.8563e-22],\n",
      "        [1.8509e-35, 2.1096e-35, 7.6436e-22, 1.8536e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2807e-06, 3.6746e-07, 1.0000e+00, 1.3497e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.3944e-15, 1.9581e-15, 1.0000e+00, 5.6356e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.1549e-20, 1.0317e-20, 1.0000e+00, 3.3297e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "288000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.8995e-22, 6.1980e-22, 1.1632e-13, 4.8566e-22],\n",
      "        [1.8538e-35, 2.1129e-35, 7.5252e-22, 1.8564e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2885e-06, 3.6968e-07, 1.0000e+00, 1.3580e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.4823e-15, 1.9900e-15, 1.0000e+00, 5.7275e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.2287e-20, 1.0559e-20, 1.0000e+00, 3.4077e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "289000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.8997e-22, 6.1987e-22, 1.1515e-13, 4.8568e-22],\n",
      "        [1.8566e-35, 2.1161e-35, 7.4090e-22, 1.8593e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2962e-06, 3.7190e-07, 1.0000e+00, 1.3662e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.5711e-15, 2.0222e-15, 1.0000e+00, 5.8203e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.3039e-20, 1.0804e-20, 1.0000e+00, 3.4870e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "290000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9000e-22, 6.1993e-22, 1.1401e-13, 4.8572e-22],\n",
      "        [1.8595e-35, 2.1194e-35, 7.2955e-22, 1.8621e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3041e-06, 3.7413e-07, 1.0000e+00, 1.3744e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.6610e-15, 2.0548e-15, 1.0000e+00, 5.9143e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.3805e-20, 1.1054e-20, 1.0000e+00, 3.5680e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "291000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9003e-22, 6.1999e-22, 1.1288e-13, 4.8575e-22],\n",
      "        [1.8623e-35, 2.1227e-35, 7.1840e-22, 1.8650e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3119e-06, 3.7636e-07, 1.0000e+00, 1.3827e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.7522e-15, 2.0879e-15, 1.0000e+00, 6.0096e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.4587e-20, 1.1310e-20, 1.0000e+00, 3.6505e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "292000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9007e-22, 6.2005e-22, 1.1177e-13, 4.8578e-22],\n",
      "        [1.8652e-35, 2.1260e-35, 7.0747e-22, 1.8678e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([1.3198e-06, 3.7860e-07, 1.0000e+00, 1.3910e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.8446e-15, 2.1214e-15, 1.0000e+00, 6.1061e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.5385e-20, 1.1570e-20, 1.0000e+00, 3.7347e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "293000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9009e-22, 6.2010e-22, 1.1067e-13, 4.8581e-22],\n",
      "        [1.8681e-35, 2.1292e-35, 6.9673e-22, 1.8707e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3277e-06, 3.8085e-07, 1.0000e+00, 1.3993e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.9384e-15, 2.1554e-15, 1.0000e+00, 6.2041e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.6200e-20, 1.1837e-20, 1.0000e+00, 3.8209e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "294000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9012e-22, 6.2016e-22, 1.0958e-13, 4.8584e-22],\n",
      "        [1.8709e-35, 2.1326e-35, 6.8617e-22, 1.8736e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3357e-06, 3.8315e-07, 1.0000e+00, 1.4078e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.0337e-15, 2.1900e-15, 1.0000e+00, 6.3038e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.7033e-20, 1.2108e-20, 1.0000e+00, 3.9088e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "295000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9015e-22, 6.2022e-22, 1.0851e-13, 4.8587e-22],\n",
      "        [1.8736e-35, 2.1358e-35, 6.7581e-22, 1.8764e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3439e-06, 3.8546e-07, 1.0000e+00, 1.4164e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.1306e-15, 2.2252e-15, 1.0000e+00, 6.4051e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.7884e-20, 1.2387e-20, 1.0000e+00, 3.9986e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "296000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9017e-22, 6.2028e-22, 1.0745e-13, 4.8590e-22],\n",
      "        [1.8764e-35, 2.1389e-35, 6.6562e-22, 1.8791e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3520e-06, 3.8779e-07, 1.0000e+00, 1.4250e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.2288e-15, 2.2608e-15, 1.0000e+00, 6.5076e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.8752e-20, 1.2670e-20, 1.0000e+00, 4.0902e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "297000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9020e-22, 6.2034e-22, 1.0640e-13, 4.8594e-22],\n",
      "        [1.8790e-35, 2.1419e-35, 6.5560e-22, 1.8818e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3603e-06, 3.9014e-07, 1.0000e+00, 1.4337e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.3284e-15, 2.2969e-15, 1.0000e+00, 6.6117e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.9637e-20, 1.2959e-20, 1.0000e+00, 4.1836e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "298000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9023e-22, 6.2040e-22, 1.0538e-13, 4.8596e-22],\n",
      "        [1.8818e-35, 2.1451e-35, 6.4579e-22, 1.8846e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3686e-06, 3.9250e-07, 1.0000e+00, 1.4424e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.4290e-15, 2.3335e-15, 1.0000e+00, 6.7168e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.0538e-20, 1.3253e-20, 1.0000e+00, 4.2787e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "299000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9026e-22, 6.2046e-22, 1.0436e-13, 4.8599e-22],\n",
      "        [1.8845e-35, 2.1482e-35, 6.3622e-22, 1.8873e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3769e-06, 3.9488e-07, 1.0000e+00, 1.4512e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.5311e-15, 2.3705e-15, 1.0000e+00, 6.8236e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.1456e-20, 1.3553e-20, 1.0000e+00, 4.3757e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "300000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9029e-22, 6.2051e-22, 1.0337e-13, 4.8603e-22],\n",
      "        [1.8871e-35, 2.1512e-35, 6.2680e-22, 1.8899e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3853e-06, 3.9727e-07, 1.0000e+00, 1.4600e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.6344e-15, 2.4080e-15, 1.0000e+00, 6.9315e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.2391e-20, 1.3858e-20, 1.0000e+00, 4.4745e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "301000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9031e-22, 6.2057e-22, 1.0238e-13, 4.8606e-22],\n",
      "        [1.8897e-35, 2.1542e-35, 6.1754e-22, 1.8925e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3937e-06, 3.9967e-07, 1.0000e+00, 1.4689e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.7390e-15, 2.4460e-15, 1.0000e+00, 7.0410e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.3345e-20, 1.4170e-20, 1.0000e+00, 4.5752e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "302000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9034e-22, 6.2063e-22, 1.0141e-13, 4.8607e-22],\n",
      "        [1.8923e-35, 2.1572e-35, 6.0845e-22, 1.8951e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([1.4022e-06, 4.0208e-07, 1.0000e+00, 1.4778e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.8451e-15, 2.4845e-15, 1.0000e+00, 7.1518e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.4317e-20, 1.4487e-20, 1.0000e+00, 4.6778e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "303000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9037e-22, 6.2069e-22, 1.0045e-13, 4.8612e-22],\n",
      "        [1.8949e-35, 2.1602e-35, 5.9953e-22, 1.8977e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4108e-06, 4.0454e-07, 1.0000e+00, 1.4869e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.9530e-15, 2.5237e-15, 1.0000e+00, 7.2647e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.5310e-20, 1.4812e-20, 1.0000e+00, 4.7827e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "304000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9040e-22, 6.2074e-22, 9.9504e-14, 4.8614e-22],\n",
      "        [1.8974e-35, 2.1630e-35, 5.9077e-22, 1.9002e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4195e-06, 4.0702e-07, 1.0000e+00, 1.4961e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.0620e-15, 2.5633e-15, 1.0000e+00, 7.3786e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.6320e-20, 1.5141e-20, 1.0000e+00, 4.8893e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "305000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9043e-22, 6.2080e-22, 9.8576e-14, 4.8617e-22],\n",
      "        [1.8999e-35, 2.1659e-35, 5.8223e-22, 1.9027e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4284e-06, 4.0957e-07, 1.0000e+00, 1.5055e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.1734e-15, 2.6037e-15, 1.0000e+00, 7.4951e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.7354e-20, 1.5480e-20, 1.0000e+00, 4.9985e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "306000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9045e-22, 6.2084e-22, 9.7658e-14, 4.8620e-22],\n",
      "        [1.9023e-35, 2.1687e-35, 5.7382e-22, 1.9052e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4373e-06, 4.1213e-07, 1.0000e+00, 1.5150e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.2868e-15, 2.6449e-15, 1.0000e+00, 7.6136e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.8412e-20, 1.5826e-20, 1.0000e+00, 5.1103e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "307000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9048e-22, 6.2090e-22, 9.6750e-14, 4.8622e-22],\n",
      "        [1.9048e-35, 2.1715e-35, 5.6552e-22, 1.9077e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4464e-06, 4.1472e-07, 1.0000e+00, 1.5245e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.4013e-15, 2.6865e-15, 1.0000e+00, 7.7333e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.9490e-20, 1.6178e-20, 1.0000e+00, 5.2242e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "308000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9051e-22, 6.2096e-22, 9.5855e-14, 4.8626e-22],\n",
      "        [1.9073e-35, 2.1744e-35, 5.5740e-22, 1.9102e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4554e-06, 4.1730e-07, 1.0000e+00, 1.5340e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.5174e-15, 2.7288e-15, 1.0000e+00, 7.8547e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.0589e-20, 1.6537e-20, 1.0000e+00, 5.3402e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "309000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9053e-22, 6.2101e-22, 9.4970e-14, 4.8629e-22],\n",
      "        [1.9098e-35, 2.1772e-35, 5.4942e-22, 1.9127e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4645e-06, 4.1991e-07, 1.0000e+00, 1.5436e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.6350e-15, 2.7715e-15, 1.0000e+00, 7.9777e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.1706e-20, 1.6903e-20, 1.0000e+00, 5.4583e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "310000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9057e-22, 6.2106e-22, 9.4099e-14, 4.8632e-22],\n",
      "        [1.9121e-35, 2.1800e-35, 5.4157e-22, 1.9150e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4738e-06, 4.2258e-07, 1.0000e+00, 1.5534e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.7545e-15, 2.8149e-15, 1.0000e+00, 8.1026e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.2847e-20, 1.7276e-20, 1.0000e+00, 5.5788e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "311000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9059e-22, 6.2112e-22, 9.3241e-14, 4.8635e-22],\n",
      "        [1.9144e-35, 2.1826e-35, 5.3389e-22, 1.9173e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4833e-06, 4.2529e-07, 1.0000e+00, 1.5634e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.8763e-15, 2.8592e-15, 1.0000e+00, 8.2300e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.4014e-20, 1.7657e-20, 1.0000e+00, 5.7019e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "312000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9062e-22, 6.2117e-22, 9.2395e-14, 4.8637e-22],\n",
      "        [1.9166e-35, 2.1851e-35, 5.2633e-22, 1.9196e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([1.4928e-06, 4.2802e-07, 1.0000e+00, 1.5734e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.9999e-15, 2.9042e-15, 1.0000e+00, 8.3593e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.5206e-20, 1.8047e-20, 1.0000e+00, 5.8279e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "313000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9065e-22, 6.2122e-22, 9.1555e-14, 4.8640e-22],\n",
      "        [1.9189e-35, 2.1878e-35, 5.1886e-22, 1.9218e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5024e-06, 4.3076e-07, 1.0000e+00, 1.5836e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.1256e-15, 2.9499e-15, 1.0000e+00, 8.4906e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.6426e-20, 1.8446e-20, 1.0000e+00, 5.9567e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "314000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9068e-22, 6.2128e-22, 9.0724e-14, 4.8643e-22],\n",
      "        [1.9211e-35, 2.1904e-35, 5.1151e-22, 1.9241e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5120e-06, 4.3354e-07, 1.0000e+00, 1.5938e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.2533e-15, 2.9963e-15, 1.0000e+00, 8.6242e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.7671e-20, 1.8853e-20, 1.0000e+00, 6.0882e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "315000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9071e-22, 6.2133e-22, 8.9900e-14, 4.8646e-22],\n",
      "        [1.9233e-35, 2.1929e-35, 5.0427e-22, 1.9263e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5218e-06, 4.3633e-07, 1.0000e+00, 1.6041e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.3823e-15, 3.0433e-15, 1.0000e+00, 8.7592e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.8938e-20, 1.9268e-20, 1.0000e+00, 6.2221e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "316000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9074e-22, 6.2137e-22, 8.9090e-14, 4.8648e-22],\n",
      "        [1.9255e-35, 2.1954e-35, 4.9717e-22, 1.9285e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5315e-06, 4.3913e-07, 1.0000e+00, 1.6143e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.5124e-15, 3.0906e-15, 1.0000e+00, 8.8951e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.0221e-20, 1.9687e-20, 1.0000e+00, 6.3577e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "317000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9075e-22, 6.2142e-22, 8.8296e-14, 4.8651e-22],\n",
      "        [1.9277e-35, 2.1979e-35, 4.9024e-22, 1.9307e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5413e-06, 4.4194e-07, 1.0000e+00, 1.6247e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.6442e-15, 3.1385e-15, 1.0000e+00, 9.0329e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.1528e-20, 2.0115e-20, 1.0000e+00, 6.4957e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "318000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9078e-22, 6.2147e-22, 8.7510e-14, 4.8654e-22],\n",
      "        [1.9299e-35, 2.2004e-35, 4.8344e-22, 1.9329e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5511e-06, 4.4475e-07, 1.0000e+00, 1.6350e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.7772e-15, 3.1869e-15, 1.0000e+00, 9.1721e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.2856e-20, 2.0549e-20, 1.0000e+00, 6.6359e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "319000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9080e-22, 6.2151e-22, 8.6736e-14, 4.8657e-22],\n",
      "        [1.9320e-35, 2.2028e-35, 4.7676e-22, 1.9350e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5610e-06, 4.4758e-07, 1.0000e+00, 1.6455e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.9123e-15, 3.2361e-15, 1.0000e+00, 9.3134e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.4213e-20, 2.0993e-20, 1.0000e+00, 6.7794e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "320000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9083e-22, 6.2158e-22, 8.5971e-14, 4.8659e-22],\n",
      "        [1.9340e-35, 2.2053e-35, 4.7018e-22, 1.9371e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5709e-06, 4.5043e-07, 1.0000e+00, 1.6560e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.0493e-15, 3.2859e-15, 1.0000e+00, 9.4567e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.5595e-20, 2.1445e-20, 1.0000e+00, 6.9253e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "321000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9086e-22, 6.2162e-22, 8.5213e-14, 4.8662e-22],\n",
      "        [1.9362e-35, 2.2077e-35, 4.6370e-22, 1.9392e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5809e-06, 4.5330e-07, 1.0000e+00, 1.6665e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.1880e-15, 3.3363e-15, 1.0000e+00, 9.6019e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.7004e-20, 2.1906e-20, 1.0000e+00, 7.0743e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "322000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9088e-22, 6.2167e-22, 8.4463e-14, 4.8665e-22],\n",
      "        [1.9382e-35, 2.2100e-35, 4.5731e-22, 1.9413e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([1.5897e-06, 4.5581e-07, 1.0000e+00, 1.6758e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.3137e-15, 3.3821e-15, 1.0000e+00, 9.7333e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.8291e-20, 2.2327e-20, 1.0000e+00, 7.2101e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "323000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9090e-22, 6.2169e-22, 8.3789e-14, 4.8666e-22],\n",
      "        [1.9400e-35, 2.2121e-35, 4.5160e-22, 1.9430e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5970e-06, 4.5789e-07, 1.0000e+00, 1.6835e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.4226e-15, 3.4216e-15, 1.0000e+00, 9.8471e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([6.9419e-20, 2.2696e-20, 1.0000e+00, 7.3295e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "324000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9092e-22, 6.2174e-22, 8.3204e-14, 4.8670e-22],\n",
      "        [1.9417e-35, 2.2141e-35, 4.4668e-22, 1.9448e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.6043e-06, 4.5998e-07, 1.0000e+00, 1.6912e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.5326e-15, 3.4617e-15, 1.0000e+00, 9.9623e-15],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.0567e-20, 2.3072e-20, 1.0000e+00, 7.4507e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "325000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9094e-22, 6.2178e-22, 8.2622e-14, 4.8671e-22],\n",
      "        [1.9434e-35, 2.2161e-35, 4.4182e-22, 1.9465e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.6116e-06, 4.6208e-07, 1.0000e+00, 1.6989e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.6439e-15, 3.5022e-15, 1.0000e+00, 1.0079e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.1732e-20, 2.3453e-20, 1.0000e+00, 7.5739e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "326000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9096e-22, 6.2183e-22, 8.2045e-14, 4.8674e-22],\n",
      "        [1.9452e-35, 2.2181e-35, 4.3702e-22, 1.9483e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.6190e-06, 4.6419e-07, 1.0000e+00, 1.7067e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.7565e-15, 3.5431e-15, 1.0000e+00, 1.0196e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.2918e-20, 2.3841e-20, 1.0000e+00, 7.6990e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "327000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9099e-22, 6.2187e-22, 8.1473e-14, 4.8677e-22],\n",
      "        [1.9469e-35, 2.2201e-35, 4.3226e-22, 1.9500e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.6262e-06, 4.6627e-07, 1.0000e+00, 1.7144e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.8683e-15, 3.5838e-15, 1.0000e+00, 1.0313e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.4098e-20, 2.4227e-20, 1.0000e+00, 7.8238e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "328000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9101e-22, 6.2191e-22, 8.0915e-14, 4.8678e-22],\n",
      "        [1.9486e-35, 2.2220e-35, 4.2765e-22, 1.9517e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.6335e-06, 4.6836e-07, 1.0000e+00, 1.7220e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.9809e-15, 3.6248e-15, 1.0000e+00, 1.0431e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.5293e-20, 2.4619e-20, 1.0000e+00, 7.9501e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "329000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9103e-22, 6.2196e-22, 8.0364e-14, 4.8680e-22],\n",
      "        [1.9502e-35, 2.2239e-35, 4.2311e-22, 1.9534e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.6408e-06, 4.7045e-07, 1.0000e+00, 1.7298e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0095e-14, 3.6662e-15, 1.0000e+00, 1.0550e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.6506e-20, 2.5015e-20, 1.0000e+00, 8.0784e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "330000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9106e-22, 6.2200e-22, 7.9818e-14, 4.8683e-22],\n",
      "        [1.9519e-35, 2.2259e-35, 4.1862e-22, 1.9551e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.6482e-06, 4.7256e-07, 1.0000e+00, 1.7375e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0209e-14, 3.7079e-15, 1.0000e+00, 1.0670e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.7733e-20, 2.5416e-20, 1.0000e+00, 8.2080e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "331000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9107e-22, 6.2205e-22, 7.9277e-14, 4.8685e-22],\n",
      "        [1.9534e-35, 2.2276e-35, 4.1418e-22, 1.9566e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.6555e-06, 4.7468e-07, 1.0000e+00, 1.7453e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0325e-14, 3.7501e-15, 1.0000e+00, 1.0792e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([7.8975e-20, 2.5823e-20, 1.0000e+00, 8.3394e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "332000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9110e-22, 6.2208e-22, 7.8742e-14, 4.8688e-22],\n",
      "        [1.9548e-35, 2.2293e-35, 4.0979e-22, 1.9580e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([1.6630e-06, 4.7681e-07, 1.0000e+00, 1.7532e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0443e-14, 3.7928e-15, 1.0000e+00, 1.0914e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.0237e-20, 2.6236e-20, 1.0000e+00, 8.4727e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "333000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9112e-22, 6.2211e-22, 7.8210e-14, 4.8689e-22],\n",
      "        [1.9562e-35, 2.2309e-35, 4.0544e-22, 1.9594e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.6706e-06, 4.7898e-07, 1.0000e+00, 1.7612e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0562e-14, 3.8361e-15, 1.0000e+00, 1.1039e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.1524e-20, 2.6657e-20, 1.0000e+00, 8.6087e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "334000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9114e-22, 6.2216e-22, 7.7685e-14, 4.8692e-22],\n",
      "        [1.9577e-35, 2.2325e-35, 4.0116e-22, 1.9608e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.6783e-06, 4.8119e-07, 1.0000e+00, 1.7694e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0683e-14, 3.8801e-15, 1.0000e+00, 1.1166e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.2835e-20, 2.7085e-20, 1.0000e+00, 8.7472e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "335000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9116e-22, 6.2219e-22, 7.7162e-14, 4.8694e-22],\n",
      "        [1.9591e-35, 2.2342e-35, 3.9693e-22, 1.9623e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.6861e-06, 4.8342e-07, 1.0000e+00, 1.7776e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0805e-14, 3.9246e-15, 1.0000e+00, 1.1294e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.4167e-20, 2.7521e-20, 1.0000e+00, 8.8880e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "336000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9117e-22, 6.2223e-22, 7.6644e-14, 4.8695e-22],\n",
      "        [1.9605e-35, 2.2358e-35, 3.9273e-22, 1.9637e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.6939e-06, 4.8566e-07, 1.0000e+00, 1.7858e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0929e-14, 3.9697e-15, 1.0000e+00, 1.1423e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.5520e-20, 2.7963e-20, 1.0000e+00, 9.0309e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "337000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9120e-22, 6.2226e-22, 7.6128e-14, 4.8697e-22],\n",
      "        [1.9619e-35, 2.2375e-35, 3.8860e-22, 1.9651e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.7018e-06, 4.8792e-07, 1.0000e+00, 1.7942e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1055e-14, 4.0154e-15, 1.0000e+00, 1.1555e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.6897e-20, 2.8414e-20, 1.0000e+00, 9.1764e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "338000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9121e-22, 6.2230e-22, 7.5618e-14, 4.8699e-22],\n",
      "        [1.9633e-35, 2.2391e-35, 3.8450e-22, 1.9665e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.7098e-06, 4.9019e-07, 1.0000e+00, 1.8026e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1182e-14, 4.0614e-15, 1.0000e+00, 1.1687e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.8292e-20, 2.8870e-20, 1.0000e+00, 9.3239e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "339000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9123e-22, 6.2234e-22, 7.5113e-14, 4.8701e-22],\n",
      "        [1.9647e-35, 2.2407e-35, 3.8047e-22, 1.9680e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.7178e-06, 4.9248e-07, 1.0000e+00, 1.8110e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1310e-14, 4.1080e-15, 1.0000e+00, 1.1821e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([8.9707e-20, 2.9333e-20, 1.0000e+00, 9.4734e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "340000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9125e-22, 6.2237e-22, 7.4612e-14, 4.8703e-22],\n",
      "        [1.9661e-35, 2.2423e-35, 3.7648e-22, 1.9694e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.7258e-06, 4.9479e-07, 1.0000e+00, 1.8195e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1440e-14, 4.1552e-15, 1.0000e+00, 1.1957e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.1143e-20, 2.9802e-20, 1.0000e+00, 9.6251e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "341000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9127e-22, 6.2240e-22, 7.4115e-14, 4.8706e-22],\n",
      "        [1.9674e-35, 2.2438e-35, 3.7252e-22, 1.9706e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.7339e-06, 4.9711e-07, 1.0000e+00, 1.8281e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1571e-14, 4.2028e-15, 1.0000e+00, 1.2094e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.2601e-20, 3.0279e-20, 1.0000e+00, 9.7792e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "342000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9129e-22, 6.2243e-22, 7.3621e-14, 4.8706e-22],\n",
      "        [1.9686e-35, 2.2452e-35, 3.6861e-22, 1.9718e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([1.7420e-06, 4.9943e-07, 1.0000e+00, 1.8366e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1703e-14, 4.2509e-15, 1.0000e+00, 1.2233e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.4080e-20, 3.0763e-20, 1.0000e+00, 9.9354e-20],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "343000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9130e-22, 6.2247e-22, 7.3132e-14, 4.8709e-22],\n",
      "        [1.9698e-35, 2.2466e-35, 3.6474e-22, 1.9731e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.7501e-06, 5.0173e-07, 1.0000e+00, 1.8451e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1835e-14, 4.2989e-15, 1.0000e+00, 1.2371e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.5561e-20, 3.1247e-20, 1.0000e+00, 1.0092e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "344000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9132e-22, 6.2250e-22, 7.2654e-14, 4.8710e-22],\n",
      "        [1.9711e-35, 2.2481e-35, 3.6098e-22, 1.9743e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.7581e-06, 5.0403e-07, 1.0000e+00, 1.8536e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1968e-14, 4.3472e-15, 1.0000e+00, 1.2510e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.7058e-20, 3.1737e-20, 1.0000e+00, 1.0250e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "345000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9133e-22, 6.2253e-22, 7.2181e-14, 4.8713e-22],\n",
      "        [1.9723e-35, 2.2495e-35, 3.5727e-22, 1.9756e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.7661e-06, 5.0633e-07, 1.0000e+00, 1.8621e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2101e-14, 4.3956e-15, 1.0000e+00, 1.2649e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([9.8566e-20, 3.2230e-20, 1.0000e+00, 1.0410e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "346000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9135e-22, 6.2257e-22, 7.1713e-14, 4.8714e-22],\n",
      "        [1.9735e-35, 2.2509e-35, 3.5362e-22, 1.9768e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.7741e-06, 5.0860e-07, 1.0000e+00, 1.8705e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2235e-14, 4.4441e-15, 1.0000e+00, 1.2789e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0008e-19, 3.2726e-20, 1.0000e+00, 1.0570e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "347000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9138e-22, 6.2260e-22, 7.1254e-14, 4.8716e-22],\n",
      "        [1.9747e-35, 2.2523e-35, 3.5004e-22, 1.9780e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.7821e-06, 5.1090e-07, 1.0000e+00, 1.8790e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2370e-14, 4.4933e-15, 1.0000e+00, 1.2930e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0163e-19, 3.3231e-20, 1.0000e+00, 1.0733e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "348000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9140e-22, 6.2264e-22, 7.0797e-14, 4.8718e-22],\n",
      "        [1.9760e-35, 2.2538e-35, 3.4650e-22, 1.9793e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.7902e-06, 5.1322e-07, 1.0000e+00, 1.8875e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2506e-14, 4.5430e-15, 1.0000e+00, 1.3073e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0320e-19, 3.3744e-20, 1.0000e+00, 1.0899e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "349000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9141e-22, 6.2267e-22, 7.0343e-14, 4.8720e-22],\n",
      "        [1.9772e-35, 2.2552e-35, 3.4300e-22, 1.9805e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.7983e-06, 5.1554e-07, 1.0000e+00, 1.8961e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2645e-14, 4.5931e-15, 1.0000e+00, 1.3217e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0479e-19, 3.4265e-20, 1.0000e+00, 1.1067e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "350000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9144e-22, 6.2270e-22, 6.9893e-14, 4.8723e-22],\n",
      "        [1.9784e-35, 2.2566e-35, 3.3954e-22, 1.9818e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.8065e-06, 5.1787e-07, 1.0000e+00, 1.9047e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2784e-14, 4.6439e-15, 1.0000e+00, 1.3364e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0640e-19, 3.4792e-20, 1.0000e+00, 1.1238e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "351000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9144e-22, 6.2273e-22, 6.9446e-14, 4.8723e-22],\n",
      "        [1.9796e-35, 2.2581e-35, 3.3611e-22, 1.9830e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.8147e-06, 5.2021e-07, 1.0000e+00, 1.9133e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2924e-14, 4.6949e-15, 1.0000e+00, 1.3510e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0803e-19, 3.5324e-20, 1.0000e+00, 1.1409e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "352000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9146e-22, 6.2276e-22, 6.9005e-14, 4.8726e-22],\n",
      "        [1.9808e-35, 2.2594e-35, 3.3274e-22, 1.9842e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([1.8228e-06, 5.2254e-07, 1.0000e+00, 1.9219e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3065e-14, 4.7460e-15, 1.0000e+00, 1.3657e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.0967e-19, 3.5860e-20, 1.0000e+00, 1.1583e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "353000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9149e-22, 6.2280e-22, 6.8570e-14, 4.8728e-22],\n",
      "        [1.9820e-35, 2.2608e-35, 3.2943e-22, 1.9854e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.8310e-06, 5.2488e-07, 1.0000e+00, 1.9305e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3208e-14, 4.7977e-15, 1.0000e+00, 1.3806e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1133e-19, 3.6404e-20, 1.0000e+00, 1.1759e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "354000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9151e-22, 6.2283e-22, 6.8139e-14, 4.8729e-22],\n",
      "        [1.9831e-35, 2.2620e-35, 3.2614e-22, 1.9865e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.8393e-06, 5.2725e-07, 1.0000e+00, 1.9393e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3352e-14, 4.8502e-15, 1.0000e+00, 1.3957e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1302e-19, 3.6956e-20, 1.0000e+00, 1.1937e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "355000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9152e-22, 6.2286e-22, 6.7710e-14, 4.8731e-22],\n",
      "        [1.9841e-35, 2.2632e-35, 3.2289e-22, 1.9875e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.8476e-06, 5.2963e-07, 1.0000e+00, 1.9481e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3498e-14, 4.9032e-15, 1.0000e+00, 1.4110e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1474e-19, 3.7517e-20, 1.0000e+00, 1.2118e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "356000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9153e-22, 6.2289e-22, 6.7284e-14, 4.8732e-22],\n",
      "        [1.9850e-35, 2.2643e-35, 3.1966e-22, 1.9885e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.8560e-06, 5.3202e-07, 1.0000e+00, 1.9569e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3645e-14, 4.9567e-15, 1.0000e+00, 1.4264e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1648e-19, 3.8086e-20, 1.0000e+00, 1.2302e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "357000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9155e-22, 6.2292e-22, 6.6861e-14, 4.8734e-22],\n",
      "        [1.9861e-35, 2.2655e-35, 3.1647e-22, 1.9895e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.8644e-06, 5.3442e-07, 1.0000e+00, 1.9658e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3794e-14, 5.0108e-15, 1.0000e+00, 1.4420e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.1824e-19, 3.8663e-20, 1.0000e+00, 1.2489e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "358000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9157e-22, 6.2295e-22, 6.6440e-14, 4.8735e-22],\n",
      "        [1.9870e-35, 2.2667e-35, 3.1331e-22, 1.9905e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.8728e-06, 5.3684e-07, 1.0000e+00, 1.9747e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3945e-14, 5.0655e-15, 1.0000e+00, 1.4577e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2003e-19, 3.9250e-20, 1.0000e+00, 1.2678e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "359000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9159e-22, 6.2298e-22, 6.6023e-14, 4.8737e-22],\n",
      "        [1.9880e-35, 2.2677e-35, 3.1018e-22, 1.9914e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.8813e-06, 5.3926e-07, 1.0000e+00, 1.9837e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4096e-14, 5.1207e-15, 1.0000e+00, 1.4736e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2185e-19, 3.9843e-20, 1.0000e+00, 1.2870e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "360000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9160e-22, 6.2301e-22, 6.5609e-14, 4.8739e-22],\n",
      "        [1.9889e-35, 2.2689e-35, 3.0709e-22, 1.9924e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.8898e-06, 5.4169e-07, 1.0000e+00, 1.9926e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4249e-14, 5.1762e-15, 1.0000e+00, 1.4896e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2368e-19, 4.0443e-20, 1.0000e+00, 1.3064e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "361000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9162e-22, 6.2303e-22, 6.5201e-14, 4.8741e-22],\n",
      "        [1.9899e-35, 2.2700e-35, 3.0404e-22, 1.9933e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.8983e-06, 5.4412e-07, 1.0000e+00, 2.0016e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4404e-14, 5.2323e-15, 1.0000e+00, 1.5058e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2555e-19, 4.1051e-20, 1.0000e+00, 1.3261e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "362000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9164e-22, 6.2307e-22, 6.4795e-14, 4.8743e-22],\n",
      "        [1.9908e-35, 2.2711e-35, 3.0103e-22, 1.9943e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([1.9069e-06, 5.4656e-07, 1.0000e+00, 2.0106e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4560e-14, 5.2890e-15, 1.0000e+00, 1.5221e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2743e-19, 4.1667e-20, 1.0000e+00, 1.3460e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "363000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9165e-22, 6.2311e-22, 6.4392e-14, 4.8745e-22],\n",
      "        [1.9917e-35, 2.2722e-35, 2.9806e-22, 1.9952e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.9154e-06, 5.4901e-07, 1.0000e+00, 2.0197e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4717e-14, 5.3460e-15, 1.0000e+00, 1.5385e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.2934e-19, 4.2291e-20, 1.0000e+00, 1.3661e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "364000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9166e-22, 6.2312e-22, 6.3992e-14, 4.8746e-22],\n",
      "        [1.9927e-35, 2.2733e-35, 2.9512e-22, 1.9962e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.9240e-06, 5.5146e-07, 1.0000e+00, 2.0287e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4875e-14, 5.4035e-15, 1.0000e+00, 1.5551e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3127e-19, 4.2923e-20, 1.0000e+00, 1.3865e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "365000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9169e-22, 6.2316e-22, 6.3597e-14, 4.8748e-22],\n",
      "        [1.9937e-35, 2.2744e-35, 2.9221e-22, 1.9972e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.9326e-06, 5.5391e-07, 1.0000e+00, 2.0378e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5035e-14, 5.4614e-15, 1.0000e+00, 1.5717e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3322e-19, 4.3561e-20, 1.0000e+00, 1.4072e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "366000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9171e-22, 6.2318e-22, 6.3206e-14, 4.8750e-22],\n",
      "        [1.9946e-35, 2.2755e-35, 2.8935e-22, 1.9981e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.9411e-06, 5.5633e-07, 1.0000e+00, 2.0468e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5193e-14, 5.5189e-15, 1.0000e+00, 1.5883e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3517e-19, 4.4197e-20, 1.0000e+00, 1.4278e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "367000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9172e-22, 6.2322e-22, 6.2823e-14, 4.8751e-22],\n",
      "        [1.9956e-35, 2.2766e-35, 2.8658e-22, 1.9991e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.9496e-06, 5.5877e-07, 1.0000e+00, 2.0557e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5353e-14, 5.5770e-15, 1.0000e+00, 1.6050e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3714e-19, 4.4843e-20, 1.0000e+00, 1.4486e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "368000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9174e-22, 6.2325e-22, 6.2444e-14, 4.8753e-22],\n",
      "        [1.9965e-35, 2.2778e-35, 2.8382e-22, 2.0000e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.9581e-06, 5.6121e-07, 1.0000e+00, 2.0648e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5515e-14, 5.6358e-15, 1.0000e+00, 1.6219e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.3915e-19, 4.5498e-20, 1.0000e+00, 1.4698e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "369000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9175e-22, 6.2328e-22, 6.2066e-14, 4.8755e-22],\n",
      "        [1.9974e-35, 2.2788e-35, 2.8109e-22, 2.0010e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.9667e-06, 5.6366e-07, 1.0000e+00, 2.0738e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5678e-14, 5.6950e-15, 1.0000e+00, 1.6390e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4117e-19, 4.6162e-20, 1.0000e+00, 1.4913e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "370000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9177e-22, 6.2330e-22, 6.1692e-14, 4.8756e-22],\n",
      "        [1.9983e-35, 2.2799e-35, 2.7839e-22, 2.0019e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.9753e-06, 5.6613e-07, 1.0000e+00, 2.0829e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5842e-14, 5.7549e-15, 1.0000e+00, 1.6563e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4324e-19, 4.6836e-20, 1.0000e+00, 1.5130e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "371000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9179e-22, 6.2334e-22, 6.1320e-14, 4.8758e-22],\n",
      "        [1.9993e-35, 2.2811e-35, 2.7572e-22, 2.0029e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.9840e-06, 5.6861e-07, 1.0000e+00, 2.0921e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.6009e-14, 5.8155e-15, 1.0000e+00, 1.6737e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4533e-19, 4.7520e-20, 1.0000e+00, 1.5352e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "372000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9180e-22, 6.2336e-22, 6.0949e-14, 4.8760e-22],\n",
      "        [2.0002e-35, 2.2821e-35, 2.7308e-22, 2.0038e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([1.9928e-06, 5.7110e-07, 1.0000e+00, 2.1013e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.6178e-14, 5.8767e-15, 1.0000e+00, 1.6913e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4745e-19, 4.8213e-20, 1.0000e+00, 1.5576e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "373000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9181e-22, 6.2339e-22, 6.0582e-14, 4.8762e-22],\n",
      "        [2.0012e-35, 2.2833e-35, 2.7046e-22, 2.0047e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.0015e-06, 5.7360e-07, 1.0000e+00, 2.1106e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.6348e-14, 5.9384e-15, 1.0000e+00, 1.7091e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.4960e-19, 4.8916e-20, 1.0000e+00, 1.5803e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "374000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9184e-22, 6.2342e-22, 6.0217e-14, 4.8763e-22],\n",
      "        [2.0021e-35, 2.2844e-35, 2.6787e-22, 2.0057e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.0103e-06, 5.7612e-07, 1.0000e+00, 2.1199e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.6520e-14, 6.0010e-15, 1.0000e+00, 1.7271e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5178e-19, 4.9630e-20, 1.0000e+00, 1.6034e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "375000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9185e-22, 6.2346e-22, 5.9854e-14, 4.8765e-22],\n",
      "        [2.0030e-35, 2.2854e-35, 2.6530e-22, 2.0066e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.0192e-06, 5.7864e-07, 1.0000e+00, 2.1292e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.6693e-14, 6.0640e-15, 1.0000e+00, 1.7453e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5399e-19, 5.0354e-20, 1.0000e+00, 1.6268e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "376000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9186e-22, 6.2348e-22, 5.9493e-14, 4.8766e-22],\n",
      "        [2.0040e-35, 2.2866e-35, 2.6276e-22, 2.0076e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.0280e-06, 5.8118e-07, 1.0000e+00, 2.1386e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.6869e-14, 6.1277e-15, 1.0000e+00, 1.7636e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5624e-19, 5.1087e-20, 1.0000e+00, 1.6505e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "377000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9188e-22, 6.2350e-22, 5.9135e-14, 4.8768e-22],\n",
      "        [2.0049e-35, 2.2876e-35, 2.6025e-22, 2.0085e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.0369e-06, 5.8372e-07, 1.0000e+00, 2.1480e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.7046e-14, 6.1921e-15, 1.0000e+00, 1.7822e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.5852e-19, 5.1832e-20, 1.0000e+00, 1.6746e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "378000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9189e-22, 6.2353e-22, 5.8779e-14, 4.8770e-22],\n",
      "        [2.0059e-35, 2.2887e-35, 2.5775e-22, 2.0095e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.0459e-06, 5.8628e-07, 1.0000e+00, 2.1574e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.7226e-14, 6.2572e-15, 1.0000e+00, 1.8010e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.6083e-19, 5.2588e-20, 1.0000e+00, 1.6990e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "379000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9191e-22, 6.2356e-22, 5.8425e-14, 4.8771e-22],\n",
      "        [2.0068e-35, 2.2898e-35, 2.5529e-22, 2.0104e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.0549e-06, 5.8885e-07, 1.0000e+00, 2.1669e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.7407e-14, 6.3230e-15, 1.0000e+00, 1.8199e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.6317e-19, 5.3354e-20, 1.0000e+00, 1.7238e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "380000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9193e-22, 6.2358e-22, 5.8073e-14, 4.8773e-22],\n",
      "        [2.0078e-35, 2.2909e-35, 2.5284e-22, 2.0114e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.0639e-06, 5.9143e-07, 1.0000e+00, 2.1765e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.7589e-14, 6.3895e-15, 1.0000e+00, 1.8390e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.6555e-19, 5.4132e-20, 1.0000e+00, 1.7490e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "381000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9194e-22, 6.2361e-22, 5.7723e-14, 4.8774e-22],\n",
      "        [2.0087e-35, 2.2921e-35, 2.5042e-22, 2.0124e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.0730e-06, 5.9403e-07, 1.0000e+00, 2.1861e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.7775e-14, 6.4568e-15, 1.0000e+00, 1.8584e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.6797e-19, 5.4921e-20, 1.0000e+00, 1.7745e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "382000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9196e-22, 6.2365e-22, 5.7377e-14, 4.8776e-22],\n",
      "        [2.0097e-35, 2.2932e-35, 2.4803e-22, 2.0133e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([2.0821e-06, 5.9663e-07, 1.0000e+00, 2.1957e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.7962e-14, 6.5246e-15, 1.0000e+00, 1.8779e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.7042e-19, 5.5722e-20, 1.0000e+00, 1.8004e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "383000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9198e-22, 6.2366e-22, 5.7031e-14, 4.8777e-22],\n",
      "        [2.0106e-35, 2.2943e-35, 2.4565e-22, 2.0142e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.0913e-06, 5.9925e-07, 9.9999e-01, 2.2054e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.8150e-14, 6.5933e-15, 1.0000e+00, 1.8977e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.7290e-19, 5.6533e-20, 1.0000e+00, 1.8266e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "384000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9198e-22, 6.2370e-22, 5.6688e-14, 4.8779e-22],\n",
      "        [2.0115e-35, 2.2953e-35, 2.4331e-22, 2.0152e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.1004e-06, 6.0184e-07, 9.9999e-01, 2.2150e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.8338e-14, 6.6614e-15, 1.0000e+00, 1.9174e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.7538e-19, 5.7345e-20, 1.0000e+00, 1.8528e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "385000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9200e-22, 6.2373e-22, 5.6353e-14, 4.8781e-22],\n",
      "        [2.0125e-35, 2.2965e-35, 2.4102e-22, 2.0161e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.1095e-06, 6.0444e-07, 9.9999e-01, 2.2246e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.8528e-14, 6.7303e-15, 1.0000e+00, 1.9372e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.7789e-19, 5.8166e-20, 1.0000e+00, 1.8794e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "386000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9202e-22, 6.2377e-22, 5.6020e-14, 4.8782e-22],\n",
      "        [2.0134e-35, 2.2976e-35, 2.3876e-22, 2.0171e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.1186e-06, 6.0704e-07, 9.9999e-01, 2.2342e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.8719e-14, 6.7996e-15, 1.0000e+00, 1.9572e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.8044e-19, 5.8998e-20, 1.0000e+00, 1.9063e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "387000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9203e-22, 6.2378e-22, 5.5690e-14, 4.8784e-22],\n",
      "        [2.0144e-35, 2.2987e-35, 2.3652e-22, 2.0180e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.1277e-06, 6.0964e-07, 9.9999e-01, 2.2438e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.8910e-14, 6.8690e-15, 1.0000e+00, 1.9772e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.8299e-19, 5.9834e-20, 1.0000e+00, 1.9333e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "388000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9205e-22, 6.2381e-22, 5.5365e-14, 4.8786e-22],\n",
      "        [2.0153e-35, 2.2998e-35, 2.3432e-22, 2.0190e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.1368e-06, 6.1223e-07, 9.9999e-01, 2.2534e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.9102e-14, 6.9387e-15, 1.0000e+00, 1.9973e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.8557e-19, 6.0675e-20, 1.0000e+00, 1.9606e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "389000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9207e-22, 6.2384e-22, 5.5043e-14, 4.8787e-22],\n",
      "        [2.0162e-35, 2.3009e-35, 2.3216e-22, 2.0200e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.1459e-06, 6.1483e-07, 9.9999e-01, 2.2630e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.9296e-14, 7.0093e-15, 1.0000e+00, 2.0176e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.8818e-19, 6.1530e-20, 1.0000e+00, 1.9882e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "390000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9208e-22, 6.2387e-22, 5.4725e-14, 4.8789e-22],\n",
      "        [2.0171e-35, 2.3019e-35, 2.3002e-22, 2.0208e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.1552e-06, 6.1750e-07, 9.9999e-01, 2.2729e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.9494e-14, 7.0811e-15, 1.0000e+00, 2.0383e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.9084e-19, 6.2397e-20, 1.0000e+00, 2.0162e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "391000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9210e-22, 6.2390e-22, 5.4407e-14, 4.8790e-22],\n",
      "        [2.0176e-35, 2.3025e-35, 2.2786e-22, 2.0213e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.1646e-06, 6.2018e-07, 9.9999e-01, 2.2828e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.9693e-14, 7.1536e-15, 1.0000e+00, 2.0591e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.9352e-19, 6.3275e-20, 1.0000e+00, 2.0446e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "392000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9211e-22, 6.2392e-22, 5.4092e-14, 4.8791e-22],\n",
      "        [2.0181e-35, 2.3030e-35, 2.2573e-22, 2.0218e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([2.1740e-06, 6.2287e-07, 9.9999e-01, 2.2927e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.9895e-14, 7.2266e-15, 1.0000e+00, 2.0802e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.9624e-19, 6.4163e-20, 1.0000e+00, 2.0734e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "393000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9212e-22, 6.2395e-22, 5.3779e-14, 4.8793e-22],\n",
      "        [2.0185e-35, 2.3036e-35, 2.2363e-22, 2.0223e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.1835e-06, 6.2557e-07, 9.9999e-01, 2.3027e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.0097e-14, 7.3003e-15, 1.0000e+00, 2.1014e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([1.9899e-19, 6.5062e-20, 1.0000e+00, 2.1024e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "394000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9213e-22, 6.2397e-22, 5.3468e-14, 4.8795e-22],\n",
      "        [2.0190e-35, 2.3041e-35, 2.2154e-22, 2.0228e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.1929e-06, 6.2827e-07, 9.9999e-01, 2.3127e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.0302e-14, 7.3747e-15, 1.0000e+00, 2.1228e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.0178e-19, 6.5974e-20, 1.0000e+00, 2.1319e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "395000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9215e-22, 6.2399e-22, 5.3160e-14, 4.8796e-22],\n",
      "        [2.0195e-35, 2.3047e-35, 2.1948e-22, 2.0233e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.2024e-06, 6.3099e-07, 9.9999e-01, 2.3227e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.0509e-14, 7.4499e-15, 1.0000e+00, 2.1445e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.0460e-19, 6.6897e-20, 1.0000e+00, 2.1618e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "396000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9216e-22, 6.2401e-22, 5.2853e-14, 4.8797e-22],\n",
      "        [2.0200e-35, 2.3052e-35, 2.1744e-22, 2.0237e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.2120e-06, 6.3371e-07, 9.9999e-01, 2.3328e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.0717e-14, 7.5256e-15, 1.0000e+00, 2.1663e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.0746e-19, 6.7834e-20, 1.0000e+00, 2.1920e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "397000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9217e-22, 6.2405e-22, 5.2549e-14, 4.8798e-22],\n",
      "        [2.0204e-35, 2.3059e-35, 2.1542e-22, 2.0242e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.2215e-06, 6.3645e-07, 9.9999e-01, 2.3429e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.0928e-14, 7.6021e-15, 1.0000e+00, 2.1883e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.1036e-19, 6.8780e-20, 1.0000e+00, 2.2227e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "398000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9219e-22, 6.2408e-22, 5.2247e-14, 4.8801e-22],\n",
      "        [2.0209e-35, 2.3064e-35, 2.1342e-22, 2.0247e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.2311e-06, 6.3918e-07, 9.9999e-01, 2.3530e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.1140e-14, 7.6790e-15, 1.0000e+00, 2.2105e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.1329e-19, 6.9736e-20, 1.0000e+00, 2.2536e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "399000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9220e-22, 6.2409e-22, 5.1948e-14, 4.8801e-22],\n",
      "        [2.0214e-35, 2.3070e-35, 2.1145e-22, 2.0251e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.2407e-06, 6.4193e-07, 9.9999e-01, 2.3631e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.1353e-14, 7.7564e-15, 1.0000e+00, 2.2328e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.1624e-19, 7.0702e-20, 1.0000e+00, 2.2848e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "400000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9222e-22, 6.2411e-22, 5.1653e-14, 4.8802e-22],\n",
      "        [2.0218e-35, 2.3075e-35, 2.0950e-22, 2.0256e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.2504e-06, 6.4469e-07, 9.9999e-01, 2.3734e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.1568e-14, 7.8348e-15, 1.0000e+00, 2.2553e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.1924e-19, 7.1681e-20, 1.0000e+00, 2.3165e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "401000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9222e-22, 6.2414e-22, 5.1359e-14, 4.8803e-22],\n",
      "        [2.0222e-35, 2.3080e-35, 2.0758e-22, 2.0260e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.2601e-06, 6.4747e-07, 9.9999e-01, 2.3836e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.1786e-14, 7.9138e-15, 1.0000e+00, 2.2781e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.2228e-19, 7.2674e-20, 1.0000e+00, 2.3486e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "402000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9224e-22, 6.2416e-22, 5.1066e-14, 4.8806e-22],\n",
      "        [2.0227e-35, 2.3085e-35, 2.0567e-22, 2.0265e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([2.2699e-06, 6.5025e-07, 9.9999e-01, 2.3939e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.2006e-14, 7.9937e-15, 1.0000e+00, 2.3011e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.2536e-19, 7.3681e-20, 1.0000e+00, 2.3812e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "403000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9225e-22, 6.2419e-22, 5.0775e-14, 4.8807e-22],\n",
      "        [2.0231e-35, 2.3090e-35, 2.0378e-22, 2.0269e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.2797e-06, 6.5305e-07, 9.9999e-01, 2.4043e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.2228e-14, 8.0745e-15, 1.0000e+00, 2.3244e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.2848e-19, 7.4702e-20, 1.0000e+00, 2.4142e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "404000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9227e-22, 6.2421e-22, 5.0486e-14, 4.8808e-22],\n",
      "        [2.0236e-35, 2.3095e-35, 2.0191e-22, 2.0273e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.2881e-06, 6.5548e-07, 9.9999e-01, 2.4132e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.2426e-14, 8.1462e-15, 1.0000e+00, 2.3451e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.3128e-19, 7.5618e-20, 1.0000e+00, 2.4438e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "405000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9227e-22, 6.2423e-22, 5.0228e-14, 4.8809e-22],\n",
      "        [2.0240e-35, 2.3100e-35, 2.0024e-22, 2.0278e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.2937e-06, 6.5706e-07, 9.9999e-01, 2.4191e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.2568e-14, 8.1981e-15, 1.0000e+00, 2.3600e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.3334e-19, 7.6291e-20, 1.0000e+00, 2.4656e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "406000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9230e-22, 6.2427e-22, 5.0034e-14, 4.8811e-22],\n",
      "        [2.0244e-35, 2.3105e-35, 1.9899e-22, 2.0282e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.2993e-06, 6.5865e-07, 9.9999e-01, 2.4250e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.2711e-14, 8.2500e-15, 1.0000e+00, 2.3750e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.3542e-19, 7.6968e-20, 1.0000e+00, 2.4875e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "407000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9230e-22, 6.2429e-22, 4.9841e-14, 4.8812e-22],\n",
      "        [2.0248e-35, 2.3110e-35, 1.9776e-22, 2.0286e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.3049e-06, 6.6024e-07, 9.9999e-01, 2.4309e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.2855e-14, 8.3023e-15, 1.0000e+00, 2.3900e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.3750e-19, 7.7651e-20, 1.0000e+00, 2.5097e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "408000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9232e-22, 6.2431e-22, 4.9648e-14, 4.8814e-22],\n",
      "        [2.0252e-35, 2.3115e-35, 1.9654e-22, 2.0290e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.3104e-06, 6.6182e-07, 9.9999e-01, 2.4368e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.2999e-14, 8.3544e-15, 1.0000e+00, 2.4051e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.3960e-19, 7.8334e-20, 1.0000e+00, 2.5318e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "409000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9233e-22, 6.2434e-22, 4.9458e-14, 4.8814e-22],\n",
      "        [2.0257e-35, 2.3120e-35, 1.9534e-22, 2.0295e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.3159e-06, 6.6339e-07, 9.9999e-01, 2.4426e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.3143e-14, 8.4066e-15, 1.0000e+00, 2.4201e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.4169e-19, 7.9017e-20, 1.0000e+00, 2.5538e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "410000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9234e-22, 6.2435e-22, 4.9270e-14, 4.8816e-22],\n",
      "        [2.0261e-35, 2.3125e-35, 1.9415e-22, 2.0299e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.3214e-06, 6.6496e-07, 9.9999e-01, 2.4484e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.3287e-14, 8.4589e-15, 1.0000e+00, 2.4352e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.4379e-19, 7.9706e-20, 1.0000e+00, 2.5762e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "411000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9236e-22, 6.2438e-22, 4.9084e-14, 4.8819e-22],\n",
      "        [2.0265e-35, 2.3130e-35, 1.9296e-22, 2.0303e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.3270e-06, 6.6655e-07, 9.9999e-01, 2.4543e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.3432e-14, 8.5117e-15, 1.0000e+00, 2.4504e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.4593e-19, 8.0403e-20, 1.0000e+00, 2.5987e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "412000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9237e-22, 6.2441e-22, 4.8897e-14, 4.8820e-22],\n",
      "        [2.0269e-35, 2.3135e-35, 1.9179e-22, 2.0308e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([2.3326e-06, 6.6815e-07, 9.9999e-01, 2.4603e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.3578e-14, 8.5650e-15, 1.0000e+00, 2.4657e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.4808e-19, 8.1106e-20, 1.0000e+00, 2.6215e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "413000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9238e-22, 6.2443e-22, 4.8712e-14, 4.8821e-22],\n",
      "        [2.0274e-35, 2.3140e-35, 1.9063e-22, 2.0312e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.3383e-06, 6.6977e-07, 9.9999e-01, 2.4662e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.3726e-14, 8.6186e-15, 1.0000e+00, 2.4812e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.5025e-19, 8.1815e-20, 1.0000e+00, 2.6444e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "414000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9240e-22, 6.2446e-22, 4.8528e-14, 4.8822e-22],\n",
      "        [2.0278e-35, 2.3146e-35, 1.8948e-22, 2.0316e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.3439e-06, 6.7137e-07, 9.9999e-01, 2.4722e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.3873e-14, 8.6721e-15, 1.0000e+00, 2.4967e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.5242e-19, 8.2526e-20, 1.0000e+00, 2.6674e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "415000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9241e-22, 6.2448e-22, 4.8345e-14, 4.8824e-22],\n",
      "        [2.0282e-35, 2.3150e-35, 1.8834e-22, 2.0321e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.3495e-06, 6.7297e-07, 9.9999e-01, 2.4781e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.4022e-14, 8.7261e-15, 1.0000e+00, 2.5122e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.5461e-19, 8.3242e-20, 1.0000e+00, 2.6906e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "416000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9242e-22, 6.2450e-22, 4.8164e-14, 4.8824e-22],\n",
      "        [2.0287e-35, 2.3156e-35, 1.8721e-22, 2.0325e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.3553e-06, 6.7460e-07, 9.9999e-01, 2.4842e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.4171e-14, 8.7805e-15, 1.0000e+00, 2.5278e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.5682e-19, 8.3966e-20, 1.0000e+00, 2.7140e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "417000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9244e-22, 6.2454e-22, 4.7983e-14, 4.8826e-22],\n",
      "        [2.0291e-35, 2.3161e-35, 1.8608e-22, 2.0330e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.3611e-06, 6.7626e-07, 9.9999e-01, 2.4903e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.4322e-14, 8.8354e-15, 1.0000e+00, 2.5436e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.5907e-19, 8.4699e-20, 1.0000e+00, 2.7377e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "418000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9245e-22, 6.2455e-22, 4.7803e-14, 4.8827e-22],\n",
      "        [2.0295e-35, 2.3166e-35, 1.8496e-22, 2.0334e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.3668e-06, 6.7790e-07, 9.9999e-01, 2.4964e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.4473e-14, 8.8903e-15, 1.0000e+00, 2.5595e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.6131e-19, 8.5430e-20, 1.0000e+00, 2.7614e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "419000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9246e-22, 6.2458e-22, 4.7626e-14, 4.8829e-22],\n",
      "        [2.0299e-35, 2.3171e-35, 1.8386e-22, 2.0338e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.3726e-06, 6.7955e-07, 9.9999e-01, 2.5025e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.4625e-14, 8.9454e-15, 1.0000e+00, 2.5753e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.6357e-19, 8.6169e-20, 1.0000e+00, 2.7853e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "420000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9248e-22, 6.2460e-22, 4.7449e-14, 4.8830e-22],\n",
      "        [2.0303e-35, 2.3176e-35, 1.8277e-22, 2.0342e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.3783e-06, 6.8120e-07, 9.9999e-01, 2.5086e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.4777e-14, 9.0008e-15, 1.0000e+00, 2.5913e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.6584e-19, 8.6915e-20, 1.0000e+00, 2.8094e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "421000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9248e-22, 6.2463e-22, 4.7273e-14, 4.8832e-22],\n",
      "        [2.0308e-35, 2.3181e-35, 1.8168e-22, 2.0347e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.3841e-06, 6.8285e-07, 9.9999e-01, 2.5147e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.4931e-14, 9.0566e-15, 1.0000e+00, 2.6074e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.6814e-19, 8.7665e-20, 1.0000e+00, 2.8336e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "422000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9249e-22, 6.2466e-22, 4.7097e-14, 4.8833e-22],\n",
      "        [2.0312e-35, 2.3186e-35, 1.8060e-22, 2.0351e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([2.3899e-06, 6.8450e-07, 9.9999e-01, 2.5208e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.5085e-14, 9.1128e-15, 1.0000e+00, 2.6235e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.7045e-19, 8.8422e-20, 1.0000e+00, 2.8581e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "423000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9252e-22, 6.2468e-22, 4.6923e-14, 4.8834e-22],\n",
      "        [2.0316e-35, 2.3191e-35, 1.7953e-22, 2.0356e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.3957e-06, 6.8615e-07, 9.9999e-01, 2.5269e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.5240e-14, 9.1692e-15, 1.0000e+00, 2.6398e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.7278e-19, 8.9184e-20, 1.0000e+00, 2.8828e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "424000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9252e-22, 6.2471e-22, 4.6749e-14, 4.8836e-22],\n",
      "        [2.0321e-35, 2.3197e-35, 1.7847e-22, 2.0360e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.4015e-06, 6.8782e-07, 9.9999e-01, 2.5331e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.5396e-14, 9.2259e-15, 1.0000e+00, 2.6561e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.7514e-19, 8.9953e-20, 1.0000e+00, 2.9077e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "425000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9254e-22, 6.2474e-22, 4.6575e-14, 4.8837e-22],\n",
      "        [2.0325e-35, 2.3202e-35, 1.7741e-22, 2.0364e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.4074e-06, 6.8947e-07, 9.9999e-01, 2.5392e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.5553e-14, 9.2829e-15, 1.0000e+00, 2.6725e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.7751e-19, 9.0728e-20, 1.0000e+00, 2.9328e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "426000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9255e-22, 6.2475e-22, 4.6403e-14, 4.8839e-22],\n",
      "        [2.0329e-35, 2.3207e-35, 1.7635e-22, 2.0369e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.4133e-06, 6.9117e-07, 9.9999e-01, 2.5455e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.5712e-14, 9.3407e-15, 1.0000e+00, 2.6892e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.7991e-19, 9.1516e-20, 1.0000e+00, 2.9582e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "427000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9256e-22, 6.2477e-22, 4.6231e-14, 4.8840e-22],\n",
      "        [2.0333e-35, 2.3212e-35, 1.7531e-22, 2.0373e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.4193e-06, 6.9288e-07, 9.9999e-01, 2.5518e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.5872e-14, 9.3991e-15, 1.0000e+00, 2.7060e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.8234e-19, 9.2309e-20, 1.0000e+00, 2.9838e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "428000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9257e-22, 6.2480e-22, 4.6060e-14, 4.8841e-22],\n",
      "        [2.0337e-35, 2.3217e-35, 1.7427e-22, 2.0377e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.4253e-06, 6.9459e-07, 9.9999e-01, 2.5581e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.6033e-14, 9.4577e-15, 1.0000e+00, 2.7228e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.8478e-19, 9.3107e-20, 1.0000e+00, 3.0097e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "429000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9258e-22, 6.2483e-22, 4.5889e-14, 4.8843e-22],\n",
      "        [2.0342e-35, 2.3222e-35, 1.7324e-22, 2.0382e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.4312e-06, 6.9631e-07, 9.9999e-01, 2.5645e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.6195e-14, 9.5164e-15, 1.0000e+00, 2.7398e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.8725e-19, 9.3913e-20, 1.0000e+00, 3.0358e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "430000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9260e-22, 6.2485e-22, 4.5719e-14, 4.8845e-22],\n",
      "        [2.0346e-35, 2.3227e-35, 1.7221e-22, 2.0386e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.4373e-06, 6.9805e-07, 9.9999e-01, 2.5709e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.6359e-14, 9.5761e-15, 1.0000e+00, 2.7569e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.8974e-19, 9.4730e-20, 1.0000e+00, 3.0621e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "431000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9260e-22, 6.2487e-22, 4.5550e-14, 4.8846e-22],\n",
      "        [2.0350e-35, 2.3232e-35, 1.7119e-22, 2.0390e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.4435e-06, 6.9981e-07, 9.9999e-01, 2.5774e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.6524e-14, 9.6363e-15, 1.0000e+00, 2.7742e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.9226e-19, 9.5556e-20, 1.0000e+00, 3.0887e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "432000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9262e-22, 6.2490e-22, 4.5382e-14, 4.8846e-22],\n",
      "        [2.0354e-35, 2.3236e-35, 1.7018e-22, 2.0394e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([2.4496e-06, 7.0157e-07, 9.9999e-01, 2.5839e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.6690e-14, 9.6964e-15, 1.0000e+00, 2.7915e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.9479e-19, 9.6382e-20, 1.0000e+00, 3.1155e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "433000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9264e-22, 6.2492e-22, 4.5215e-14, 4.8848e-22],\n",
      "        [2.0358e-35, 2.3241e-35, 1.6917e-22, 2.0398e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.4559e-06, 7.0335e-07, 9.9999e-01, 2.5904e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.6856e-14, 9.7569e-15, 1.0000e+00, 2.8089e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.9732e-19, 9.7213e-20, 1.0000e+00, 3.1424e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "434000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9265e-22, 6.2494e-22, 4.5051e-14, 4.8849e-22],\n",
      "        [2.0362e-35, 2.3246e-35, 1.6819e-22, 2.0403e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.4619e-06, 7.0510e-07, 9.9999e-01, 2.5969e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.7019e-14, 9.8163e-15, 1.0000e+00, 2.8260e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.9982e-19, 9.8032e-20, 1.0000e+00, 3.1688e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "435000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9266e-22, 6.2497e-22, 4.4892e-14, 4.8851e-22],\n",
      "        [2.0367e-35, 2.3251e-35, 1.6724e-22, 2.0407e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.4680e-06, 7.0686e-07, 9.9999e-01, 2.6034e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.7183e-14, 9.8760e-15, 1.0000e+00, 2.8432e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.0235e-19, 9.8858e-20, 1.0000e+00, 3.1955e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "436000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9267e-22, 6.2499e-22, 4.4732e-14, 4.8852e-22],\n",
      "        [2.0371e-35, 2.3256e-35, 1.6629e-22, 2.0411e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.4742e-06, 7.0863e-07, 9.9999e-01, 2.6099e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.7349e-14, 9.9364e-15, 1.0000e+00, 2.8605e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.0489e-19, 9.9691e-20, 1.0000e+00, 3.2225e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "437000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9268e-22, 6.2501e-22, 4.4574e-14, 4.8854e-22],\n",
      "        [2.0375e-35, 2.3261e-35, 1.6535e-22, 2.0415e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.4805e-06, 7.1041e-07, 9.9999e-01, 2.6165e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.7515e-14, 9.9972e-15, 1.0000e+00, 2.8780e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.0747e-19, 1.0053e-19, 1.0000e+00, 3.2497e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "438000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9270e-22, 6.2504e-22, 4.4416e-14, 4.8855e-22],\n",
      "        [2.0379e-35, 2.3266e-35, 1.6441e-22, 2.0420e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.4867e-06, 7.1220e-07, 9.9999e-01, 2.6231e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.7683e-14, 1.0058e-14, 1.0000e+00, 2.8956e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.1006e-19, 1.0138e-19, 1.0000e+00, 3.2772e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "439000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9271e-22, 6.2506e-22, 4.4259e-14, 4.8857e-22],\n",
      "        [2.0384e-35, 2.3271e-35, 1.6348e-22, 2.0424e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.4929e-06, 7.1400e-07, 9.9999e-01, 2.6297e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.7852e-14, 1.0120e-14, 1.0000e+00, 2.9133e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.1268e-19, 1.0224e-19, 1.0000e+00, 3.3048e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "440000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9273e-22, 6.2509e-22, 4.4102e-14, 4.8858e-22],\n",
      "        [2.0388e-35, 2.3276e-35, 1.6255e-22, 2.0428e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.4992e-06, 7.1579e-07, 9.9999e-01, 2.6363e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.8022e-14, 1.0182e-14, 1.0000e+00, 2.9311e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.1532e-19, 1.0311e-19, 1.0000e+00, 3.3328e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "441000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9274e-22, 6.2512e-22, 4.3946e-14, 4.8860e-22],\n",
      "        [2.0392e-35, 2.3281e-35, 1.6163e-22, 2.0432e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.5055e-06, 7.1760e-07, 9.9999e-01, 2.6430e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.8193e-14, 1.0244e-14, 1.0000e+00, 2.9490e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.1798e-19, 1.0398e-19, 1.0000e+00, 3.3609e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "442000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9276e-22, 6.2514e-22, 4.3791e-14, 4.8861e-22],\n",
      "        [2.0396e-35, 2.3286e-35, 1.6071e-22, 2.0437e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([2.5118e-06, 7.1941e-07, 9.9999e-01, 2.6496e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.8365e-14, 1.0307e-14, 1.0000e+00, 2.9670e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.2066e-19, 1.0486e-19, 1.0000e+00, 3.3893e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "443000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9276e-22, 6.2515e-22, 4.3635e-14, 4.8863e-22],\n",
      "        [2.0401e-35, 2.3291e-35, 1.5980e-22, 2.0441e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.5181e-06, 7.2123e-07, 9.9999e-01, 2.6563e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.8538e-14, 1.0370e-14, 1.0000e+00, 2.9852e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.2337e-19, 1.0574e-19, 1.0000e+00, 3.4179e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "444000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9279e-22, 6.2518e-22, 4.3481e-14, 4.8864e-22],\n",
      "        [2.0405e-35, 2.3296e-35, 1.5889e-22, 2.0445e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.5244e-06, 7.2305e-07, 9.9999e-01, 2.6630e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.8713e-14, 1.0434e-14, 1.0000e+00, 3.0035e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.2610e-19, 1.0664e-19, 1.0000e+00, 3.4468e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "445000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9279e-22, 6.2521e-22, 4.3327e-14, 4.8865e-22],\n",
      "        [2.0409e-35, 2.3301e-35, 1.5800e-22, 2.0450e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.5308e-06, 7.2487e-07, 9.9999e-01, 2.6697e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.8888e-14, 1.0498e-14, 1.0000e+00, 3.0218e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.2885e-19, 1.0754e-19, 1.0000e+00, 3.4759e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "446000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9281e-22, 6.2524e-22, 4.3174e-14, 4.8868e-22],\n",
      "        [2.0413e-35, 2.3307e-35, 1.5710e-22, 2.0454e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.5371e-06, 7.2669e-07, 9.9999e-01, 2.6764e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.9063e-14, 1.0561e-14, 1.0000e+00, 3.0401e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.3161e-19, 1.0844e-19, 1.0000e+00, 3.5051e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "447000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9282e-22, 6.2526e-22, 4.3022e-14, 4.8868e-22],\n",
      "        [2.0418e-35, 2.3312e-35, 1.5622e-22, 2.0459e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.5436e-06, 7.2854e-07, 9.9999e-01, 2.6832e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.9240e-14, 1.0626e-14, 1.0000e+00, 3.0587e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.3440e-19, 1.0935e-19, 1.0000e+00, 3.5346e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "448000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9284e-22, 6.2529e-22, 4.2871e-14, 4.8871e-22],\n",
      "        [2.0422e-35, 2.3316e-35, 1.5534e-22, 2.0463e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.5500e-06, 7.3039e-07, 9.9999e-01, 2.6901e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.9418e-14, 1.0691e-14, 1.0000e+00, 3.0773e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.3721e-19, 1.1027e-19, 1.0000e+00, 3.5644e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "449000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9285e-22, 6.2530e-22, 4.2722e-14, 4.8872e-22],\n",
      "        [2.0426e-35, 2.3321e-35, 1.5447e-22, 2.0467e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.5565e-06, 7.3225e-07, 9.9999e-01, 2.6969e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.9597e-14, 1.0756e-14, 1.0000e+00, 3.0961e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.4003e-19, 1.1120e-19, 1.0000e+00, 3.5943e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "450000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9285e-22, 6.2533e-22, 4.2572e-14, 4.8873e-22],\n",
      "        [2.0430e-35, 2.3326e-35, 1.5360e-22, 2.0471e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.5630e-06, 7.3411e-07, 9.9999e-01, 2.7038e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.9778e-14, 1.0821e-14, 1.0000e+00, 3.1149e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.4289e-19, 1.1213e-19, 1.0000e+00, 3.6245e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "451000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9288e-22, 6.2535e-22, 4.2423e-14, 4.8875e-22],\n",
      "        [2.0435e-35, 2.3331e-35, 1.5274e-22, 2.0476e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.5695e-06, 7.3597e-07, 9.9999e-01, 2.7106e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.9958e-14, 1.0887e-14, 1.0000e+00, 3.1339e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.4576e-19, 1.1307e-19, 1.0000e+00, 3.6548e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "452000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9289e-22, 6.2536e-22, 4.2275e-14, 4.8875e-22],\n",
      "        [2.0439e-35, 2.3336e-35, 1.5189e-22, 2.0480e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([2.5760e-06, 7.3783e-07, 9.9999e-01, 2.7175e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.0139e-14, 1.0953e-14, 1.0000e+00, 3.1529e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.4865e-19, 1.1402e-19, 1.0000e+00, 3.6854e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "453000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9290e-22, 6.2540e-22, 4.2128e-14, 4.8877e-22],\n",
      "        [2.0443e-35, 2.3341e-35, 1.5104e-22, 2.0484e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.5825e-06, 7.3969e-07, 9.9999e-01, 2.7244e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.0322e-14, 1.1020e-14, 1.0000e+00, 3.1720e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.5156e-19, 1.1497e-19, 1.0000e+00, 3.7163e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "454000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9291e-22, 6.2542e-22, 4.1981e-14, 4.8877e-22],\n",
      "        [2.0447e-35, 2.3346e-35, 1.5020e-22, 2.0488e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.5891e-06, 7.4158e-07, 9.9999e-01, 2.7313e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.0506e-14, 1.1087e-14, 1.0000e+00, 3.1912e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.5450e-19, 1.1593e-19, 1.0000e+00, 3.7473e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "455000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9292e-22, 6.2544e-22, 4.1835e-14, 4.8879e-22],\n",
      "        [2.0451e-35, 2.3351e-35, 1.4936e-22, 2.0493e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.5957e-06, 7.4349e-07, 9.9999e-01, 2.7384e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.0691e-14, 1.1154e-14, 1.0000e+00, 3.2107e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.5747e-19, 1.1690e-19, 1.0000e+00, 3.7787e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "456000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9293e-22, 6.2546e-22, 4.1690e-14, 4.8881e-22],\n",
      "        [2.0455e-35, 2.3356e-35, 1.4854e-22, 2.0497e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.6024e-06, 7.4541e-07, 9.9999e-01, 2.7454e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.0878e-14, 1.1222e-14, 1.0000e+00, 3.2302e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.6046e-19, 1.1788e-19, 1.0000e+00, 3.8103e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "457000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9294e-22, 6.2548e-22, 4.1546e-14, 4.8882e-22],\n",
      "        [2.0460e-35, 2.3360e-35, 1.4771e-22, 2.0501e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.6091e-06, 7.4733e-07, 9.9999e-01, 2.7525e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.1066e-14, 1.1290e-14, 1.0000e+00, 3.2499e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.6347e-19, 1.1887e-19, 1.0000e+00, 3.8423e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "458000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9295e-22, 6.2551e-22, 4.1403e-14, 4.8883e-22],\n",
      "        [2.0464e-35, 2.3365e-35, 1.4690e-22, 2.0505e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.6158e-06, 7.4926e-07, 9.9999e-01, 2.7596e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.1254e-14, 1.1359e-14, 1.0000e+00, 3.2696e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.6651e-19, 1.1986e-19, 1.0000e+00, 3.8744e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "459000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9297e-22, 6.2551e-22, 4.1260e-14, 4.8885e-22],\n",
      "        [2.0468e-35, 2.3370e-35, 1.4609e-22, 2.0510e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.6225e-06, 7.5116e-07, 9.9999e-01, 2.7667e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.1442e-14, 1.1427e-14, 1.0000e+00, 3.2893e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.6953e-19, 1.2085e-19, 1.0000e+00, 3.9064e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "460000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9298e-22, 6.2553e-22, 4.1119e-14, 4.8886e-22],\n",
      "        [2.0473e-35, 2.3376e-35, 1.4529e-22, 2.0514e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.6293e-06, 7.5311e-07, 9.9999e-01, 2.7738e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.1632e-14, 1.1497e-14, 1.0000e+00, 3.3092e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.7260e-19, 1.2186e-19, 1.0000e+00, 3.9388e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "461000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9299e-22, 6.2556e-22, 4.0979e-14, 4.8887e-22],\n",
      "        [2.0476e-35, 2.3380e-35, 1.4449e-22, 2.0518e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.6362e-06, 7.5508e-07, 9.9999e-01, 2.7811e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.1824e-14, 1.1566e-14, 1.0000e+00, 3.3293e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.7570e-19, 1.2287e-19, 1.0000e+00, 3.9716e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "462000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9299e-22, 6.2557e-22, 4.0838e-14, 4.8888e-22],\n",
      "        [2.0479e-35, 2.3384e-35, 1.4370e-22, 2.0521e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([2.6431e-06, 7.5706e-07, 9.9999e-01, 2.7884e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.2017e-14, 1.1637e-14, 1.0000e+00, 3.3495e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.7882e-19, 1.2389e-19, 1.0000e+00, 4.0046e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "463000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9302e-22, 6.2560e-22, 4.0699e-14, 4.8889e-22],\n",
      "        [2.0483e-35, 2.3388e-35, 1.4291e-22, 2.0525e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.6501e-06, 7.5907e-07, 9.9999e-01, 2.7958e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.2213e-14, 1.1708e-14, 1.0000e+00, 3.3700e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.8199e-19, 1.2493e-19, 1.0000e+00, 4.0382e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "464000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9303e-22, 6.2561e-22, 4.0560e-14, 4.8890e-22],\n",
      "        [2.0487e-35, 2.3393e-35, 1.4213e-22, 2.0529e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.6571e-06, 7.6109e-07, 9.9999e-01, 2.8033e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.2410e-14, 1.1780e-14, 1.0000e+00, 3.3906e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.8519e-19, 1.2598e-19, 1.0000e+00, 4.0720e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "465000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9304e-22, 6.2564e-22, 4.0422e-14, 4.8891e-22],\n",
      "        [2.0491e-35, 2.3396e-35, 1.4135e-22, 2.0532e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.6641e-06, 7.6309e-07, 9.9999e-01, 2.8106e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.2604e-14, 1.1851e-14, 1.0000e+00, 3.4110e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.8835e-19, 1.2701e-19, 1.0000e+00, 4.1053e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "466000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9305e-22, 6.2565e-22, 4.0286e-14, 4.8893e-22],\n",
      "        [2.0494e-35, 2.3401e-35, 1.4059e-22, 2.0536e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.6710e-06, 7.6509e-07, 9.9999e-01, 2.8179e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.2800e-14, 1.1922e-14, 1.0000e+00, 3.4314e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.9153e-19, 1.2805e-19, 1.0000e+00, 4.1390e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "467000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9305e-22, 6.2567e-22, 4.0152e-14, 4.8892e-22],\n",
      "        [2.0498e-35, 2.3405e-35, 1.3984e-22, 2.0540e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.6780e-06, 7.6709e-07, 9.9999e-01, 2.8253e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.2997e-14, 1.1994e-14, 1.0000e+00, 3.4520e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.9474e-19, 1.2911e-19, 1.0000e+00, 4.1730e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "468000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9306e-22, 6.2569e-22, 4.0018e-14, 4.8894e-22],\n",
      "        [2.0501e-35, 2.3409e-35, 1.3909e-22, 2.0543e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.6850e-06, 7.6910e-07, 9.9999e-01, 2.8327e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.3194e-14, 1.2066e-14, 1.0000e+00, 3.4728e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.9798e-19, 1.3017e-19, 1.0000e+00, 4.2072e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "469000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9308e-22, 6.2570e-22, 3.9884e-14, 4.8896e-22],\n",
      "        [2.0505e-35, 2.3413e-35, 1.3834e-22, 2.0547e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.6920e-06, 7.7111e-07, 9.9999e-01, 2.8401e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.3393e-14, 1.2138e-14, 1.0000e+00, 3.4936e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.0124e-19, 1.3123e-19, 1.0000e+00, 4.2418e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "470000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9310e-22, 6.2572e-22, 3.9751e-14, 4.8896e-22],\n",
      "        [2.0509e-35, 2.3417e-35, 1.3760e-22, 2.0550e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.6989e-06, 7.7309e-07, 9.9999e-01, 2.8474e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.3590e-14, 1.2210e-14, 1.0000e+00, 3.5141e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.0447e-19, 1.3229e-19, 1.0000e+00, 4.2759e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "471000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9310e-22, 6.2573e-22, 3.9620e-14, 4.8897e-22],\n",
      "        [2.0512e-35, 2.3421e-35, 1.3687e-22, 2.0554e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.7058e-06, 7.7507e-07, 9.9999e-01, 2.8547e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.3787e-14, 1.2282e-14, 1.0000e+00, 3.5348e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.0772e-19, 1.3335e-19, 1.0000e+00, 4.3103e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "472000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9311e-22, 6.2576e-22, 3.9491e-14, 4.8899e-22],\n",
      "        [2.0516e-35, 2.3426e-35, 1.3615e-22, 2.0558e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([2.7128e-06, 7.7706e-07, 9.9999e-01, 2.8620e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.3986e-14, 1.2354e-14, 1.0000e+00, 3.5556e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.1099e-19, 1.3442e-19, 1.0000e+00, 4.3449e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "473000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9312e-22, 6.2577e-22, 3.9362e-14, 4.8900e-22],\n",
      "        [2.0519e-35, 2.3430e-35, 1.3544e-22, 2.0561e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.7197e-06, 7.7905e-07, 9.9999e-01, 2.8693e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.4185e-14, 1.2427e-14, 1.0000e+00, 3.5765e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.1429e-19, 1.3551e-19, 1.0000e+00, 4.3798e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "474000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9312e-22, 6.2578e-22, 3.9232e-14, 4.8900e-22],\n",
      "        [2.0523e-35, 2.3434e-35, 1.3473e-22, 2.0565e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.7267e-06, 7.8105e-07, 9.9999e-01, 2.8767e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.4386e-14, 1.2500e-14, 1.0000e+00, 3.5975e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.1762e-19, 1.3660e-19, 1.0000e+00, 4.4150e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "475000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9314e-22, 6.2581e-22, 3.9104e-14, 4.8902e-22],\n",
      "        [2.0526e-35, 2.3438e-35, 1.3402e-22, 2.0568e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.7337e-06, 7.8305e-07, 9.9999e-01, 2.8841e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.4588e-14, 1.2573e-14, 1.0000e+00, 3.6186e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.2098e-19, 1.3769e-19, 1.0000e+00, 4.4505e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "476000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9315e-22, 6.2582e-22, 3.8976e-14, 4.8903e-22],\n",
      "        [2.0530e-35, 2.3442e-35, 1.3332e-22, 2.0572e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.7408e-06, 7.8509e-07, 9.9999e-01, 2.8916e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.4792e-14, 1.2647e-14, 1.0000e+00, 3.6400e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.2438e-19, 1.3880e-19, 1.0000e+00, 4.4864e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "477000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9316e-22, 6.2584e-22, 3.8849e-14, 4.8904e-22],\n",
      "        [2.0534e-35, 2.3446e-35, 1.3262e-22, 2.0576e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.7479e-06, 7.8714e-07, 9.9999e-01, 2.8991e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.4998e-14, 1.2723e-14, 1.0000e+00, 3.6616e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.2780e-19, 1.3993e-19, 1.0000e+00, 4.5227e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "478000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9317e-22, 6.2585e-22, 3.8722e-14, 4.8905e-22],\n",
      "        [2.0537e-35, 2.3450e-35, 1.3192e-22, 2.0579e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.7551e-06, 7.8921e-07, 9.9999e-01, 2.9068e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.5205e-14, 1.2798e-14, 1.0000e+00, 3.6833e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.3126e-19, 1.4106e-19, 1.0000e+00, 4.5592e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "479000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9317e-22, 6.2587e-22, 3.8595e-14, 4.8906e-22],\n",
      "        [2.0541e-35, 2.3455e-35, 1.3123e-22, 2.0583e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.7624e-06, 7.9128e-07, 9.9999e-01, 2.9144e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.5415e-14, 1.2874e-14, 1.0000e+00, 3.7051e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.3475e-19, 1.4220e-19, 1.0000e+00, 4.5961e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "480000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9319e-22, 6.2587e-22, 3.8469e-14, 4.8906e-22],\n",
      "        [2.0544e-35, 2.3459e-35, 1.3054e-22, 2.0586e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.7698e-06, 7.9340e-07, 9.9999e-01, 2.9222e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.5626e-14, 1.2951e-14, 1.0000e+00, 3.7273e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.3828e-19, 1.4335e-19, 1.0000e+00, 4.6335e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "481000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9319e-22, 6.2590e-22, 3.8344e-14, 4.8908e-22],\n",
      "        [2.0548e-35, 2.3463e-35, 1.2985e-22, 2.0590e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.7772e-06, 7.9552e-07, 9.9999e-01, 2.9300e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.5838e-14, 1.3028e-14, 1.0000e+00, 3.7495e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.4184e-19, 1.4452e-19, 1.0000e+00, 4.6711e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "482000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9321e-22, 6.2590e-22, 3.8219e-14, 4.8908e-22],\n",
      "        [2.0551e-35, 2.3467e-35, 1.2917e-22, 2.0593e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([2.7846e-06, 7.9765e-07, 9.9999e-01, 2.9378e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.6053e-14, 1.3106e-14, 1.0000e+00, 3.7719e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.4543e-19, 1.4569e-19, 1.0000e+00, 4.7091e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "483000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9321e-22, 6.2592e-22, 3.8094e-14, 4.8908e-22],\n",
      "        [2.0555e-35, 2.3470e-35, 1.2850e-22, 2.0597e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.7922e-06, 7.9983e-07, 9.9999e-01, 2.9458e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.6270e-14, 1.3185e-14, 1.0000e+00, 3.7946e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.4907e-19, 1.4689e-19, 1.0000e+00, 4.7476e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "484000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9322e-22, 6.2593e-22, 3.7970e-14, 4.8909e-22],\n",
      "        [2.0558e-35, 2.3475e-35, 1.2782e-22, 2.0600e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.7998e-06, 8.0201e-07, 9.9999e-01, 2.9539e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.6488e-14, 1.3265e-14, 1.0000e+00, 3.8175e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.5275e-19, 1.4809e-19, 1.0000e+00, 4.7866e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "485000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9322e-22, 6.2593e-22, 3.7845e-14, 4.8910e-22],\n",
      "        [2.0562e-35, 2.3479e-35, 1.2715e-22, 2.0604e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.8075e-06, 8.0421e-07, 9.9999e-01, 2.9620e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.6709e-14, 1.3345e-14, 1.0000e+00, 3.8406e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.5646e-19, 1.4930e-19, 1.0000e+00, 4.8258e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "486000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9322e-22, 6.2596e-22, 3.7722e-14, 4.8911e-22],\n",
      "        [2.0565e-35, 2.3482e-35, 1.2648e-22, 2.0607e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.8152e-06, 8.0641e-07, 9.9999e-01, 2.9701e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.6930e-14, 1.3426e-14, 1.0000e+00, 3.8638e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.6021e-19, 1.5053e-19, 1.0000e+00, 4.8653e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "487000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9323e-22, 6.2595e-22, 3.7598e-14, 4.8911e-22],\n",
      "        [2.0569e-35, 2.3486e-35, 1.2582e-22, 2.0611e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.8229e-06, 8.0862e-07, 9.9999e-01, 2.9783e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.7154e-14, 1.3507e-14, 1.0000e+00, 3.8871e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.6398e-19, 1.5176e-19, 1.0000e+00, 4.9052e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "488000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9322e-22, 6.2595e-22, 3.7476e-14, 4.8911e-22],\n",
      "        [2.0572e-35, 2.3490e-35, 1.2516e-22, 2.0614e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.8306e-06, 8.1084e-07, 9.9999e-01, 2.9864e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.7378e-14, 1.3588e-14, 1.0000e+00, 3.9106e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.6777e-19, 1.5301e-19, 1.0000e+00, 4.9453e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "489000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9325e-22, 6.2597e-22, 3.7353e-14, 4.8912e-22],\n",
      "        [2.0575e-35, 2.3494e-35, 1.2451e-22, 2.0617e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.8384e-06, 8.1307e-07, 9.9999e-01, 2.9946e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.7604e-14, 1.3670e-14, 1.0000e+00, 3.9342e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.7161e-19, 1.5426e-19, 1.0000e+00, 4.9859e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "490000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9324e-22, 6.2598e-22, 3.7231e-14, 4.8912e-22],\n",
      "        [2.0579e-35, 2.3498e-35, 1.2385e-22, 2.0621e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.8462e-06, 8.1531e-07, 9.9999e-01, 3.0029e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.7831e-14, 1.3753e-14, 1.0000e+00, 3.9580e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.7548e-19, 1.5552e-19, 1.0000e+00, 5.0269e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "491000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9325e-22, 6.2600e-22, 3.7110e-14, 4.8913e-22],\n",
      "        [2.0582e-35, 2.3501e-35, 1.2320e-22, 2.0624e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.8541e-06, 8.1756e-07, 9.9999e-01, 3.0111e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.8060e-14, 1.3836e-14, 1.0000e+00, 3.9820e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.7938e-19, 1.5680e-19, 1.0000e+00, 5.0681e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "492000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9325e-22, 6.2599e-22, 3.6989e-14, 4.8914e-22],\n",
      "        [2.0585e-35, 2.3505e-35, 1.2256e-22, 2.0627e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "probs=  tensor([2.8619e-06, 8.1982e-07, 9.9999e-01, 3.0195e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.8290e-14, 1.3920e-14, 1.0000e+00, 4.0061e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.8331e-19, 1.5809e-19, 1.0000e+00, 5.1097e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "493000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9326e-22, 6.2600e-22, 3.6868e-14, 4.8914e-22],\n",
      "        [2.0588e-35, 2.3509e-35, 1.2191e-22, 2.0631e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.8698e-06, 8.2208e-07, 9.9999e-01, 3.0278e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.8522e-14, 1.4004e-14, 1.0000e+00, 4.0303e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.8728e-19, 1.5939e-19, 1.0000e+00, 5.1516e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "494000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9326e-22, 6.2602e-22, 3.6748e-14, 4.8915e-22],\n",
      "        [2.0591e-35, 2.3513e-35, 1.2127e-22, 2.0634e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.8777e-06, 8.2435e-07, 9.9999e-01, 3.0362e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.8755e-14, 1.4089e-14, 1.0000e+00, 4.0547e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.9128e-19, 1.6069e-19, 1.0000e+00, 5.1939e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "495000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9327e-22, 6.2602e-22, 3.6628e-14, 4.8914e-22],\n",
      "        [2.0595e-35, 2.3517e-35, 1.2064e-22, 2.0637e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.8857e-06, 8.2663e-07, 9.9999e-01, 3.0445e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.8990e-14, 1.4175e-14, 1.0000e+00, 4.0793e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.9532e-19, 1.6201e-19, 1.0000e+00, 5.2366e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "496000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9328e-22, 6.2604e-22, 3.6508e-14, 4.8916e-22],\n",
      "        [2.0598e-35, 2.3520e-35, 1.2001e-22, 2.0640e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.8937e-06, 8.2891e-07, 9.9999e-01, 3.0529e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.9226e-14, 1.4261e-14, 1.0000e+00, 4.1041e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([4.9938e-19, 1.6334e-19, 1.0000e+00, 5.2796e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "497000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9329e-22, 6.2604e-22, 3.6389e-14, 4.8916e-22],\n",
      "        [2.0601e-35, 2.3524e-35, 1.1937e-22, 2.0644e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.9016e-06, 8.3121e-07, 9.9999e-01, 3.0614e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.9464e-14, 1.4347e-14, 1.0000e+00, 4.1289e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.0348e-19, 1.6468e-19, 1.0000e+00, 5.3229e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "498000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9329e-22, 6.2604e-22, 3.6270e-14, 4.8916e-22],\n",
      "        [2.0605e-35, 2.3527e-35, 1.1875e-22, 2.0647e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([2.9097e-06, 8.3350e-07, 9.9999e-01, 3.0698e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([3.9703e-14, 1.4434e-14, 1.0000e+00, 4.1539e-14],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "------------------------------\n",
      "probs=  tensor([5.0761e-19, 1.6604e-19, 1.0000e+00, 5.3667e-19],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "--------------------------------------------------\n",
      "499000   actions:  tensor([2, 2, 2])\n",
      "loss=  tensor(2.3605, grad_fn=<DivBackward0>)   , return=  16145.578125\n",
      "discReturns/1000= tensor([5.1083, 5.4351, 5.6023])\n",
      "actionProbs tensor([[1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00],\n",
      "        [4.9329e-22, 6.2605e-22, 3.6152e-14, 4.8917e-22],\n",
      "        [2.0608e-35, 2.3531e-35, 1.1812e-22, 2.0650e-35]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "algorithm.solver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "advModeNames=\"\"\n",
    "for i in range(len(adversaryProbs)):\n",
    "    if adversaryProbs[i]!=0:\n",
    "        tmp=\"{:.1f}\".format(adversaryProbs[i])\n",
    "        advModeNames+=f\"{(AdversaryModes(i)).name}-{tmp}-\"\n",
    "    \n",
    "name=f\"ep {algorithm.numberEpisodes}, {advModeNames}, {game.advHistoryNum} hist, {neuralNet.lr} lr\"\n",
    "neuralNet.save(name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "profits = pd.DataFrame(game.profit).T\n",
    "prices = pd.DataFrame(game.prices).T\n",
    "demandPotential = pd.DataFrame(game.demandPotential).T\n",
    "learning = pd.DataFrame(algorithm.returns.mean(axis = 0),columns=['entry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = pd.DataFrame(algorithm.loss.mean(axis = 0),columns=['entry'])\n",
    "loss.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200.00</td>\n",
       "      <td>200.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>204.50</td>\n",
       "      <td>195.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>206.75</td>\n",
       "      <td>193.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0       1\n",
       "0  200.00  200.00\n",
       "1  204.50  195.50\n",
       "2  206.75  193.25"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "demandPotential.plot()\n",
    "demandPotential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    16145.578125\n",
       "1    11771.578125\n",
       "dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profits.sum(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5108.250000</td>\n",
       "      <td>4160.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5435.062500</td>\n",
       "      <td>3875.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5602.265625</td>\n",
       "      <td>3736.265625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0            1\n",
       "0  5108.250000  4160.250000\n",
       "1  5435.062500  3875.062500\n",
       "2  5602.265625  3736.265625"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAmjUlEQVR4nO3df3Rc5X3n8fdXv2VZPy3Z1g9LssFAbH7Y1kBIaSghaXGBAGmbxGxTkkLWhYWWPdltAm1P2ySn5/THZpuTZEPqZLsJTYCwbQlZDhBo0zRtgyES2GCDARtsEJJt2ZZl+YdkafTdP+4dzYw0lkZGmtFoPq9z7tHMc+8dPzNcvs8zz/eZ+5i7IyIi+aEg2xUQEZHMUdAXEckjCvoiInlEQV9EJI8o6IuI5JGibFdgOvX19d7e3p7taoiI5JSurq5D7t4wsXzeB/329nY6OzuzXQ0RkZxiZvtSlWt4R0Qkjyjoi4jkEQV9EZE8Mu/H9FMZGRmhu7uboaGhbFfljMrKymhpaaG4uDjbVRERGZeTQb+7u5vKykra29sxs2xXZxJ35/Dhw3R3d7Ny5cpsV0dEZFxODu8MDQ2xZMmSeRnwAcyMJUuWzOtvIiKSn3Iy6APzNuDHzPf6iUh+ysnhHRGRhcTdOXpyhHeOnqIn3A4ODvP715w/6x1IBf2z9OSTT3L33XcTjUb59Kc/zT333JPtKonIPDU0EqV3YIieo6d45+gpeo8Gj3sGTo0H+qGRsaRzSgoLuP2qc6gqm93JIAr6ZyEajXLnnXfy9NNP09LSwqWXXsoNN9zAmjVrsl01EcmwsTHn0PFhesKgHgvsweMhegdOcej46UnnNVSW0lRTzvnLKvnA+UtpqimnuaaMpppyGqvLWVJRQkHB7A8TK+ifheeee45zzz2XVatWAbBp0yYeffRRBX2RBej48Ci944E8Hth7BuJBfSSavALhopJCmmvKaawp58LmKpqqy4NgXlNGc005y6vLKC0qzMr7yfmg//n/t5OXe47N6muuaariTz689oz733nnHVasWDH+vKWlhWeffXZW6yAic280OsaBweGkHnps6CXWWz82NJp0TmGBsSzspa9bUcO1FzXSXFNGYxjYm2vKqSovmreTOXI+6GdDqnWF5+t/YJF85e4MnBoZ76H3DkzurR84NsTYhP+dq8uLaaopp6W2nMtW1oXBPOihN9WUs7SylKLCnJ34mPtBf6oe+VxpaWnh7bffHn/e3d1NU1NTxushks+GRqLsHxgaH2ZJ6q2H4+snT0eTzikpLKCxpoym6nLed86S8UAeG09vrC6nojTnw+KUFva7myOXXnopr7/+Om+++SbNzc089NBDPPDAA9mulsiCMTbmHD5xekJiNOitB8+HOHR8eNJ59YtLaaop49yGxVy5uiGph95YU0Z9RemcJEdziYL+WSgqKuJrX/sa11xzDdFolFtvvZW1azP/jUMkV50YHg2HW4Ieee/R+OOegWBc/XQ0eQpjeXEhTeHslvc0Vo330Juqg7Ll1WWUFWcnOZpL0gr6ZrYXGASiwKi7R8zsT4H/DPSFh/2Buz8eHn8vcFt4/O+5+4/C8g7g20A58Dhwt6caIM8B1157Lddee222qyEy74xGxzgYS44mTGPsSQjsA6dGks4pMFhWFQTvi1tq2Hhh2fiMl1hvvbq8WLmzWTCTnv4H3P3QhLK/dvf/kVhgZmuATcBaoAn4JzM7z92jwH3AZmArQdDfCDxxtpUXkcxyd46dGg3H0ZMDeW84tr7/2BDRCdnRqrKi8Zktkbba8amLsd76shxPjuaSuRjeuRF4yN2HgTfNbDdwWfhtocrdnwEws/uBm1DQF5k3hkejHBgYTrodwMRE6YkJydHiQhuf4fLelXXxYZcwsDfWlLN4gSdHc0m6/yUceMrMHPgbd98Slt9lZrcAncB/c/d+oJmgJx/THZaNhI8nlk9iZpsJvhHQ2tqaZhVFZCruE5OjQ/SO3wogCOp9g6mSoyU0VpezqqGCX1xdH0+MVgdBvX6xkqO5JN2gf4W795jZUuBpM9tFMFTzRYIG4YvAl4BbgVT/9X2K8smFQaOyBSASieTkmL9Ipp08PTreI09MksZ77EOcHk1OjpYVF4wPu1wQ3gogceilUcnRBSetoO/uPeHfg2b2CHCZu/80tt/Mvgk8Fj7tBlYknN4C9ITlLSnKRWQa0THn4OBQ8m0AYr31cHy9/2RyctQMllWW0VRTxoXN1VyzdjmN4UyXWKCvWaTkaL6ZNuibWQVQ4O6D4eNfAb5gZo3u3hse9hFgR/j4h8ADZvY/CRK5q4Hn3D1qZoNmdjnwLHAL8NVZfj8iOenY0MjkxGg4N/2d8JejoxOSo5VlReM98nUrasYDeWw8fVlVGcVKjsoE6fT0lwGPhL2BIuABd3/SzP7OzNYRDNHsBX4HwN13mtnDwMvAKHBnOHMH4A7iUzafIIeTuLfeeiuPPfYYS5cuZceOHdOfIHnr9OgYB44NjSdHeweGkhOlR4c4Ppx8f5eiAqMx/IXoZSvrxuenB/PSgyGY2b7lruSHaYO+u78BXJKi/LemOOfPgD9LUd4JXDjDOs5Ln/rUp7jrrru45ZZbsl0VySJ358iJ08Gwy0ByIH8nHFs/ODjMxF+j1FWU0FRTRvuSCn7hnPpwlkvZeG+9fnEphUqOyhzQPKqzdOWVV7J3795sV0MyaHg0yo53jvH8vn669vXz2oFB3jl6iuEJydHSooLxYZZfOq9hvHceG3ZprC6nvETJUcmO3A/6T9wD+1+a3ddcfhH86p/P7mtKzukbHOb5t/p5fl8/nfv6eal7YPzWAG1LFrG2qYoPvmdpUmK0qaacWiVHZR7L/aAvMguiY87rBwfpCnvxXfv62Xf4JBDcmfGilmo+dUU7HW21bGitpaGyNMs1Fjk7uR/01SOXs3B8eJRtbx0NAvxb/bywr5/BMJlav7iUjrYaPvHeNja01XJhc1XWVjkSmW25H/RFpuHudPefSurF79p/jDEP5rKfv6ySG9Y1EWmvpaO1jhV15RqekQVLQf8s3XzzzfzkJz/h0KFDtLS08PnPf57bbrst29USgoTrzp54wrVrXz8Hw9sLLC4tYn1rDb979Woi7bWsW1FDpaY+Sh5R0D9LDz74YLarIKFDx4eDAB8mXbd3D4zfbqC1bhFXnFvPhrZaIm21nLesUlMhJa8p6EtOGRtzXj94fLwH//xb/bx56AQQJFwvbK7ik+9rCxKubbUsrSzLco1F5hcFfZnXjg+Psv3to0lBfnAolnAtYUNrLZsuXUGkvZa1TdW6OZjINHI26Lv7vE625eiCYFkVS7g+/1Z8LP6V3uSE64cvaaKjtZZIey2tdYvm9TUgMh/lZNAvKyvj8OHDLFmyZF7+T+/uHD58mLIyDS1M5fToGDt7BsZ78F37+jlwLEi4VpQUsr61lruuXk1HWy3rW2t0rxmRWZCTQb+lpYXu7m76+vqmPzhLysrKaGlpmf7APHL4+DDPh3Pjg4Tr0fFbGKyoK+d9q5aMj8VfsLxKCVeROZCTQb+4uJiVK1dmuxoyhbExZ0/fcTpjY/H7+nkjTLgWFxoXNlfzW5cHCdeOtlqWVulbkUgm5GTQl/nnRGLCNZw6eSxMuC6pKGFDWy0fu3QFHW21XNSshKtItijoy4y5Oz0DQ3TuPTI+P/6V3kGiY44ZnLe0kusubhrvxbcvUcJVZL5Q0JdpjUTHeLnnGJ3hME3Xvn72HxsCYFFJIetba7jzqnPY0FbL+tZaqsuVcBWZrxT0ZZL+E6fHh2m69vXzYvdRhkaChGtzTTnvXVU3frfJC5ZXUqQl+URyRlpB38z2AoNAFBh194iZ/RXwYeA0sAf4bXc/ambtwCvAq+HpW9399vB1Oogvl/g4cLdrQntWjY05bxw6Tufe/vFA/0ZfPOG6tqma33xv23iQX16thKtILptJT/8D7n4o4fnTwL3uPmpmfwHcC3wu3LfH3deleI37gM3AVoKgv5EcXic3F508Pcr2twfo2ncknB9/lIFTI0CwhN+G1lo+2hEkXC9uUcJVZKE56+Edd38q4elW4DemOt7MGoEqd38mfH4/cBMK+nOq52jyLYVf7j1GdCz4crV66WKuvWg5G1qDhOvK+golXEUWuHSDvgNPmZkDf+PuWybsvxX4fsLzlWb2AnAM+CN3/zegGehOOKY7LJNZMhId45XeY8FQTThtsncgnnBdt6KG/xImXDesqKV6kRKuIvkm3aB/hbv3mNlS4Gkz2+XuPwUwsz8ERoHvhcf2Aq3ufjgcw/+Bma0FUnUhU47nm9lmgmEgWltb0383eab/xGleeLt/fDx++4SE66XtdePTJpVwFRFIM+i7e0/496CZPQJcBvzUzD4JXA98MJaQdfdhYDh83GVme4DzCHr2ifclaAF6zvDvbQG2AEQiESV6CebG7+k7ES7SHYzH7wkTrkUFxtqmKv7TZbFbCtfQWF2e5RqLyHw0bdA3swqgwN0Hw8e/AnzBzDYSJG5/yd1PJhzfABxx96iZrQJWA2+4+xEzGzSzy4FngVuAr87Be1oQTp2Osr07+ZbCR08GCdeaRcV0tNby6x0tdLTWcnFLDeUlSriKyPTS6ekvAx4JE3xFwAPu/qSZ7QZKCYZ7ID4180qCRmGUYIrn7e5+JHytO4hP2XwCJXHH9Q4ECdfOvUGAf7nnGKNhwvXcpYu5Zs1yOtqDoZpVSriKyFmy+T5NPhKJeGdnZ7arMatGomPs6h2ka9+R8V+59oQJ1/LiQi5ZUU1HWy2RtjrWt9ZQs6gkyzUWkVxjZl3uHplYrl/kZsDRk6d5IbylcOe+I2x/e4BTI1EAmqrL2NBWy+a2Wjra6rigsZJiJVxFZI4o6M8yd+eNQyfGbyfcua+f3QePA1AYJlw/Hi7vt6G1lqYaJVxFJHMU9N+lU6ejvNh9NLhPTTge3x8mXKvLi+loq+Uj65vHf+G6qEQfuYhkjyLQDO0fGEr4hesRdiYkXM9pqOCX1ywL58bXsaq+ggKt/iQi84iC/hRGo2Ps2j+YdBuDd46eAqCsuIBLWmrYfOUqIu21rF9RS22FEq4iMr8p6CcYODnC82/H7xm/7e2jnDwdJFyXV5XR0V7Lbb+4kkh7Le9prFLCVURyTt4GfXfnzVjCNbxv/GsH4gnXNY1VfCyygg1ttUTalHAVkYUhb4L+0EiUF7sHkn7heuTEaQCqyoroaKvlhkua6Gir45IVSriKyMK0YCPbgWNDSWPxO3sGGIkGCddVDRV88IKlwQ+g2mtZVb9YCVcRyQsLNuj/+n0/o7v/FKVFBVyyooZPv38VHa21bGirpU4JVxHJUws26H/xpgupXVTCmsYqSoqUcBURgQUc9D9w/tJsV0FEZN5RF1hEJI8o6IuI5BEFfRGRPKKgLyKSRxT0RUTyiIK+iEgeSSvom9leM3vJzLaZWWdYVmdmT5vZ6+Hf2oTj7zWz3Wb2qpldk1DeEb7ObjP7immhVxGRjJpJT/8D7r4uYc3Fe4B/dvfVwD+HzzGzNcAmYC2wEfi6mRWG59wHbAZWh9vGd/8WREQkXe9meOdG4Dvh4+8ANyWUP+Tuw+7+JrAbuMzMGoEqd3/Gg9XY7084R0REMiDdoO/AU2bWZWabw7Jl7t4LEP6N/QS2GXg74dzusKw5fDyxfBIz22xmnWbW2dfXl2YVRURkOunehuEKd+8xs6XA02a2a4pjU43T+xTlkwvdtwBbACKRSMpjRERk5tLq6bt7T/j3IPAIcBlwIByyIfx7MDy8G1iRcHoL0BOWt6QoFxGRDJk26JtZhZlVxh4DvwLsAH4IfDI87JPAo+HjHwKbzKzUzFYSJGyfC4eABs3s8nDWzi0J54iISAakM7yzDHgknF1ZBDzg7k+a2c+Bh83sNuAt4KMA7r7TzB4GXgZGgTvdPRq+1h3At4Fy4IlwExGRDLFgIs38FYlEvLOzM9vVEBHJKWbWlTDFfpx+kSsikkcU9EVE8oiCvohIHlHQFxHJIwr6IiJ5REFfRCSPKOiLiOQRBX0RkTyioC8ikkcU9EVE8oiCvohIHlHQFxHJIwr6IiJ5REFfRCSPKOiLiOQRBX0RkTyioC8ikkfSDvpmVmhmL5jZY+Hz75vZtnDba2bbwvJ2MzuVsO8bCa/RYWYvmdluM/tKuFauiIhkSDpr5MbcDbwCVAG4+8djO8zsS8BAwrF73H1dite4D9gMbAUeBzaidXJFRDImrZ6+mbUA1wHfSrHPgI8BD07zGo1Albs/48HCvPcDN820wiIicvbSHd75MvBZYCzFvvcDB9z99YSyleFQ0L+a2fvDsmagO+GY7rBMREQyZNqgb2bXAwfdvesMh9xMci+/F2h19/XAZ4AHzKwKSDV+72f4NzebWaeZdfb19U1XRRERSVM6Pf0rgBvMbC/wEHC1mX0XwMyKgF8Dvh872N2H3f1w+LgL2AOcR9Czb0l43RagJ9U/6O5b3D3i7pGGhoYZvykREUlt2qDv7ve6e4u7twObgB+7+yfC3R8Cdrn7+LCNmTWYWWH4eBWwGnjD3XuBQTO7PMwD3AI8OrtvR0REpjKT2TupbGJyAvdK4AtmNgpEgdvd/Ui47w7g20A5wawdzdwREckgCybSzF+RSMQ7OzuzXQ0RkZxiZl3uHplYrl/kiojkEQV9EZE8oqAvIpJHFPRFRPKIgr6ISB5R0BcRySMK+iIieURBX0Qkjyjoi4jkEQV9EZE8oqAvIpJHFPRFRPKIgr6ISB5R0BcRySMK+iIieURBX0Qkjyjoi4jkEQV9EZE8knbQN7NCM3vBzB4Ln/+pmb1jZtvC7dqEY+81s91m9qqZXZNQ3mFmL4X7vhIukC4iIhkyk57+3cArE8r+2t3XhdvjAGa2hmDB9LXARuDrZlYYHn8fsBlYHW4b303lRURkZtIK+mbWAlwHfCuNw28EHnL3YXd/E9gNXGZmjUCVuz/jwWrs9wM3nV21RUTkbKTb0/8y8FlgbEL5XWb2opn9rZnVhmXNwNsJx3SHZc3h44nlk5jZZjPrNLPOvr6+NKsoIiLTmTbom9n1wEF375qw6z7gHGAd0At8KXZKipfxKconF7pvcfeIu0caGhqmq6KIiKSpKI1jrgBuCBO1ZUCVmX3X3T8RO8DMvgk8Fj7tBlYknN8C9ITlLSnKRUQkQ6bt6bv7ve7e4u7tBAnaH7v7J8Ix+piPADvCxz8ENplZqZmtJEjYPufuvcCgmV0eztq5BXh0Nt+MiIhMLZ2e/pn8pZmtIxii2Qv8DoC77zSzh4GXgVHgTnePhufcAXwbKAeeCDcREckQCybSzF+RSMQ7OzuzXQ0RkZxiZl3uHplYrl/kiojkEQV9EZE8oqAvIpJHFPRFRPKIgr6ISB5R0BcRySMK+iIieURBX0Qkjyjoi4jkEQV9EZE8oqAvIpJHFPRFRPKIgr6ISB5R0BcRySMK+iIieURBX0Qkjyjoi4jkkbSDvpkVmtkLZvZY+PyvzGyXmb1oZo+YWU1Y3m5mp8xsW7h9I+E1OszsJTPbbWZfCdfKFRGRDJlJT/9u4JWE508DF7r7xcBrwL0J+/a4+7pwuz2h/D5gM8Fi6auBjWdXbRERORtpBX0zawGuA74VK3P3p9x9NHy6FWiZ5jUagSp3f8aDhXnvB246m0qLiMjZSben/2Xgs8DYGfbfCjyR8HxlOBT0r2b2/rCsGehOOKY7LJvEzDabWaeZdfb19aVZRRERmc60Qd/MrgcOunvXGfb/ITAKfC8s6gVa3X098BngATOrAlKN33uq13T3Le4ecfdIQ0NDGm9DRETSUZTGMVcAN5jZtUAZUGVm33X3T5jZJ4HrgQ+GQza4+zAwHD7uMrM9wHkEPfvEIaAWoGf23oqIiExn2p6+u9/r7i3u3g5sAn4cBvyNwOeAG9z9ZOx4M2sws8Lw8SqChO0b7t4LDJrZ5eGsnVuAR2f/LYmIyJmk09M/k68BpcDT4czLreFMnSuBL5jZKBAFbnf3I+E5dwDfBsoJcgBPTHxRERGZOxaOysxbkUjEOzs7s10NEZGcYmZd7h6ZWK5f5IqI5BEFfRGRPKKgLyKSR95NInd+e+QOiJ6GxkugaV3wt6w627USEcmqhRv0cXhrK+z4+3hR3SpoXBdvBBovgfLabFVQRCTjFm7Q/0h4c88Th6B3G/RsC/52d8LOf4wfV9ue0BCsCxqCRXUZrqyISGYs3KAfU1EP534o2GJOHkluCHpegJd/EN9f0zqhIVgHFUsyV2cRkTmy8IN+Kovq4Jyrgy3m5BHY/2JCQ7ANXvlhfH/1ioT8wPrg8WLdF0hEckt+Bv1UFtXBqquCLebU0ckNwa7H4vurmpO/ETStg8VLM1VjEZEZU9CfSnkNrLwy2GKGBqD3RejdHm8IXn2c8RuGVjZObggql2e23iIiZ6CgP1Nl1bDy/cEWMzwYNgTbgsagZxu89iTjDcHiZSkagkbQapEikmEK+rOhtBLarwi2mOHjsP+l5IZg99Pg4To0FUsTcgTrgr9VzWoIRGROKejPldLF0Pa+YIs5fQL270iYObQd9vwYPBrsX1Sf8BuCdcHj6hVqCERk1ijoZ1JJBbS+N9hiTp+EAzuTp5Du+Zd4Q1BeN7khqGlTQyAiZ0VBP9tKFsGKS4MtZmQobAheiDcEP/sqjIXr0JfXxn9RHGsIaleqIRCRaSnoz0fFZdDSEWwxI0Nw8OXkbwTPfB3GRoL9ZdXxRqDxEmhaHzQEBbqnnojEKejniuIyaN4QbDGjw2FDsD3eEDz7jeBGcwClVfFvBE3hD8rqzlFDIJLHFPRzWVFpEMyb1kPsS8Hoaeh7JbkheO6bEB0O9pdUQuPFyTeeW3IuFBRm5S2ISGalHfTDxc47gXfc/XozqwO+D7QDe4GPuXt/eOy9wG0Ea+T+nrv/KCzvIL5G7uPA3T7f12vMNUUl8d79hluCsugI9O2Kzxjq3Qad/xtGh4L9xRWTG4L689QQiCxAaa+Ra2afASJAVRj0/xI44u5/bmb3ALXu/jkzWwM8CFwGNAH/BJzn7lEzew64G9hKEPS/4u5TLo6uNXLnSHQUDr2a3BDsfwlGTgb7ixfB8ouSf1RWfx4U6suhSC440xq5af0fbGYtwHXAnwGfCYtvBK4KH38H+AnwubD8IXcfBt40s93AZWa2l6DBeCZ8zfuBm4Apg77MkcIiWLY22Nb/ZlA2FoVDr8WHhXq3wwvfhef+JthfVA7LL0xuCBrOh8LirLwFEZm5dLttXwY+C1QmlC1z914Ad+81s9idxpoJevIx3WHZSPh4YvkkZrYZ2AzQ2tqaZhXlXSsohKXvCbZ1NwdlY1E4vDv5pnPbH4SffzPYX1QWNByJDcHS96ghEJmnpg36ZnY9cNDdu8zsqjReM9VkcZ+ifHKh+xZgCwTDO2n8mzJXCgqD3nzD+XDJx4OysTE4sie5IXjx4SBPAFBYkqIhWBPkG0Qkq9Lp6V8B3GBm1wJlQJWZfRc4YGaNYS+/ETgYHt8NrEg4vwXoCctbUpRLrikogPrVwXbxR4OysTHofzNYkCbWEOz4R+j6P+E5xbBsTXJDsGxtMANJRDIm7UQuQNjT/+9hIvevgMMJidw6d/+sma0FHiCeyP1nYHWYyP058LvAswSJ3K+6++NT/ZtK5OYw97Ah2Jb8o7KhgWB/QXEwFJS4OM2ytcFvEkTkXXlXidwz+HPgYTO7DXgL+CiAu+80s4eBl4FR4E732I1kuIP4lM0nUBJ3YTMLFqOvWwUX/lpQ5g79e5PXI9j1GLzwd8H+giJoSGwI1gXJ4+LyrLwFkYVmRj39bFBPPw+4w9G3km9D3bsNTh4O9lshNFyQfOO55RcF9y0SkZTmoqcvMjvMoLYt2NbcGJS5w0B3ckPw+lOw7XvhOQVQf/7khqB0cXbeg0iOUNCX+ckMalYE23s+HJS5w7GeyesRbH8wdlLwA7LEhqDx4mCRGxEBFPQll5hBdXOwXXBdvPxYb3Ki+M2fwovfj50U3Fsolh+I3aKirCrTtReZFxT0JfdVNQbb+b8aLxs8kNwQ7P0PeOn/xvfXnTO5ISivyWStRbJCQV8WpsplUHkNnHdNvOz4weRE8VvPwo5/iO+vXZm8ZnHjJcGCNSILiIK+5I/FS2H1LwdbzIlDyd8Iurtg5yPx/TVtExqCdbCoLoOVFpldCvqS3yrq4dwPBVvMicOwf3vyj8pefjS+v7oVmi4Jfk9QuQwWL4fK5UGjsniZfmUs85qCvshEFUvgnKuDLebkEdj/YnJD8MpjpLx9VHltEPwXLwsbgwmPYw1EaZXWNZaMU9AXSceiOlh1VbDFREfhRB8c3x8kjo/vD/IGg/vh+IFg2/dMUB5bwjJRUXn8m8LipRMahYSGYtESLWgjs0ZBX+RsFRbFZw5NxR1O9QcNwpkaiL5d8Ma/wvDA5POtECoapm8gFi/TfYtkWgr6InPNLPimsKgOll4w9bGnT4bfEiY2EAeCx4M9wZ1MT/SRcmiprCZsDGK5hliDsDy50Sir1tBSnlLQF5lPShZB3cpgm0p0FE4eCr8pnKGBeHtr8Dc6PPn8orKEIaQpGoiKeg0tLTAK+iK5qLAoGNqpXD71ce7BrayPH5jQQCTkHfpeC37FPJRqaKkgGFpKTEAnzVZKaCx0J9ScoKAvspCZBb80Lq8JVj+bysipsFE4kNwoJD7ufRFOHAQfm3x+aXW8AUg1ayn2raKsRkNLWaSgLyKB4vL43U6nMhYNftSW1ChMSEx3/zwYWho9Nfn8wtKEoaQpGoiKhuAbjcwqfaIiMjMFheFtLpZNfZw7DB8Lcw1naCAO74a9/w5DRyefbwWwqP7MyejEGUwaWkqbgr6IzA2zYJZQWTU0nDf1saPD8QT08QOpp7Ye2Bk8Hl+IL0FpVYq8Q4oGorw274eWpg36ZlYG/BQoDY//e3f/EzP7PhAbJKwBjrr7OjNrB14BXg33bXX328PX6iC+XOLjwN0+35fuEpG5V1QKNa3BNpWxaPDr6PFGIUUD8c7zQfnIycnnF5acOdeQmJSuWLpgh5bSeVfDwNXuftzMioF/N7Mn3P3jsQPM7EtAYup/j7uvS/Fa9wGbga0EQX8jWidXRNJVUAiLG4Jt+UVnPs4dhgdTz1aKNRBH3oB9P4NTR1K8gAXTVdNpIEoq5uztzoVpg37YEz8ePi0Ot/HeuZkZ8DHg6slnx5lZI1Dl7s+Ez+8HbkJBX0Rmm1mwUE5ZFdSfO/Wxo6cn/CAuRQPRtyt4PjY6+fySytRDSUkNxPJ5M7SU1vcXMysEuoBzgf/l7s8m7H4/cMDdX08oW2lmLwDHgD9y938DmoHuhGO6w7JU/95mgm8EtLZO83VPROTdKCqJL805lbGx4FvBmaazxhbuee0AjJyYfH5BcXJDMOl2Gkvj5YXFc/JWIc2g7+5RYJ2Z1QCPmNmF7r4j3H0z8GDC4b1Aq7sfDsfwf2Bma4FUTVzK8Xx33wJsAYhEIhrzF5HsKygIhnwq6oELpz52+PjUv3fo3xv8Yvrk4RQnW3CTvcXL4LYfzfoazzPKVLj7UTP7CcFY/A4zKwJ+DehIOGaYIA+Au3eZ2R7gPIKefUvCy7UAPe+q9iIi81Hp4mBbcs7Ux42ennCn1oQG4kQflCye9aqlM3unARgJA3458CHgL8LdHwJ2uXv3hOOPuHvUzFYBq4E33P2ImQ2a2eXAs8AtwFdn+f2IiOSOohKobg62TP2TaRzTCHwnHNcvAB5298fCfZtIHtoBuBL4gpmNAlHgdnePpcfvID5l8wmUxBURySib79PkI5GId3Z2ZrsaIiI5xcy63D0ysbwgG5UREZHsUNAXEckjCvoiInlEQV9EJI8o6IuI5BEFfRGRPDLvp2yaWR+w7yxPrwcOzWJ1ZovqNTOq18yoXjOzUOvV5u4NEwvnfdB/N8ysM9U81WxTvWZG9ZoZ1Wtm8q1eGt4REckjCvoiInlkoQf9LdmuwBmoXjOjes2M6jUzeVWvBT2mLyIiyRZ6T19ERBIo6IuI5JGcDPpmttHMXjWz3WZ2T4r9ZmZfCfe/aGYb0j13juv1m2F9XjSzn5nZJQn79prZS2a2zcxm9V7SadTrKjMbCP/tbWb2x+meO8f1+v2EOu0ws6iZ1YX75vLz+lszO2hmO86wP1vX13T1ytb1NV29snV9TVevbF1fK8zsX8zsFTPbaWZ3pzhm7q4xd8+pDSgE9gCrgBJgO7BmwjHXEizQYsDlwLPpnjvH9foFoDZ8/KuxeoXP9wL1Wfq8rgIeO5tz57JeE47/MPDjuf68wte+EtgA7DjD/oxfX2nWK+PXV5r1yvj1lU69snh9NQIbwseVwGuZjGG52NO/DNjt7m+4+2ngIeDGCcfcCNzvga1AjZk1pnnunNXL3X/m7v3h060krxk8V97Ne87q5zXBzUxepW1OuPtPgSNTHJKN62vaemXp+krn8zqTrH5eE2Ty+up19+fDx4PAK8DE9RLn7BrLxaDfDLyd8LybyR/YmY5J59y5rFei20heLtKBp8ysy8w2z1KdZlKv95nZdjN7wszWzvDcuawXZrYI2Aj8Q0LxXH1e6cjG9TVTmbq+0pXp6ytt2by+zKwdWE+wbniiObvG0lkjd76xFGUT552e6Zh0zj1bab+2mX2A4H/KX0wovsLde8xsKfC0me0KeyqZqNfzBPfpOG5m1wI/IFjQfl58XgRfvf/D42stw9x9XunIxvWVtgxfX+nIxvU1E1m5vsxsMUFD81/d/djE3SlOmZVrLBd7+t3AioTnLUBPmsekc+5c1gszuxj4FnCjux+Olbt7T/j3IPAIwde4jNTL3Y+5+/Hw8eNAsZnVp3PuXNYrwSYmfPWew88rHdm4vtKShetrWlm6vmYi49eXmRUTBPzvufs/pjhk7q6xuUhUzOVG8O3kDWAl8UTG2gnHXEdyEuS5dM+d43q1AruBX5hQXgFUJjz+GbAxg/VaTvyHepcBb4WfXVY/r/C4aoJx2YpMfF4J/0Y7Z05MZvz6SrNeGb++0qxXxq+vdOqVresrfO/3A1+e4pg5u8ZybnjH3UfN7C7gRwSZ7L91951mdnu4/xvA4wTZ793ASeC3pzo3g/X6Y2AJ8HUzAxj14C56y4BHwrIi4AF3fzKD9foN4A4zGwVOAZs8uMKy/XkBfAR4yt1PJJw+Z58XgJk9SDDjpN7MuoE/AYoT6pXx6yvNemX8+kqzXhm/vtKsF2Th+gKuAH4LeMnMtoVlf0DQaM/5NabbMIiI5JFcHNMXEZGzpKAvIpJHFPRFRPKIgr6ISB5R0BcRySMK+iIieURBX0Qkj/x/rwOYkCRrj/UAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "profits.plot()\n",
    "profits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>126.500</td>\n",
       "      <td>135.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>128.750</td>\n",
       "      <td>133.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>129.875</td>\n",
       "      <td>132.125</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0        1\n",
       "0  126.500  135.500\n",
       "1  128.750  133.250\n",
       "2  129.875  132.125"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "prices.plot()\n",
    "prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learning.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pricelearning = pd.DataFrame(game.prices.mean(axis = 0))\n",
    "# pricelearning.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_1 = learning.to_numpy()\n",
    "learning_2 = [0]*len(learning_1)\n",
    "for i in range(len(learning_1)):\n",
    "    learning_2[i] = learning_1[i][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_learning = np.convolve(learning_2, np.ones(1000)/1000, mode = 'valid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAD4CAYAAAD2FnFTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAYSElEQVR4nO3de5Bc5X3m8e+jGV0Q6MbMYGQhPCZCwUgWMRaJHAVHwK6DwYm0a8hCilrZSy1bxEU58YLLLhdhs8FVQibBcZHEYcMUmE1AhMWgZDcmNhIQNo5kyQZb8koggxwNYM/IkgUS6DKa3/7R70g9rdPqVkvTp2fO86mamjPvufTvFdR5+j1XRQRmZmaVxuVdgJmZtSYHhJmZZXJAmJlZJgeEmZllckCYmVmm9rwLaFRnZ2d0d3fnXYaZ2aiycePGnRHRVc+yozYguru72bBhQ95lmJmNKpJ+XO+yPsRkZmaZHBBmZpbJAWFmZpkcEGZmlskBYWZmmRwQZmaWyQFhZmaZRu19EHk7ODDIT9/cz9e/9xoDhwc5Y1I75545Oe+y7BQ5PAht/vpkI2zn3oPs3neQczsmM7G9/v/hLpw5jXM7Rn5/44A4ATv3HqDn+Vf582d+lHcpZlZgdy6bzw0d7xnxz3FAnICFd37rmLbFczr44rL3cziCgwODOVRlp9qedw7xf37wBr949hQuPndG3uXYGDd98nh+/vahE1rn7KmTRqia4RwQJ+HPfudirl4wM+8ybAQsOq8j7xKsQGZOOy3vEjI5IBq0fcXVeZdgZjaifBrOzMwyOSDqNHD46PmFz3/0ghwrMTNrDgdEnbb/bN+R6f/y67+QYyVmZs3hgKjTD17bA8D7Z03LuRIzs+ZwQNTp91e9CHBCN7OYmY1m3tudoF+fW9eb+szMRj0HxAm6yvc9mFlBOCBO0Hs7Ts+7BDOzpnBAnKBx45R3CWZmTeGAMDOzTA6IOvlR3mZWNA6IOvS/dYB/3fV23mWYmTWVA6IO39j0Rt4lmJk1nQOiDlMmjc+7BDOzpqsZEJJ6JPVJ2lTRfoukrZI2S1qZ2jokrZW0V9K9Vba3unxbkiZKWiVpm6R1krpPsk+n3KwZpWe1+wImMyuSekYQDwBXljdIugxYCiyIiHnA3WnWfuB24NasDUn698DeiuYbgd0RMQe4B7ir3uKb5VB6kmvPJy7JuRIzs+apGRAR8Rywq6L5ZmBFRBxIy/Sl3/si4nlKQTGMpDOAzwB3VsxaCjyYph8DrpDUUt/Vf+d/rANg7Za+nCsxM2ueRs9BzAUuTYeEnpVUz1frPwL+GKi8HGgWsAMgIgaAPUDm+x4l3SRpg6QN/f39DZbeuPPfNaXpn2lmlpdGA6IdmAEsAm4DHj3et35JvwTMiYivZ83OaIus7UTEfRGxMCIWdnU1/6F5rTWuMTMbWY0GRC/weJSsBwaBzuMs/yHgg5K2A88DcyU9U7at2QCS2oFpHHtIqyVcdM70vEswM2uaRgPiCeByAElzgQnAzmoLR8RfRMS7I6Ib+DXgpYhYkmavBpan6WuANRGROYLI23y/LMjMCqS91gKSHgaWAJ2SeoE7gB6gJ12uehBYPrRTT6OEqcAEScuAj0TED4/zEfcDD0naRmnkcF3DvRkh82dNZdNrb+ZdhplZU9UMiIi4vsqsG6os311je9uB+WV/7weurVVHni44eyq79h7Muwwzs6byndR1GDg8SHub/6nMrFi816vDz/YdZM87h/Iuw8ysqWoeYjL4p5ernn83MxuzPIIwM7NMDggzM8vkgDAzs0wOiBr2HRjIuwQzs1w4IGqYd8dTeZdgZpYLB4SZmWVyQJiZWSYHhJmZZXJA1OnJTy3OuwQzs6ZyQBzHPd986cj0eV2n51iJmVnzOSCSJ194jTVbfjqs7U+ffvnI9JRJ45tdkplZrvwspuTTj7wAwPYVV+dbiJlZi/AIwszMMjkgqhg4PJh3CWZmuXJAVLH+1V1Hpj+2YGaOlZiZ5cMBUcWb+4++IGjlNQtyrMTMLB8OiCq+/K2jVzBNnuBz+WZWPA6IKrb85K28SzAzy5UDAlj3ys+OTA8ORo6VmJm1DgcE8NO3DhyZ/v5rewC4aPb0nKoxM2sNDghg/DgdmV72Z/8XgGs+eA4AM6dNyqUmM7O8OSCAnXsPDPv79Z+/w+kT2gD4q+UL8yjJzCx3Dgjg9T37h/39qyvW8Er/PgCm+hlMZlZQDghgTtcZx7Tdu3YbAOPKDj+ZmRWJAwL4r3/7YtV5b75zqOo8M7OxrGZASOqR1CdpU0X7LZK2StosaWVq65C0VtJeSfdWLP8NSS+m5b8qqS21T5S0StI2SeskdZ/C/p20s6ZMzLsEM7Nc1DOCeAC4srxB0mXAUmBBRMwD7k6z9gO3A7dmbOe3I+IiYD7QBVyb2m8EdkfEHOAe4K4T7MOImjS+Le8SzMxyUTMgIuI5YFdF883Aiog4kJbpS7/3RcTzlIKicjtvpsl2YAIwdEfaUuDBNP0YcIWkljnwP77NR+HMrJga3fvNBS5Nh4SelXRJPStJegroA96iFAYAs4AdABExAOwBOqqsf5OkDZI29Pf3N1j6iRnf1jJZZWbWVI0GRDswA1gE3AY8Ws+3/oj4DWAmMBG4PDVnrZf5vIuIuC8iFkbEwq6uroYKP1EtNJgxM2uqRgOiF3g8StYDg0BnPStGxH5gNaVDS0Pbmg0gqR2YxrGHtJpi5cf9WG8zsyGNBsQTpBGApLmUzinsrLawpDMkzUzT7cBVwJY0ezWwPE1fA6yJiFyemPevu97O42PNzFpSzRcdSHoYWAJ0SuoF7gB6gJ506etBYPnQTl3SdmAqMEHSMuAjwM+A1ZImAm3AGuCr6SPuBx6StI3SyOG6U9W5EzV0c5yZmdUREBFxfZVZN1RZvrvK8pknstMhp2uz5pmZWX58DaeZmWVyQJiZWSYHBHDp+Z1cfO50/vH3P5x3KWZmLcMBAQxGME6i3U9uNTM7wgEBDA7COIm39g/kXYqZWcuoeRVTEQxGgGDvgaMB8eSnFtPlJ7maWYE5ICg912Oc4ODhwSNtF82enls9ZmatwIeYgEjnIHbtPZh3KWZmLcMBAQxG6RzE4jl1PU7KzKwQHBCUzkFIMH3y+LxLMTNrGT4HAby44+ecPXXSkbfHffzic3KuyMwsfw4ISoeYXt9Tegne9hVX51yNmVlrcEAAp41v4z0dk/Muw8yspTgggO7O0zlnxml5l2Fm1lJ8kpqhy1zzrsLMrLU4IEhXMWW+GtvMrLgcEEAEjPO/hJnZMN4tMnQfhEcQZmblHBCURhCOBzOz4XwVE/DKzn28c+hw3mWYmbUUjyCSN9KNcmZmVuKAMDOzTA6IZNJ4/1OYmZXzOQhgxuTx/OZF7867DDOzluKvzRx9H4SZmR3lgAAGB0vvgzAzs6McEJRulGtzQpiZDeOAAA5HMM5P6zMzG6ZmQEjqkdQnaVNF+y2StkraLGllauuQtFbSXkn3li07WdL/lrQlLb+ibN5ESaskbZO0TlL3KexfXXwOwszsWPWMIB4ArixvkHQZsBRYEBHzgLvTrP3A7cCtGdu5OyIuAD4ALJb00dR+I7A7IuYA9wB3nWgnTpYf921mdqyaARERzwG7KppvBlZExIG0TF/6vS8inqcUFOXbeDsi1qbpg8B3gaEXPy8FHkzTjwFXqMlPzjt0OFj/amUXzcyKrdFzEHOBS9MhoWclXVLvipKmA78JPJ2aZgE7ACJiANgDdFRZ9yZJGyRt6O/vb7D04QYHA4ANP959SrZnZjZWNBoQ7cAMYBFwG/BoPd/6JbUDDwNfiYhXhpozFo2s9SPivohYGBELu7q6Gqu8wuEofdQnfrX7lGzPzGysaDQgeoHHo2Q9MAh01rHefcDLEfHlim3NhiMBMo1jD2mNmMNpBNE1ZWKzPtLMbFRoNCCeAC4HkDQXmADsPN4Kku6ktPP/vYpZq4HlafoaYE1EZI4gRsJg+qg2n6U2Mxum5rOYJD0MLAE6JfUCdwA9QE+69PUgsHxopy5pOzAVmCBpGfAR4E3gC8AW4LvpaNS9EfFXwP3AQ5K2URo5XHcK+3dca7f0ccHMKQC+Uc7MrELNgIiI66vMuqHK8t1Vls/cA0fEfuDaWnWcar273+aTD3yHC84uBcQ3Nv+E//zh85pdhplZyyrsndRvHyy9QW7LT94CYKOvYjIzG6awATHYvNMcZmajUmEDYmgEMeSPls7LqRIzs9ZU2ICoHECcPtHvTjIzK1fYgPjSU1uG/e2LmMzMhitsQPzLK8PvxTt02OckzMzKFTIgvvbt7ce0+XHfZmbDFTIg/uDJzce0vfnOoRwqMTNrXYUMiCxDz2QyM7MSB0RyaHAw7xLMzFqKAyIZ8ElqM7NhHBDJocMeQZiZlXNAJO9U3FltZlZ0Dojkke/syLsEM7OW4oBI/t0HZuVdgplZS3FAmJlZJgdEMuD7IMzMhnFAJAO+isnMbBgHRPLOIV/FZGZWzgGRvG/m1LxLMDNrKYUPiH/zvrMAeP+saTlXYmbWWgr/GrU/XDqfxXN+wqXnd+ZdiplZSyl8QJwxsZ1PLn5v3mWYmbWcwh9i8nuCzMyyFT4gwle3mpllKnxAtLd5CGFmlqXwAeFDTGZm2RwQOCHMzLLUDAhJPZL6JG2qaL9F0lZJmyWtTG0dktZK2ivp3orlvyhph6S9Fe0TJa2StE3SOkndp6BfdfMIwswsWz0jiAeAK8sbJF0GLAUWRMQ84O40az9wO3Brxnb+DvjljPYbgd0RMQe4B7irrsrNzGxE1QyIiHgO2FXRfDOwIiIOpGX60u99EfE8paCo3M6/RMQbGR+xFHgwTT8GXCE173u9RxBmZtkaPQcxF7g0HRJ6VtIlJ1HDLGAHQEQMAHuAjqwFJd0kaYOkDf39/SfxkWXb9DkIM7NMjQZEOzADWATcBjx6Et/6s9bLfDlDRNwXEQsjYmFXV1eDH1fx4c4HM7NMjQZEL/B4lKwHBoFGH2bUC8wGkNQOTOPYQ1pmZtZkjQbEE8DlAJLmAhOAnQ1uazWwPE1fA6yJiKa93m2chxBmZpnqucz1YeDbwC9K6pV0I9ADnJcufX0EWD60U5e0HfgT4BNp+QtT+0pJvcDk1P7f0kfcD3RI2gZ8BvjcKe1hDY4HM7NsNZ/mGhHXV5l1Q5Xlu6u0fxb4bEb7fuDaWnWMFA8gzMyy+U5qJ4SZWabCB4SZmWVzQJiZWSYHhJmZZXJAmJlZJgeEmZllckCYmVkmB4SZmWVyQJiZWSYHhJmZZXJAmJlZJgeEmZllckCYmVmmwgVEE181YWY2qhUwIPKuwMxsdChcQAw6IczM6lLAgMi7AjOz0aGAAeGEMDOrR+EC4uDhwbxLMDMbFQoXEG1+xaiZWV0KFxA+xGRmVp/CBYTjwcysPsULCJ+CMDOrS+EC4pmX+vIuwcxsVChcQHz6kRfyLsHMbFQoXECYmVl9HBBmZpbJAWFmZplqBoSkHkl9kjZVtN8iaaukzZJWprYOSWsl7ZV0b8XyH5T0A0nbJH1FKt2xJmmipFWpfZ2k7lPYPzMza1A9I4gHgCvLGyRdBiwFFkTEPODuNGs/cDtwa8Z2/gK4CTg//Qxt80Zgd0TMAe4B7jqxLpiZ2UioGRAR8Rywq6L5ZmBFRBxIy/Sl3/si4nlKQXGEpJnA1Ij4dpTe2PM1YFmavRR4ME0/BlwxNLoYCWeePmGkNm1mNqY0eg5iLnBpOiT0rKRLaiw/C+gt+7s3tQ3N2wEQEQPAHqAjayOSbpK0QdKG/v7+hgp3QJiZ1afRgGgHZgCLgNuAR2t868+aF3XMG94YcV9ELIyIhV1dXSdS7xFXv39mQ+uZmRVNowHRCzweJeuBQaCzxvLnlP19DvB62bzZAJLagWkce0jrlLl6gQPCzKwejQbEE8DlAJLmAhOAndUWjog3gLckLUojjf8IPJlmrwaWp+lrgDXpPMWImPuuKXzhqveN1ObNzMaM9loLSHoYWAJ0SuoF7gB6gJ506etBYPnQTl3SdmAqMEHSMuAjEfFDSie2HwBOA/4h/QDcDzwkaRulkcN1p6hvVf3CWaeP9EeYmY16NQMiIq6vMuuGKst3V2nfAMzPaN8PXFurjlNpnF8aZGZWUyHvpG4fV8hum5mdkELuKZ0PZma1FXJX6RGEmVlthdxTthWy12ZmJ6aQu8o2jyDMzGoq5J6yzVcxmZnVVMiA8ADCzKy2Qu4q28Z5BGFmVkshA6LdAWFmVlMhA8J3UpuZ1VbIgPAhJjOz2hwQZmaWyQFhZmaZihkQPgdhZlZTIQNinEcQZmY1FTIgPIIwM6utkAHhEYSZWW2FDAjfKGdmVlshA2LS+La8SzAza3mFDAhf5mpmVlshA8LMzGpzQJiZWSYHhJmZZWrPu4C83LlsPvNnTcu7DDOzllXYgLhh0XvyLsHMrKX5EJOZmWVyQJiZWaaaASGpR1KfpE0V7bdI2ipps6SVZe2fl7QtzfuNsvb/IOn7GctPlLQqrbNOUvcp6puZmZ2EekYQDwBXljdIugxYCiyIiHnA3an9QuA6YF5a588ltUnqAL4EXJGWf5ekK9LmbgR2R8Qc4B7grpPulZmZnbSaARERzwG7KppvBlZExIG0TF9qXwo8EhEHIuJVYBvwy8B5wEsR0Z+W+xbw8bJ1HkzTjwFXSH7cqplZ3ho9BzEXuDQdEnpW0iWpfRawo2y53tS2DbhAUrekdmAZMLtynYgYAPYAHQ3WZWZmp0ijl7m2AzOARcAlwKOSzgOyvvlHROyWdDOwChgE/pnSqIJq62R9qKSbgJsAzj333AZLNzOzejQ6gugFHo+S9ZR2+p2pfXbZcucArwNExN9FxK9ExIeArcDLZduaDZBGF9M49pAWaRv3RcTCiFjY1dXVYOlmZlaPRkcQTwCXA89ImgtMAHYCq4G/kfQnwLuB84H1AJLOiog+STOA3wV+O21rNbAc+DZwDbAmIjJHEOU2bty4U9KPG6y/M9VbJO5zMbjPxXAyfa77LuGaASHpYWAJ0CmpF7gD6AF60qWvB4Hlaae+WdKjwA+BAeBTEXE4bepPJV2Upv97RLyUpu8HHpK0jdLI4bp6Co+IhocQkjZExMJG1x+N3OdicJ+LoVl9rhkQEXF9lVk3VFn+i8AX691OROwHrq1Vh5mZNZfvpDYzs0xFDYj78i4gB+5zMbjPxdCUPquO88FmZlZARR1BmJlZDQ4IMzPLVLiAkHRletLsNkmfy7ueWrKepivpTEnflPRy+j2jbF61p+l+UNIP0ryvDD3v6nhP05W0PH3Gy5KWN6nLSJotaa2k/5ee/vvpsd5vSZMkrZf0YurzH471Ppd9dpuk70n6+/T3mO6zpO2p1hckbWjpPkdEYX6ANuBHlB7zMQF4Ebgw77pq1Pxh4GJgU1nbSuBzafpzwF1p+sLUp4nAe1Nf29K89cCHKD3a5B+Aj6b23wW+mqavA1al6TOBV9LvGWl6RpP6PBO4OE1PAV5KfRuz/U71nZGmxwPrKD3KZsz2uazvnwH+Bvj7gvz/vR3orGhryT435X+AVvlJ/5hPlf39eeDzeddVR93dDA+IrcDMND0T2JrVH+Cp1OeZwJay9uuBvyxfJk23U7o7U+XLpHl/CVyfU/+fBP5tUfoNTAa+C/zKWO8zpcfxPE3pyQxDATHW+7ydYwOiJftctENM1Z42O9q8KyLeAEi/z0rt1fo3K01Xtg9bJ4Y/Tbcl/q3S8PgDlL5Rj+l+p0MtLwB9wDcjYsz3Gfgy8FlKz3MbMtb7HMA/Stqo0gNIoUX73OizmEarup8cO0pV69/x+t3IOk0h6QzgfwG/FxFvqvprQsZEv6P0WJpfkjQd+Lqk+cdZfNT3WdLHgL6I2ChpST2rZLSNqj4niyPidUlnAd+UtOU4y+ba56KNIKo+bXaU+amkmQDp99ALm6r1rzdNV7YPW0fDn6ab67+VpPGUwuGvI+Lx1Dzm+w0QET8HnqH0Vsax3OfFwG9J2g48Alwu6X8ytvtMRAw94boP+Dqll6q1Zp+bccytVX4ojZheoXSyZ+gk9by866qj7m6Gn4P4EsNPaK1M0/MYfkLrFY6e0PoOpZOeQye0rkrtn2L4Ca1H0/SZwKuUTmbNSNNnNqm/Ar4GfLmifcz2G+gCpqfp04B/Aj42lvtc0f8lHD0HMWb7DJwOTCmb/mdKXwRass9N+x+gVX6AqyhdFfMj4At511NHvQ8DbwCHKH0DuJHS8cSnKb1T4+ny/8jAF1LftpKuakjtC4FNad69HL2LfhLwt5Te+rceOK9snf+U2rcBn2xin3+N0tD3+8AL6eeqsdxvYAHwvdTnTcAfpPYx2+eK/i/haECM2T5TuoLyxfSzmbQPatU++1EbZmaWqWjnIMzMrE4OCDMzy+SAMDOzTA4IMzPL5IAwM7NMDggzM8vkgDAzs0z/H/fIVa8m75SRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(avg_learning)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1f1b68affd0>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(learning['entry'],loss['entry'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
